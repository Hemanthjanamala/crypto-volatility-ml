{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635f480b-2f9b-4d81-80b6-77239f4e5ac3",
   "metadata": {},
   "source": [
    "# PATH SETUP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b6e5eba-fd42-458e-96c0-ab6e4e6d0243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: C:\\Users\\BALA\\OneDrive - University of Hertfordshire\\Desktop\\Hemanth Project\\crypto-volatility-ml\n",
      "PROCESSED_DIR: C:\\Users\\BALA\\OneDrive - University of Hertfordshire\\Desktop\\Hemanth Project\\crypto-volatility-ml\\data\\processed\n",
      "FIG_DIR: C:\\Users\\BALA\\OneDrive - University of Hertfordshire\\Desktop\\Hemanth Project\\crypto-volatility-ml\\reports\\figures\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    # Running as .py script\n",
    "    FILE_PATH = Path(__file__).resolve()\n",
    "    PROJECT_ROOT = FILE_PATH.parents[2]  # crypto-volatility-ml\n",
    "except NameError:\n",
    "    # Running inside Jupyter (cwd = crypto-volatility-ml/notebooks)\n",
    "    PROJECT_ROOT = Path.cwd().resolve().parents[0]\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "REPORT_DIR = PROJECT_ROOT / \"reports\"\n",
    "FIG_DIR = REPORT_DIR / \"figures\"\n",
    "\n",
    "# Create folders if missing\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"PROCESSED_DIR:\", PROCESSED_DIR)\n",
    "print(\"FIG_DIR:\", FIG_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3b8900-fbda-4834-b109-c0e5b9e85fc9",
   "metadata": {},
   "source": [
    "## # AUTO ARIMA MODEL — FULL PIPELINE WITH DETAILED LOGGING (p,d,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e743e7b-7a82-440a-98cb-84965514cf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (37082, 44)\n",
      "Columns: ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Name', 'Symbol', 'SourceFile', 'LogReturn', 'Return_%', 'Volatility_7d', 'Volatility_30d', 'Momentum_7d', 'Momentum_30d', 'RSI_14', 'EMA_12', 'EMA_26', 'MACD', 'MACD_Signal', 'EMA_10', 'EMA_20', 'EMA_50', 'BB_Upper', 'BB_Lower', 'BB_Width', 'High_Low_%', 'Close_Open_%', 'MarketPressure', 'Close_lag1', 'Volume_lag1', 'Return_lag1', 'Close_lag7', 'Volume_lag7', 'Return_lag7', 'Close_lag14', 'Volume_lag14', 'Return_lag14', 'Close_lag30', 'Volume_lag30', 'Return_lag30', 'DayOfWeek', 'Month', 'Quarter']\n",
      "\n",
      "================= AUTO ARIMA (WITH EXOGENOUS) START =================\n",
      "\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: AAVE\n",
      "----------------------------------------------------------\n",
      " Skipping Aave: not enough rows after dropping NaNs.\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: BINANCE COIN\n",
      "----------------------------------------------------------\n",
      "• Train interval: 2017-08-26 → 2020-09-26 (1128 rows)\n",
      "• Test interval : 2020-09-27 → 2021-07-06 (283 rows)\n",
      " Fitting Auto ARIMA with exogenous regressors for Binance Coin...\n",
      " Selected ARIMA order (p,d,q) = (0, 1, 0)\n",
      " Train MAE  = 0.532\n",
      " Train RMSE = 0.869\n",
      " Forecasting next 283 points...\n",
      " Test MAE   = 181.088\n",
      " Test RMSE  = 265.331\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: BITCOIN\n",
      "----------------------------------------------------------\n",
      "• Train interval: 2013-05-30 → 2019-11-22 (2368 rows)\n",
      "• Test interval : 2019-11-23 → 2021-07-06 (592 rows)\n",
      " Fitting Auto ARIMA with exogenous regressors for Bitcoin...\n",
      " Selected ARIMA order (p,d,q) = (1, 1, 1)\n",
      " Train MAE  = 97.837\n",
      " Train RMSE = 250.291\n",
      " Forecasting next 592 points...\n",
      " Test MAE   = 14570.987\n",
      " Test RMSE  = 22679.981\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: CARDANO\n",
      "----------------------------------------------------------\n",
      "• Train interval: 2017-11-02 → 2020-10-10 (1074 rows)\n",
      "• Test interval : 2020-10-11 → 2021-07-06 (269 rows)\n",
      " Fitting Auto ARIMA with exogenous regressors for Cardano...\n",
      " Selected ARIMA order (p,d,q) = (0, 1, 3)\n",
      " Train MAE  = 0.007\n",
      " Train RMSE = 0.020\n",
      " Forecasting next 269 points...\n",
      " Test MAE   = 0.722\n",
      " Test RMSE  = 0.942\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: CHAINLINK\n",
      "----------------------------------------------------------\n",
      "• Train interval: 2017-10-22 → 2020-10-08 (1083 rows)\n",
      "• Test interval : 2020-10-09 → 2021-07-06 (271 rows)\n",
      " Fitting Auto ARIMA with exogenous regressors for Chainlink...\n",
      " Selected ARIMA order (p,d,q) = (3, 1, 3)\n",
      " Train MAE  = 0.114\n",
      " Train RMSE = 0.295\n",
      " Forecasting next 271 points...\n",
      " Test MAE   = 13.887\n",
      " Test RMSE  = 17.162\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: COSMOS\n",
      "----------------------------------------------------------\n",
      "• Train interval: 2019-04-15 → 2021-01-24 (651 rows)\n",
      "• Test interval : 2021-01-25 → 2021-07-06 (163 rows)\n",
      " Fitting Auto ARIMA with exogenous regressors for Cosmos...\n",
      " Selected ARIMA order (p,d,q) = (0, 1, 1)\n",
      " Train MAE  = 0.198\n",
      " Train RMSE = 0.342\n",
      " Forecasting next 163 points...\n",
      " Test MAE   = 9.443\n",
      " Test RMSE  = 10.780\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: CRYPTO.COM COIN\n",
      "----------------------------------------------------------\n",
      "• Train interval: 2019-01-15 → 2021-01-06 (723 rows)\n",
      "• Test interval : 2021-01-07 → 2021-07-06 (181 rows)\n",
      " Fitting Auto ARIMA with exogenous regressors for Crypto.com Coin...\n",
      " Selected ARIMA order (p,d,q) = (0, 1, 0)\n",
      " Train MAE  = 0.002\n",
      " Train RMSE = 0.004\n",
      " Forecasting next 181 points...\n",
      " Test MAE   = 0.067\n",
      " Test RMSE  = 0.084\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: DOGECOIN\n",
      "----------------------------------------------------------\n",
      "• Train interval: 2014-01-16 → 2020-01-07 (2183 rows)\n",
      "• Test interval : 2020-01-08 → 2021-07-06 (546 rows)\n",
      " Fitting Auto ARIMA with exogenous regressors for Dogecoin...\n",
      " Selected ARIMA order (p,d,q) = (1, 1, 0)\n",
      " Train MAE  = 0.000\n",
      " Train RMSE = 0.000\n",
      " Forecasting next 546 points...\n",
      " Test MAE   = 0.061\n",
      " Test RMSE  = 0.143\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: EOS\n",
      "----------------------------------------------------------\n",
      "• Train interval: 2017-08-02 → 2020-09-22 (1148 rows)\n",
      "• Test interval : 2020-09-23 → 2021-07-06 (287 rows)\n",
      " Fitting Auto ARIMA with exogenous regressors for EOS...\n",
      " Selected ARIMA order (p,d,q) = (2, 1, 3)\n",
      " Train MAE  = 0.238\n",
      " Train RMSE = 0.494\n",
      " Forecasting next 287 points...\n",
      " Test MAE   = 1.641\n",
      " Test RMSE  = 2.574\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: ETHEREUM\n",
      "----------------------------------------------------------\n",
      "• Train interval: 2015-09-08 → 2020-05-06 (1703 rows)\n",
      "• Test interval : 2020-05-07 → 2021-07-06 (426 rows)\n",
      " Fitting Auto ARIMA with exogenous regressors for Ethereum...\n",
      " Selected ARIMA order (p,d,q) = (0, 1, 0)\n",
      " Train MAE  = 8.489\n",
      " Train RMSE = 19.659\n",
      " Forecasting next 426 points...\n",
      " Test MAE   = 917.882\n",
      " Test RMSE  = 1330.912\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: IOTA\n",
      "----------------------------------------------------------\n",
      "• Train interval: 2017-07-15 → 2020-09-18 (1162 rows)\n",
      "• Test interval : 2020-09-19 → 2021-07-06 (291 rows)\n",
      " Fitting Auto ARIMA with exogenous regressors for IOTA...\n",
      " Selected ARIMA order (p,d,q) = (2, 1, 2)\n",
      " Train MAE  = 0.043\n",
      " Train RMSE = 0.108\n",
      " Forecasting next 291 points...\n",
      " Test MAE   = 0.623\n",
      " Test RMSE  = 0.893\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: LITECOIN\n",
      "----------------------------------------------------------\n",
      "• Train interval: 2013-05-30 → 2019-11-22 (2368 rows)\n",
      "• Test interval : 2019-11-23 → 2021-07-06 (592 rows)\n",
      " Fitting Auto ARIMA with exogenous regressors for Litecoin...\n",
      " Selected ARIMA order (p,d,q) = (2, 1, 2)\n",
      " Train MAE  = 1.771\n",
      " Train RMSE = 4.863\n",
      " Forecasting next 592 points...\n",
      " Test MAE   = 55.254\n",
      " Test RMSE  = 91.425\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: MONERO\n",
      "----------------------------------------------------------\n",
      "• Train interval: 2014-06-23 → 2020-02-07 (2056 rows)\n",
      "• Test interval : 2020-02-08 → 2021-07-06 (515 rows)\n",
      " Fitting Auto ARIMA with exogenous regressors for Monero...\n",
      " Selected ARIMA order (p,d,q) = (3, 1, 2)\n",
      " Train MAE  = 2.753\n",
      " Train RMSE = 7.487\n",
      " Forecasting next 515 points...\n",
      " Test MAE   = 77.804\n",
      " Test RMSE  = 116.847\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: NEM\n",
      "----------------------------------------------------------\n",
      "• Train interval: 2015-05-03 → 2020-04-10 (1805 rows)\n",
      "• Test interval : 2020-04-11 → 2021-07-06 (452 rows)\n",
      " Fitting Auto ARIMA with exogenous regressors for NEM...\n",
      " Selected ARIMA order (p,d,q) = (2, 1, 3)\n",
      " Train MAE  = 0.007\n",
      " Train RMSE = 0.028\n",
      " Forecasting next 452 points...\n",
      " Test MAE   = 0.151\n",
      " Test RMSE  = 0.215\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: POLKADOT\n",
      "----------------------------------------------------------\n",
      " Skipping Polkadot: not enough rows after dropping NaNs.\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: SOLANA\n",
      "----------------------------------------------------------\n",
      "• Train interval: 2020-05-12 → 2021-04-12 (336 rows)\n",
      "• Test interval : 2021-04-13 → 2021-07-06 (85 rows)\n",
      " Fitting Auto ARIMA with exogenous regressors for Solana...\n",
      " Selected ARIMA order (p,d,q) = (0, 2, 1)\n",
      " Train MAE  = 0.292\n",
      " Train RMSE = 0.543\n",
      " Forecasting next 85 points...\n",
      " Test MAE   = 14.308\n",
      " Test RMSE  = 17.752\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: STELLAR\n",
      "----------------------------------------------------------\n",
      "• Train interval: 2014-09-06 → 2020-02-22 (1996 rows)\n",
      "• Test interval : 2020-02-23 → 2021-07-06 (500 rows)\n",
      " Fitting Auto ARIMA with exogenous regressors for Stellar...\n",
      " Selected ARIMA order (p,d,q) = (3, 1, 3)\n",
      " Train MAE  = 0.004\n",
      " Train RMSE = 0.014\n",
      " Forecasting next 500 points...\n",
      " Test MAE   = 0.142\n",
      " Test RMSE  = 0.221\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: TRON\n",
      "----------------------------------------------------------\n",
      "• Train interval: 2017-10-15 → 2020-10-06 (1088 rows)\n",
      "• Test interval : 2020-10-07 → 2021-07-06 (273 rows)\n",
      " Fitting Auto ARIMA with exogenous regressors for TRON...\n",
      " Selected ARIMA order (p,d,q) = (3, 1, 3)\n",
      " Train MAE  = 0.002\n",
      " Train RMSE = 0.005\n",
      " Forecasting next 273 points...\n",
      " Test MAE   = 0.033\n",
      " Test RMSE  = 0.049\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: TETHER\n",
      "----------------------------------------------------------\n",
      "• Train interval: 2015-04-03 → 2020-04-04 (1829 rows)\n",
      "• Test interval : 2020-04-05 → 2021-07-06 (458 rows)\n",
      " Fitting Auto ARIMA with exogenous regressors for Tether...\n",
      " Selected ARIMA order (p,d,q) = (2, 1, 1)\n",
      " Train MAE  = 0.003\n",
      " Train RMSE = 0.024\n",
      " Forecasting next 458 points...\n",
      " Test MAE   = 0.002\n",
      " Test RMSE  = 0.002\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: USD COIN\n",
      "----------------------------------------------------------\n",
      "• Train interval: 2018-11-09 → 2020-12-23 (776 rows)\n",
      "• Test interval : 2020-12-24 → 2021-07-06 (195 rows)\n",
      " Fitting Auto ARIMA with exogenous regressors for USD Coin...\n",
      " Selected ARIMA order (p,d,q) = (0, 1, 2)\n",
      " Train MAE  = 0.004\n",
      " Train RMSE = 0.036\n",
      " Forecasting next 195 points...\n",
      " Test MAE   = 0.000\n",
      " Test RMSE  = 0.001\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: UNISWAP\n",
      "----------------------------------------------------------\n",
      " Skipping Uniswap: not enough rows after dropping NaNs.\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: WRAPPED BITCOIN\n",
      "----------------------------------------------------------\n",
      "• Train interval: 2019-03-03 → 2021-01-15 (685 rows)\n",
      "• Test interval : 2021-01-16 → 2021-07-06 (172 rows)\n",
      " Fitting Auto ARIMA with exogenous regressors for Wrapped Bitcoin...\n",
      " Selected ARIMA order (p,d,q) = (3, 2, 1)\n",
      " Train MAE  = 297.453\n",
      " Train RMSE = 534.466\n",
      " Forecasting next 172 points...\n",
      " Test MAE   = 18751.208\n",
      " Test RMSE  = 27019.678\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: XRP\n",
      "----------------------------------------------------------\n",
      "• Train interval: 2013-09-05 → 2019-12-11 (2289 rows)\n",
      "• Test interval : 2019-12-12 → 2021-07-06 (573 rows)\n",
      " Fitting Auto ARIMA with exogenous regressors for XRP...\n",
      " Selected ARIMA order (p,d,q) = (1, 1, 1)\n",
      " Train MAE  = 0.010\n",
      " Train RMSE = 0.040\n",
      " Forecasting next 573 points...\n",
      " Test MAE   = 0.217\n",
      " Test RMSE  = 0.402\n",
      "\n",
      "================= AUTO ARIMA (WITH EXOGENOUS) FINISHED =================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coin</th>\n",
       "      <th>Model</th>\n",
       "      <th>p</th>\n",
       "      <th>d</th>\n",
       "      <th>q</th>\n",
       "      <th>Train_MAE</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Test_MAE</th>\n",
       "      <th>Test_RMSE</th>\n",
       "      <th>ForecastPlot</th>\n",
       "      <th>ResidualPlot</th>\n",
       "      <th>PredCSV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>USD Coin</td>\n",
       "      <td>AutoARIMA_Exog</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.036455</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Tether</td>\n",
       "      <td>AutoARIMA_Exog</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TRON</td>\n",
       "      <td>AutoARIMA_Exog</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>0.033432</td>\n",
       "      <td>0.049419</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Crypto.com Coin</td>\n",
       "      <td>AutoARIMA_Exog</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>0.067442</td>\n",
       "      <td>0.083893</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dogecoin</td>\n",
       "      <td>AutoARIMA_Exog</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.060954</td>\n",
       "      <td>0.142855</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NEM</td>\n",
       "      <td>AutoARIMA_Exog</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007073</td>\n",
       "      <td>0.027819</td>\n",
       "      <td>0.151176</td>\n",
       "      <td>0.214900</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Stellar</td>\n",
       "      <td>AutoARIMA_Exog</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.004107</td>\n",
       "      <td>0.013509</td>\n",
       "      <td>0.141974</td>\n",
       "      <td>0.221459</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XRP</td>\n",
       "      <td>AutoARIMA_Exog</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.009734</td>\n",
       "      <td>0.040190</td>\n",
       "      <td>0.217128</td>\n",
       "      <td>0.402317</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IOTA</td>\n",
       "      <td>AutoARIMA_Exog</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.043218</td>\n",
       "      <td>0.108275</td>\n",
       "      <td>0.623414</td>\n",
       "      <td>0.892742</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cardano</td>\n",
       "      <td>AutoARIMA_Exog</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.007048</td>\n",
       "      <td>0.019612</td>\n",
       "      <td>0.722350</td>\n",
       "      <td>0.941808</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EOS</td>\n",
       "      <td>AutoARIMA_Exog</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.237845</td>\n",
       "      <td>0.494086</td>\n",
       "      <td>1.641010</td>\n",
       "      <td>2.574301</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cosmos</td>\n",
       "      <td>AutoARIMA_Exog</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.198199</td>\n",
       "      <td>0.342108</td>\n",
       "      <td>9.442800</td>\n",
       "      <td>10.779605</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chainlink</td>\n",
       "      <td>AutoARIMA_Exog</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.114085</td>\n",
       "      <td>0.295144</td>\n",
       "      <td>13.886791</td>\n",
       "      <td>17.161961</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Solana</td>\n",
       "      <td>AutoARIMA_Exog</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.292227</td>\n",
       "      <td>0.543106</td>\n",
       "      <td>14.307503</td>\n",
       "      <td>17.751533</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Litecoin</td>\n",
       "      <td>AutoARIMA_Exog</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.771152</td>\n",
       "      <td>4.862677</td>\n",
       "      <td>55.254385</td>\n",
       "      <td>91.424582</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Monero</td>\n",
       "      <td>AutoARIMA_Exog</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.753100</td>\n",
       "      <td>7.486989</td>\n",
       "      <td>77.804499</td>\n",
       "      <td>116.847256</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Binance Coin</td>\n",
       "      <td>AutoARIMA_Exog</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.531610</td>\n",
       "      <td>0.869120</td>\n",
       "      <td>181.088165</td>\n",
       "      <td>265.330850</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ethereum</td>\n",
       "      <td>AutoARIMA_Exog</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.488787</td>\n",
       "      <td>19.658918</td>\n",
       "      <td>917.882427</td>\n",
       "      <td>1330.911657</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>AutoARIMA_Exog</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>97.837136</td>\n",
       "      <td>250.291076</td>\n",
       "      <td>14570.987172</td>\n",
       "      <td>22679.981065</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wrapped Bitcoin</td>\n",
       "      <td>AutoARIMA_Exog</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>297.452629</td>\n",
       "      <td>534.465857</td>\n",
       "      <td>18751.208421</td>\n",
       "      <td>27019.678256</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Coin           Model  p  d  q   Train_MAE  Train_RMSE  \\\n",
       "17         USD Coin  AutoARIMA_Exog  0  1  2    0.003937    0.036455   \n",
       "16           Tether  AutoARIMA_Exog  2  1  1    0.002887    0.023950   \n",
       "15             TRON  AutoARIMA_Exog  3  1  3    0.001645    0.004624   \n",
       "5   Crypto.com Coin  AutoARIMA_Exog  0  1  0    0.002320    0.004106   \n",
       "6          Dogecoin  AutoARIMA_Exog  1  1  0    0.000078    0.000220   \n",
       "12              NEM  AutoARIMA_Exog  2  1  3    0.007073    0.027819   \n",
       "14          Stellar  AutoARIMA_Exog  3  1  3    0.004107    0.013509   \n",
       "19              XRP  AutoARIMA_Exog  1  1  1    0.009734    0.040190   \n",
       "9              IOTA  AutoARIMA_Exog  2  1  2    0.043218    0.108275   \n",
       "2           Cardano  AutoARIMA_Exog  0  1  3    0.007048    0.019612   \n",
       "7               EOS  AutoARIMA_Exog  2  1  3    0.237845    0.494086   \n",
       "4            Cosmos  AutoARIMA_Exog  0  1  1    0.198199    0.342108   \n",
       "3         Chainlink  AutoARIMA_Exog  3  1  3    0.114085    0.295144   \n",
       "13           Solana  AutoARIMA_Exog  0  2  1    0.292227    0.543106   \n",
       "10         Litecoin  AutoARIMA_Exog  2  1  2    1.771152    4.862677   \n",
       "11           Monero  AutoARIMA_Exog  3  1  2    2.753100    7.486989   \n",
       "0      Binance Coin  AutoARIMA_Exog  0  1  0    0.531610    0.869120   \n",
       "8          Ethereum  AutoARIMA_Exog  0  1  0    8.488787   19.658918   \n",
       "1           Bitcoin  AutoARIMA_Exog  1  1  1   97.837136  250.291076   \n",
       "18  Wrapped Bitcoin  AutoARIMA_Exog  3  2  1  297.452629  534.465857   \n",
       "\n",
       "        Test_MAE     Test_RMSE  \\\n",
       "17      0.000456      0.001016   \n",
       "16      0.001694      0.002454   \n",
       "15      0.033432      0.049419   \n",
       "5       0.067442      0.083893   \n",
       "6       0.060954      0.142855   \n",
       "12      0.151176      0.214900   \n",
       "14      0.141974      0.221459   \n",
       "19      0.217128      0.402317   \n",
       "9       0.623414      0.892742   \n",
       "2       0.722350      0.941808   \n",
       "7       1.641010      2.574301   \n",
       "4       9.442800     10.779605   \n",
       "3      13.886791     17.161961   \n",
       "13     14.307503     17.751533   \n",
       "10     55.254385     91.424582   \n",
       "11     77.804499    116.847256   \n",
       "0     181.088165    265.330850   \n",
       "8     917.882427   1330.911657   \n",
       "1   14570.987172  22679.981065   \n",
       "18  18751.208421  27019.678256   \n",
       "\n",
       "                                         ForecastPlot  \\\n",
       "17  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "16  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "15  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "5   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "6   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "12  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "14  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "19  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "9   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "2   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "7   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "4   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "3   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "13  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "10  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "11  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "0   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "8   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "1   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "18  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "\n",
       "                                         ResidualPlot  \\\n",
       "17  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "16  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "15  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "5   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "6   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "12  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "14  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "19  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "9   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "2   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "7   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "4   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "3   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "13  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "10  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "11  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "0   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "8   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "1   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "18  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "\n",
       "                                              PredCSV  \n",
       "17  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "16  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "15  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "5   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "6   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "12  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "14  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "19  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "9   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "2   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "7   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "4   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "3   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "13  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "10  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "11  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "0   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "8   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "1   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "18  C:\\Users\\BALA\\OneDrive - University of Hertfor...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# IMPROVED AUTO-ARIMA WITH LAG REGRESSORS (NO LEAKAGE)\n",
    "# ============================================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "# ---------- Paths ----------\n",
    "PROJECT_ROOT = Path(\"..\").resolve()   # adjust if needed\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "FIG_DIR = PROJECT_ROOT / \"reports\" / \"figures\"\n",
    "\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Load full engineered data ----------\n",
    "df = pd.read_csv(PROCESSED_DIR / \"crypto_features.csv\", parse_dates=[\"Date\"])\n",
    "df = df.sort_values([\"Name\", \"Date\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# ---------- Helper: plotting & saving ----------\n",
    "def save_forecast_plot(dates, actual, predicted, coin, model_name):\n",
    "    plt.figure(figsize=(11, 5))\n",
    "    plt.plot(dates, actual, label=\"Actual\", linewidth=2)\n",
    "    plt.plot(dates, predicted, label=\"Predicted\", linewidth=2)\n",
    "    plt.title(f\"{model_name} Forecast vs Actual — {coin}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Close Price\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    out_path = FIG_DIR / f\"{model_name}_{coin}_forecast.png\"\n",
    "    plt.savefig(out_path, dpi=240)\n",
    "    plt.close()\n",
    "    return out_path\n",
    "\n",
    "def save_residual_plot(dates, residuals, coin, model_name):\n",
    "    plt.figure(figsize=(11, 5))\n",
    "    plt.plot(dates, residuals, color=\"purple\")\n",
    "    plt.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "    plt.title(f\"{model_name} Residuals — {coin}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Residual (y_true - y_pred)\")\n",
    "    plt.tight_layout()\n",
    "    out_path = FIG_DIR / f\"{model_name}_{coin}_residuals.png\"\n",
    "    plt.savefig(out_path, dpi=240)\n",
    "    plt.close()\n",
    "    return out_path\n",
    "\n",
    "def save_predictions_csv(dates, actual, predicted, coin, model_name):\n",
    "    out = pd.DataFrame({\n",
    "        \"Date\": dates,\n",
    "        \"y_true\": actual,\n",
    "        \"y_pred\": predicted\n",
    "    })\n",
    "    out_path = PROCESSED_DIR / f\"predictions_{model_name.lower()}_{coin}.csv\"\n",
    "    out.to_csv(out_path, index=False)\n",
    "    return out_path\n",
    "\n",
    "# ---------- ARIMA runner ----------\n",
    "def run_auto_arima_exog(sub_df, coin_name, exog_cols):\n",
    "    \"\"\"\n",
    "    sub_df: one-coin dataframe\n",
    "    exog_cols: list of lag/time features safe as regressors\n",
    "    \"\"\"\n",
    "    # Keep only required columns\n",
    "    cols = [\"Date\", \"Close\"] + exog_cols\n",
    "    sub = sub_df[cols].dropna().copy()\n",
    "\n",
    "    if len(sub) < 300:\n",
    "        print(f\" Skipping {coin_name}: not enough rows after dropping NaNs.\")\n",
    "        return None\n",
    "\n",
    "    # Time-based split 80/20\n",
    "    split = int(len(sub) * 0.8)\n",
    "    train = sub.iloc[:split]\n",
    "    test  = sub.iloc[split:]\n",
    "\n",
    "    print(f\"• Train interval: {train['Date'].iloc[0].date()} → {train['Date'].iloc[-1].date()} ({len(train)} rows)\")\n",
    "    print(f\"• Test interval : {test['Date'].iloc[0].date()} → {test['Date'].iloc[-1].date()} ({len(test)} rows)\")\n",
    "\n",
    "    y_train = train[\"Close\"].values\n",
    "    y_test  = test[\"Close\"].values\n",
    "\n",
    "    X_train = train[exog_cols].values\n",
    "    X_test  = test[exog_cols].values\n",
    "\n",
    "    # ---------- Fit Auto ARIMA ----------\n",
    "    print(f\" Fitting Auto ARIMA with exogenous regressors for {coin_name}...\")\n",
    "\n",
    "    model = auto_arima(\n",
    "        y_train,\n",
    "        exogenous=X_train,\n",
    "        seasonal=False,\n",
    "        stepwise=True,\n",
    "        max_p=3,\n",
    "        max_q=3,\n",
    "        max_d=2,\n",
    "        max_order=6,\n",
    "        suppress_warnings=True,\n",
    "        error_action=\"ignore\",\n",
    "        trace=False,\n",
    "        n_jobs=1\n",
    "    )\n",
    "\n",
    "    order = model.order  # (p,d,q)\n",
    "    p, d, q = order\n",
    "    print(f\" Selected ARIMA order (p,d,q) = ({p}, {d}, {q})\")\n",
    "\n",
    "    # ---------- Train (in-sample) metrics ----------\n",
    "    train_pred = model.predict_in_sample(exogenous=X_train)\n",
    "\n",
    "    train_mae = mean_absolute_error(y_train, train_pred)\n",
    "    train_rmse = root_mean_squared_error(y_train, train_pred)\n",
    "    print(f\" Train MAE  = {train_mae:.3f}\")\n",
    "    print(f\" Train RMSE = {train_rmse:.3f}\")\n",
    "\n",
    "    # ---------- Test forecast ----------\n",
    "    print(f\" Forecasting next {len(test)} points...\")\n",
    "    test_pred = model.predict(n_periods=len(test), exogenous=X_test)\n",
    "\n",
    "    test_mae = mean_absolute_error(y_test, test_pred)\n",
    "    test_rmse = root_mean_squared_error(y_test, test_pred)\n",
    "    print(f\" Test MAE   = {test_mae:.3f}\")\n",
    "    print(f\" Test RMSE  = {test_rmse:.3f}\")\n",
    "\n",
    "    # ---------- Save plots & CSV ----------\n",
    "    forecast_plot = save_forecast_plot(\n",
    "        dates=test[\"Date\"].values,\n",
    "        actual=y_test,\n",
    "        predicted=test_pred,\n",
    "        coin=coin_name,\n",
    "        model_name=\"AutoARIMA_Exog\"\n",
    "    )\n",
    "\n",
    "    residuals = y_test - test_pred\n",
    "    residual_plot = save_residual_plot(\n",
    "        dates=test[\"Date\"].values,\n",
    "        residuals=residuals,\n",
    "        coin=coin_name,\n",
    "        model_name=\"AutoARIMA_Exog\"\n",
    "    )\n",
    "\n",
    "    pred_csv = save_predictions_csv(\n",
    "        dates=test[\"Date\"].values,\n",
    "        actual=y_test,\n",
    "        predicted=test_pred,\n",
    "        coin=coin_name,\n",
    "        model_name=\"AutoARIMA_Exog\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"Coin\": coin_name,\n",
    "        \"Model\": \"AutoARIMA_Exog\",\n",
    "        \"p\": p,\n",
    "        \"d\": d,\n",
    "        \"q\": q,\n",
    "        \"Train_MAE\": train_mae,\n",
    "        \"Train_RMSE\": train_rmse,\n",
    "        \"Test_MAE\": test_mae,\n",
    "        \"Test_RMSE\": test_rmse,\n",
    "        \"ForecastPlot\": str(forecast_plot),\n",
    "        \"ResidualPlot\": str(residual_plot),\n",
    "        \"PredCSV\": str(pred_csv),\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# RUN AUTO ARIMA WITH EXOGENOUS REGRESSORS\n",
    "# ============================================================\n",
    "\n",
    "# Safe regressors: ONLY lags + calendar features (no leakage)\n",
    "arima_exog_cols = [\n",
    "    \"Close_lag1\", \"Close_lag7\", \"Close_lag14\", \"Close_lag30\",\n",
    "    \"Return_lag1\", \"Return_lag7\", \"Return_lag14\", \"Return_lag30\",\n",
    "    \"Volume_lag1\", \"Volume_lag7\", \"Volume_lag14\", \"Volume_lag30\",\n",
    "    \"DayOfWeek\", \"Month\"\n",
    "]\n",
    "\n",
    "results_arima_exog = []\n",
    "\n",
    "print(\"\\n================= AUTO ARIMA (WITH EXOGENOUS) START =================\\n\")\n",
    "\n",
    "for coin in df[\"Name\"].unique():\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    print(f\" Now Processing Coin: {coin.upper()}\")\n",
    "    print(\"----------------------------------------------------------\")\n",
    "\n",
    "    sub_coin = df[df[\"Name\"] == coin].copy()\n",
    "\n",
    "    try:\n",
    "        row = run_auto_arima_exog(sub_coin, coin, arima_exog_cols)\n",
    "        if row is not None:\n",
    "            results_arima_exog.append(row)\n",
    "    except Exception as e:\n",
    "        print(f\" !! Failed for {coin}: {e}\")\n",
    "\n",
    "print(\"\\n================= AUTO ARIMA (WITH EXOGENOUS) FINISHED =================\\n\")\n",
    "\n",
    "if results_arima_exog:\n",
    "    arima_exog_df = pd.DataFrame(results_arima_exog).sort_values(\"Test_RMSE\")\n",
    "    display(arima_exog_df)\n",
    "else:\n",
    "    print(\"No ARIMA results — something went wrong.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995e7f24-d1cf-4f0b-a1da-2154fd9515f1",
   "metadata": {},
   "source": [
    "## PROPHET MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dea4f76-8937-4d50-9327-fe0587e4cda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (37082, 44)\n",
      "Columns: ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Name', 'Symbol', 'SourceFile', 'LogReturn', 'Return_%', 'Volatility_7d', 'Volatility_30d', 'Momentum_7d', 'Momentum_30d', 'RSI_14', 'EMA_12', 'EMA_26', 'MACD', 'MACD_Signal', 'EMA_10', 'EMA_20', 'EMA_50', 'BB_Upper', 'BB_Lower', 'BB_Width', 'High_Low_%', 'Close_Open_%', 'MarketPressure', 'Close_lag1', 'Volume_lag1', 'Return_lag1', 'Close_lag7', 'Volume_lag7', 'Return_lag7', 'Close_lag14', 'Volume_lag14', 'Return_lag14', 'Close_lag30', 'Volume_lag30', 'Return_lag30', 'DayOfWeek', 'Month', 'Quarter']\n",
      "\n",
      "================= PROPHET (LAG REGRESSORS) START =================\n",
      "\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: AAVE\n",
      "----------------------------------------------------------\n",
      " Skipping Aave: not enough rows after dropping NaNs.\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: BINANCE COIN\n",
      "----------------------------------------------------------\n",
      "Train interval: 2017-08-26 → 2020-09-26 (1128 rows)\n",
      "Test interval : 2020-09-27 → 2021-07-06 (283 rows)\n",
      " Tuning hyperparameters on train set (using last 20% as validation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:29:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:29:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=5.0 → Val RMSE = 8.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:29:17 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:29:21 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=10.0 → Val RMSE = 7.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:29:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:29:27 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=5.0 → Val RMSE = 9.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:29:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:29:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=10.0 → Val RMSE = 8.18\n",
      " Best config for Binance Coin: cp=0.3, sp=10.0 (Val RMSE=7.33)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:29:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:29:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train MAE  = 0.527\n",
      "  Train RMSE = 0.809\n",
      " Test MAE   = 14.338\n",
      " Test RMSE  = 26.136\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: BITCOIN\n",
      "----------------------------------------------------------\n",
      "Train interval: 2013-05-30 → 2019-11-22 (2368 rows)\n",
      "Test interval : 2019-11-23 → 2021-07-06 (592 rows)\n",
      " Tuning hyperparameters on train set (using last 20% as validation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:29:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:29:42 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=5.0 → Val RMSE = 501.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:29:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:29:46 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=10.0 → Val RMSE = 524.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:29:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:29:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=5.0 → Val RMSE = 768.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:29:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:29:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=10.0 → Val RMSE = 523.84\n",
      " Best config for Bitcoin: cp=0.3, sp=5.0 (Val RMSE=501.54)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:29:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train MAE  = 100.441\n",
      "  Train RMSE = 246.529\n",
      " Test MAE   = 1080.141\n",
      " Test RMSE  = 1798.180\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: CARDANO\n",
      "----------------------------------------------------------\n",
      "Train interval: 2017-11-02 → 2020-10-10 (1074 rows)\n",
      "Test interval : 2020-10-11 → 2021-07-06 (269 rows)\n",
      " Tuning hyperparameters on train set (using last 20% as validation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:07 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=5.0 → Val RMSE = 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=10.0 → Val RMSE = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=5.0 → Val RMSE = 0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:13 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=10.0 → Val RMSE = 0.07\n",
      " Best config for Cardano: cp=0.3, sp=5.0 (Val RMSE=0.03)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:16 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train MAE  = 0.008\n",
      "  Train RMSE = 0.018\n",
      " Test MAE   = 0.261\n",
      " Test RMSE  = 0.366\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: CHAINLINK\n",
      "----------------------------------------------------------\n",
      "Train interval: 2017-10-22 → 2020-10-08 (1083 rows)\n",
      "Test interval : 2020-10-09 → 2021-07-06 (271 rows)\n",
      " Tuning hyperparameters on train set (using last 20% as validation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:24 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=5.0 → Val RMSE = 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:27 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=10.0 → Val RMSE = 1.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:30 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=5.0 → Val RMSE = 1.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=10.0 → Val RMSE = 1.55\n",
      " Best config for Chainlink: cp=0.3, sp=10.0 (Val RMSE=1.37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:34 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train MAE  = 0.124\n",
      "  Train RMSE = 0.286\n",
      " Test MAE   = 9.151\n",
      " Test RMSE  = 11.371\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: COSMOS\n",
      "----------------------------------------------------------\n",
      "Train interval: 2019-04-15 → 2021-01-24 (651 rows)\n",
      "Test interval : 2021-01-25 → 2021-07-06 (163 rows)\n",
      " Tuning hyperparameters on train set (using last 20% as validation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:37 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=5.0 → Val RMSE = 2.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:38 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=10.0 → Val RMSE = 2.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=5.0 → Val RMSE = 2.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:40 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:41 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=10.0 → Val RMSE = 2.90\n",
      " Best config for Cosmos: cp=0.3, sp=10.0 (Val RMSE=2.60)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:42 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train MAE  = 0.185\n",
      "  Train RMSE = 0.270\n",
      " Test MAE   = 1.419\n",
      " Test RMSE  = 1.896\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: CRYPTO.COM COIN\n",
      "----------------------------------------------------------\n",
      "Train interval: 2019-01-15 → 2021-01-06 (723 rows)\n",
      "Test interval : 2021-01-07 → 2021-07-06 (181 rows)\n",
      " Tuning hyperparameters on train set (using last 20% as validation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=5.0 → Val RMSE = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=10.0 → Val RMSE = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:48 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=5.0 → Val RMSE = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:50 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=10.0 → Val RMSE = 0.01\n",
      " Best config for Crypto.com Coin: cp=0.3, sp=10.0 (Val RMSE=0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:51 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train MAE  = 0.002\n",
      "  Train RMSE = 0.004\n",
      " Test MAE   = 0.012\n",
      " Test RMSE  = 0.016\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: DOGECOIN\n",
      "----------------------------------------------------------\n",
      "Train interval: 2014-01-16 → 2020-01-07 (2183 rows)\n",
      "Test interval : 2020-01-08 → 2021-07-06 (546 rows)\n",
      " Tuning hyperparameters on train set (using last 20% as validation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=5.0 → Val RMSE = 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=10.0 → Val RMSE = 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=5.0 → Val RMSE = 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:30:59 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=10.0 → Val RMSE = 0.00\n",
      " Best config for Dogecoin: cp=0.3, sp=10.0 (Val RMSE=0.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:30:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train MAE  = 0.000\n",
      "  Train RMSE = 0.000\n",
      " Test MAE   = 0.008\n",
      " Test RMSE  = 0.024\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: EOS\n",
      "----------------------------------------------------------\n",
      "Train interval: 2017-08-02 → 2020-09-22 (1148 rows)\n",
      "Test interval : 2020-09-23 → 2021-07-06 (287 rows)\n",
      " Tuning hyperparameters on train set (using last 20% as validation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:04 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=5.0 → Val RMSE = 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=10.0 → Val RMSE = 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:07 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=5.0 → Val RMSE = 1.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:07 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=10.0 → Val RMSE = 2.00\n",
      " Best config for EOS: cp=0.3, sp=5.0 (Val RMSE=0.22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:10 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train MAE  = 0.250\n",
      "  Train RMSE = 0.466\n",
      " Test MAE   = 0.307\n",
      " Test RMSE  = 0.610\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: ETHEREUM\n",
      "----------------------------------------------------------\n",
      "Train interval: 2015-09-08 → 2020-05-06 (1703 rows)\n",
      "Test interval : 2020-05-07 → 2021-07-06 (426 rows)\n",
      " Tuning hyperparameters on train set (using last 20% as validation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:13 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:14 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=5.0 → Val RMSE = 30.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:15 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=10.0 → Val RMSE = 26.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:16 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=5.0 → Val RMSE = 64.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:19 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=10.0 → Val RMSE = 77.63\n",
      " Best config for Ethereum: cp=0.3, sp=10.0 (Val RMSE=26.52)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train MAE  = 8.907\n",
      "  Train RMSE = 18.976\n",
      " Test MAE   = 63.407\n",
      " Test RMSE  = 113.201\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: IOTA\n",
      "----------------------------------------------------------\n",
      "Train interval: 2017-07-15 → 2020-09-18 (1162 rows)\n",
      "Test interval : 2020-09-19 → 2021-07-06 (291 rows)\n",
      " Tuning hyperparameters on train set (using last 20% as validation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:23 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=5.0 → Val RMSE = 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:24 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:25 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=10.0 → Val RMSE = 0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=5.0 → Val RMSE = 0.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:27 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=10.0 → Val RMSE = 0.05\n",
      " Best config for IOTA: cp=0.8, sp=10.0 (Val RMSE=0.05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:28 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train MAE  = 0.047\n",
      "  Train RMSE = 0.104\n",
      " Test MAE   = 0.111\n",
      " Test RMSE  = 0.155\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: LITECOIN\n",
      "----------------------------------------------------------\n",
      "Train interval: 2013-05-30 → 2019-11-22 (2368 rows)\n",
      "Test interval : 2019-11-23 → 2021-07-06 (592 rows)\n",
      " Tuning hyperparameters on train set (using last 20% as validation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:31 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=5.0 → Val RMSE = 8.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:32 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:33 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=10.0 → Val RMSE = 7.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:33 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:35 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=5.0 → Val RMSE = 12.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:38 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=10.0 → Val RMSE = 13.09\n",
      " Best config for Litecoin: cp=0.3, sp=10.0 (Val RMSE=7.95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train MAE  = 1.924\n",
      "  Train RMSE = 4.847\n",
      " Test MAE   = 15.670\n",
      " Test RMSE  = 25.252\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: MONERO\n",
      "----------------------------------------------------------\n",
      "Train interval: 2014-06-23 → 2020-02-07 (2056 rows)\n",
      "Test interval : 2020-02-08 → 2021-07-06 (515 rows)\n",
      " Tuning hyperparameters on train set (using last 20% as validation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:43 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=5.0 → Val RMSE = 10.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=10.0 → Val RMSE = 9.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:46 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=5.0 → Val RMSE = 10.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:48 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=10.0 → Val RMSE = 10.40\n",
      " Best config for Monero: cp=0.3, sp=10.0 (Val RMSE=9.44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:50 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train MAE  = 3.120\n",
      "  Train RMSE = 7.514\n",
      " Test MAE   = 22.478\n",
      " Test RMSE  = 57.005\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: NEM\n",
      "----------------------------------------------------------\n",
      "Train interval: 2015-05-03 → 2020-04-10 (1805 rows)\n",
      "Test interval : 2020-04-11 → 2021-07-06 (452 rows)\n",
      " Tuning hyperparameters on train set (using last 20% as validation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=5.0 → Val RMSE = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=10.0 → Val RMSE = 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:31:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=5.0 → Val RMSE = 0.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:31:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:00 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=10.0 → Val RMSE = 0.07\n",
      " Best config for NEM: cp=0.3, sp=5.0 (Val RMSE=0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:02 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train MAE  = 0.009\n",
      "  Train RMSE = 0.026\n",
      " Test MAE   = 0.127\n",
      " Test RMSE  = 0.176\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: POLKADOT\n",
      "----------------------------------------------------------\n",
      " Skipping Polkadot: not enough rows after dropping NaNs.\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: SOLANA\n",
      "----------------------------------------------------------\n",
      "Train interval: 2020-05-12 → 2021-04-12 (336 rows)\n",
      "Test interval : 2021-04-13 → 2021-07-06 (85 rows)\n",
      " Tuning hyperparameters on train set (using last 20% as validation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:04 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=5.0 → Val RMSE = 4.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:05 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:06 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=10.0 → Val RMSE = 4.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:32:07 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=5.0 → Val RMSE = 4.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:07 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=10.0 → Val RMSE = 4.47\n",
      " Best config for Solana: cp=0.3, sp=10.0 (Val RMSE=4.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:08 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train MAE  = 0.259\n",
      "  Train RMSE = 0.445\n",
      " Test MAE   = 19.058\n",
      " Test RMSE  = 22.977\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: STELLAR\n",
      "----------------------------------------------------------\n",
      "Train interval: 2014-09-06 → 2020-02-22 (1996 rows)\n",
      "Test interval : 2020-02-23 → 2021-07-06 (500 rows)\n",
      " Tuning hyperparameters on train set (using last 20% as validation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:11 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=5.0 → Val RMSE = 0.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:12 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:15 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=10.0 → Val RMSE = 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:15 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:17 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=5.0 → Val RMSE = 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=10.0 → Val RMSE = 0.10\n",
      " Best config for Stellar: cp=0.3, sp=5.0 (Val RMSE=0.02)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:22 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train MAE  = 0.005\n",
      "  Train RMSE = 0.013\n",
      " Test MAE   = 0.068\n",
      " Test RMSE  = 0.102\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: TRON\n",
      "----------------------------------------------------------\n",
      "Train interval: 2017-10-15 → 2020-10-06 (1088 rows)\n",
      "Test interval : 2020-10-07 → 2021-07-06 (273 rows)\n",
      " Tuning hyperparameters on train set (using last 20% as validation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:25 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:26 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=5.0 → Val RMSE = 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:26 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:27 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=10.0 → Val RMSE = 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:28 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=5.0 → Val RMSE = 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=10.0 → Val RMSE = 0.01\n",
      " Best config for TRON: cp=0.3, sp=10.0 (Val RMSE=0.00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:32 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train MAE  = 0.002\n",
      "  Train RMSE = 0.005\n",
      " Test MAE   = 0.015\n",
      " Test RMSE  = 0.019\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: TETHER\n",
      "----------------------------------------------------------\n",
      "Train interval: 2015-04-03 → 2020-04-04 (1829 rows)\n",
      "Test interval : 2020-04-05 → 2021-07-06 (458 rows)\n",
      " Tuning hyperparameters on train set (using last 20% as validation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:34 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:34 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=5.0 → Val RMSE = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:36 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=10.0 → Val RMSE = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:37 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=5.0 → Val RMSE = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:39 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=10.0 → Val RMSE = 0.01\n",
      " Best config for Tether: cp=0.3, sp=5.0 (Val RMSE=0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train MAE  = 0.002\n",
      "  Train RMSE = 0.005\n",
      " Test MAE   = 0.003\n",
      " Test RMSE  = 0.004\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: USD COIN\n",
      "----------------------------------------------------------\n",
      "Train interval: 2018-11-09 → 2020-12-23 (776 rows)\n",
      "Test interval : 2020-12-24 → 2021-07-06 (195 rows)\n",
      " Tuning hyperparameters on train set (using last 20% as validation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:42 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:43 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=5.0 → Val RMSE = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:43 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:44 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=10.0 → Val RMSE = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=5.0 → Val RMSE = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:46 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:46 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=10.0 → Val RMSE = 0.01\n",
      " Best config for USD Coin: cp=0.8, sp=5.0 (Val RMSE=0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:47 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:47 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train MAE  = 0.003\n",
      "  Train RMSE = 0.004\n",
      " Test MAE   = 0.011\n",
      " Test RMSE  = 0.011\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: UNISWAP\n",
      "----------------------------------------------------------\n",
      " Skipping Uniswap: not enough rows after dropping NaNs.\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: WRAPPED BITCOIN\n",
      "----------------------------------------------------------\n",
      "Train interval: 2019-03-03 → 2021-01-15 (685 rows)\n",
      "Test interval : 2021-01-16 → 2021-07-06 (172 rows)\n",
      " Tuning hyperparameters on train set (using last 20% as validation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:50 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=5.0 → Val RMSE = 6099.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:51 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "04:32:52 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=10.0 → Val RMSE = 5983.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:53 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=5.0 → Val RMSE = 6857.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:54 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=10.0 → Val RMSE = 7365.09\n",
      " Best config for Wrapped Bitcoin: cp=0.3, sp=10.0 (Val RMSE=5983.83)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:54 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:56 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train MAE  = 1305.023\n",
      "  Train RMSE = 2311.671\n",
      " Test MAE   = 25314.331\n",
      " Test RMSE  = 28608.457\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: XRP\n",
      "----------------------------------------------------------\n",
      "Train interval: 2013-09-05 → 2019-12-11 (2289 rows)\n",
      "Test interval : 2019-12-12 → 2021-07-06 (573 rows)\n",
      " Tuning hyperparameters on train set (using last 20% as validation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:32:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:32:59 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=5.0 → Val RMSE = 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:33:00 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:33:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.3, sp=10.0 → Val RMSE = 0.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:33:01 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:33:03 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=5.0 → Val RMSE = 0.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:33:03 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:33:05 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cp=0.8, sp=10.0 → Val RMSE = 0.10\n",
      " Best config for XRP: cp=0.3, sp=10.0 (Val RMSE=0.09)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04:33:06 - cmdstanpy - INFO - Chain [1] start processing\n",
      "04:33:08 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train MAE  = 0.013\n",
      "  Train RMSE = 0.038\n",
      " Test MAE   = 0.277\n",
      " Test RMSE  = 0.458\n",
      "\n",
      "================= PROPHET (LAG REGRESSORS) FINISHED =================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coin</th>\n",
       "      <th>Model</th>\n",
       "      <th>cp_best</th>\n",
       "      <th>sp_best</th>\n",
       "      <th>Val_RMSE</th>\n",
       "      <th>Train_MAE</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Test_MAE</th>\n",
       "      <th>Test_RMSE</th>\n",
       "      <th>ForecastPlot</th>\n",
       "      <th>ResidualPlot</th>\n",
       "      <th>PredCSV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Tether</td>\n",
       "      <td>Prophet_LagReg</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.005062</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>USD Coin</td>\n",
       "      <td>Prophet_LagReg</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.010558</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>0.004107</td>\n",
       "      <td>0.010536</td>\n",
       "      <td>0.011466</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Crypto.com Coin</td>\n",
       "      <td>Prophet_LagReg</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.003770</td>\n",
       "      <td>0.012213</td>\n",
       "      <td>0.016095</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TRON</td>\n",
       "      <td>Prophet_LagReg</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.001895</td>\n",
       "      <td>0.004636</td>\n",
       "      <td>0.014711</td>\n",
       "      <td>0.019107</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dogecoin</td>\n",
       "      <td>Prophet_LagReg</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.007662</td>\n",
       "      <td>0.023727</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Stellar</td>\n",
       "      <td>Prophet_LagReg</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.019263</td>\n",
       "      <td>0.004725</td>\n",
       "      <td>0.013352</td>\n",
       "      <td>0.067640</td>\n",
       "      <td>0.101605</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IOTA</td>\n",
       "      <td>Prophet_LagReg</td>\n",
       "      <td>0.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.046258</td>\n",
       "      <td>0.047076</td>\n",
       "      <td>0.103736</td>\n",
       "      <td>0.110564</td>\n",
       "      <td>0.155057</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NEM</td>\n",
       "      <td>Prophet_LagReg</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.012285</td>\n",
       "      <td>0.009407</td>\n",
       "      <td>0.026007</td>\n",
       "      <td>0.126985</td>\n",
       "      <td>0.175865</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cardano</td>\n",
       "      <td>Prophet_LagReg</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.033909</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>0.017939</td>\n",
       "      <td>0.260808</td>\n",
       "      <td>0.365844</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XRP</td>\n",
       "      <td>Prophet_LagReg</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.090628</td>\n",
       "      <td>0.012952</td>\n",
       "      <td>0.037814</td>\n",
       "      <td>0.277163</td>\n",
       "      <td>0.457708</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EOS</td>\n",
       "      <td>Prophet_LagReg</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.223751</td>\n",
       "      <td>0.250336</td>\n",
       "      <td>0.465684</td>\n",
       "      <td>0.306862</td>\n",
       "      <td>0.610332</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cosmos</td>\n",
       "      <td>Prophet_LagReg</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.601837</td>\n",
       "      <td>0.184752</td>\n",
       "      <td>0.269912</td>\n",
       "      <td>1.419016</td>\n",
       "      <td>1.895655</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chainlink</td>\n",
       "      <td>Prophet_LagReg</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.369328</td>\n",
       "      <td>0.123771</td>\n",
       "      <td>0.286098</td>\n",
       "      <td>9.150926</td>\n",
       "      <td>11.371027</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Solana</td>\n",
       "      <td>Prophet_LagReg</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.314532</td>\n",
       "      <td>0.259335</td>\n",
       "      <td>0.445233</td>\n",
       "      <td>19.057826</td>\n",
       "      <td>22.977223</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Litecoin</td>\n",
       "      <td>Prophet_LagReg</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.951489</td>\n",
       "      <td>1.924458</td>\n",
       "      <td>4.846854</td>\n",
       "      <td>15.669538</td>\n",
       "      <td>25.252385</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Binance Coin</td>\n",
       "      <td>Prophet_LagReg</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.330867</td>\n",
       "      <td>0.526537</td>\n",
       "      <td>0.809357</td>\n",
       "      <td>14.338241</td>\n",
       "      <td>26.135827</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Monero</td>\n",
       "      <td>Prophet_LagReg</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.440676</td>\n",
       "      <td>3.120013</td>\n",
       "      <td>7.514041</td>\n",
       "      <td>22.478017</td>\n",
       "      <td>57.005374</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ethereum</td>\n",
       "      <td>Prophet_LagReg</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>26.523831</td>\n",
       "      <td>8.906900</td>\n",
       "      <td>18.975728</td>\n",
       "      <td>63.406942</td>\n",
       "      <td>113.200780</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Prophet_LagReg</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>501.540647</td>\n",
       "      <td>100.440567</td>\n",
       "      <td>246.529461</td>\n",
       "      <td>1080.140978</td>\n",
       "      <td>1798.179727</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wrapped Bitcoin</td>\n",
       "      <td>Prophet_LagReg</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5983.825051</td>\n",
       "      <td>1305.022562</td>\n",
       "      <td>2311.670644</td>\n",
       "      <td>25314.330839</td>\n",
       "      <td>28608.457303</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Coin           Model  cp_best  sp_best     Val_RMSE  \\\n",
       "16           Tether  Prophet_LagReg      0.3      5.0     0.006735   \n",
       "17         USD Coin  Prophet_LagReg      0.8      5.0     0.010558   \n",
       "5   Crypto.com Coin  Prophet_LagReg      0.3     10.0     0.006156   \n",
       "15             TRON  Prophet_LagReg      0.3     10.0     0.003433   \n",
       "6          Dogecoin  Prophet_LagReg      0.3     10.0     0.000112   \n",
       "14          Stellar  Prophet_LagReg      0.3      5.0     0.019263   \n",
       "9              IOTA  Prophet_LagReg      0.8     10.0     0.046258   \n",
       "12              NEM  Prophet_LagReg      0.3      5.0     0.012285   \n",
       "2           Cardano  Prophet_LagReg      0.3      5.0     0.033909   \n",
       "19              XRP  Prophet_LagReg      0.3     10.0     0.090628   \n",
       "7               EOS  Prophet_LagReg      0.3      5.0     0.223751   \n",
       "4            Cosmos  Prophet_LagReg      0.3     10.0     2.601837   \n",
       "3         Chainlink  Prophet_LagReg      0.3     10.0     1.369328   \n",
       "13           Solana  Prophet_LagReg      0.3     10.0     4.314532   \n",
       "10         Litecoin  Prophet_LagReg      0.3     10.0     7.951489   \n",
       "0      Binance Coin  Prophet_LagReg      0.3     10.0     7.330867   \n",
       "11           Monero  Prophet_LagReg      0.3     10.0     9.440676   \n",
       "8          Ethereum  Prophet_LagReg      0.3     10.0    26.523831   \n",
       "1           Bitcoin  Prophet_LagReg      0.3      5.0   501.540647   \n",
       "18  Wrapped Bitcoin  Prophet_LagReg      0.3     10.0  5983.825051   \n",
       "\n",
       "      Train_MAE   Train_RMSE      Test_MAE     Test_RMSE  \\\n",
       "16     0.002443     0.005062      0.002717      0.003787   \n",
       "17     0.002566     0.004107      0.010536      0.011466   \n",
       "5      0.002334     0.003770      0.012213      0.016095   \n",
       "15     0.001895     0.004636      0.014711      0.019107   \n",
       "6      0.000084     0.000216      0.007662      0.023727   \n",
       "14     0.004725     0.013352      0.067640      0.101605   \n",
       "9      0.047076     0.103736      0.110564      0.155057   \n",
       "12     0.009407     0.026007      0.126985      0.175865   \n",
       "2      0.007698     0.017939      0.260808      0.365844   \n",
       "19     0.012952     0.037814      0.277163      0.457708   \n",
       "7      0.250336     0.465684      0.306862      0.610332   \n",
       "4      0.184752     0.269912      1.419016      1.895655   \n",
       "3      0.123771     0.286098      9.150926     11.371027   \n",
       "13     0.259335     0.445233     19.057826     22.977223   \n",
       "10     1.924458     4.846854     15.669538     25.252385   \n",
       "0      0.526537     0.809357     14.338241     26.135827   \n",
       "11     3.120013     7.514041     22.478017     57.005374   \n",
       "8      8.906900    18.975728     63.406942    113.200780   \n",
       "1    100.440567   246.529461   1080.140978   1798.179727   \n",
       "18  1305.022562  2311.670644  25314.330839  28608.457303   \n",
       "\n",
       "                                         ForecastPlot  \\\n",
       "16  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "17  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "5   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "15  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "6   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "14  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "9   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "12  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "2   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "19  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "7   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "4   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "3   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "13  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "10  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "0   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "11  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "8   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "1   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "18  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "\n",
       "                                         ResidualPlot  \\\n",
       "16  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "17  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "5   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "15  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "6   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "14  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "9   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "12  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "2   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "19  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "7   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "4   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "3   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "13  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "10  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "0   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "11  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "8   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "1   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "18  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "\n",
       "                                              PredCSV  \n",
       "16  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "17  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "5   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "15  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "6   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "14  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "9   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "12  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "2   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "19  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "7   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "4   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "3   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "13  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "10  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "0   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "11  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "8   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "1   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "18  C:\\Users\\BALA\\OneDrive - University of Hertfor...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "from prophet import Prophet\n",
    "\n",
    "# ---------- Paths ----------\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "FIG_DIR = PROJECT_ROOT / \"reports\" / \"figures\"\n",
    "\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- Load engineered dataset ----------\n",
    "df = pd.read_csv(PROCESSED_DIR / \"crypto_features.csv\", parse_dates=[\"Date\"])\n",
    "df = df.sort_values([\"Name\", \"Date\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# ---------- Helper: plotting & saving ----------\n",
    "def save_forecast_plot(dates, actual, predicted, coin, model_name):\n",
    "    plt.figure(figsize=(11, 5))\n",
    "    plt.plot(dates, actual, label=\"Actual\", linewidth=2)\n",
    "    plt.plot(dates, predicted, label=\"Predicted\", linewidth=2)\n",
    "    plt.title(f\"{model_name} Forecast vs Actual — {coin}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Close Price\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    out_path = FIG_DIR / f\"{model_name}_{coin}_forecast.png\"\n",
    "    plt.savefig(out_path, dpi=240)\n",
    "    plt.close()\n",
    "    return out_path\n",
    "\n",
    "def save_residual_plot(dates, residuals, coin, model_name):\n",
    "    plt.figure(figsize=(11, 5))\n",
    "    plt.plot(dates, residuals, color=\"purple\")\n",
    "    plt.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "    plt.title(f\"{model_name} Residuals — {coin}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Residual (y_true - y_pred)\")\n",
    "    plt.tight_layout()\n",
    "    out_path = FIG_DIR / f\"{model_name}_{coin}_residuals.png\"\n",
    "    plt.savefig(out_path, dpi=240)\n",
    "    plt.close()\n",
    "    return out_path\n",
    "\n",
    "def save_predictions_csv(dates, actual, predicted, coin, model_name):\n",
    "    out = pd.DataFrame({\n",
    "        \"Date\": dates,\n",
    "        \"y_true\": actual,\n",
    "        \"y_pred\": predicted\n",
    "    })\n",
    "    out_path = PROCESSED_DIR / f\"predictions_{model_name.lower()}_{coin}.csv\"\n",
    "    out.to_csv(out_path, index=False)\n",
    "    return out_path\n",
    "\n",
    "\n",
    "# ---------- Prophet runner ----------\n",
    "def run_prophet_with_lags(sub_df, coin_name, regressors):\n",
    "    \"\"\"\n",
    "    sub_df: one-coin dataframe\n",
    "    regressors: lag + calendar features only (no leakage)\n",
    "    \"\"\"\n",
    "    cols = [\"Date\", \"Close\"] + regressors\n",
    "    sub = sub_df[cols].dropna().copy()\n",
    "\n",
    "    if len(sub) < 300:\n",
    "        print(f\" Skipping {coin_name}: not enough rows after dropping NaNs.\")\n",
    "        return None\n",
    "\n",
    "    # Time-based 80/20 split\n",
    "    split = int(len(sub) * 0.8)\n",
    "    train = sub.iloc[:split]\n",
    "    test  = sub.iloc[split:]\n",
    "\n",
    "    print(f\"Train interval: {train['Date'].iloc[0].date()} → {train['Date'].iloc[-1].date()} ({len(train)} rows)\")\n",
    "    print(f\"Test interval : {test['Date'].iloc[0].date()} → {test['Date'].iloc[-1].date()} ({len(test)} rows)\")\n",
    "\n",
    "    # Prepare Prophet dfs\n",
    "    def to_prophet(df_part):\n",
    "        tmp = df_part.rename(columns={\"Date\": \"ds\", \"Close\": \"y\"})\n",
    "        return tmp\n",
    "\n",
    "    train_p = to_prophet(train)\n",
    "    test_p  = to_prophet(test)\n",
    "\n",
    "    # Simple hyperparameter grid\n",
    "    cp_grid = [0.3, 0.8]      # changepoint_prior_scale\n",
    "    sp_grid = [5.0, 10.0]     # seasonality_prior_scale\n",
    "\n",
    "    best_cfg = None\n",
    "    best_rmse = np.inf\n",
    "\n",
    "    print(\" Tuning hyperparameters on train set (using last 20% as validation)...\")\n",
    "\n",
    "    # Split train into base_train + validation\n",
    "    n_train = len(train_p)\n",
    "    n_val = max(int(0.2 * n_train), 60)\n",
    "    base_train = train_p.iloc[:-n_val]\n",
    "    val = train_p.iloc[-n_val:]\n",
    "\n",
    "    base_train_X = base_train[[\"ds\"] + regressors]\n",
    "    val_X = val[[\"ds\"] + regressors]\n",
    "\n",
    "    for cp in cp_grid:\n",
    "        for sp in sp_grid:\n",
    "            m = Prophet(\n",
    "                seasonality_mode=\"multiplicative\",\n",
    "                changepoint_prior_scale=cp,\n",
    "                seasonality_prior_scale=sp,\n",
    "                changepoint_range=0.95,\n",
    "                weekly_seasonality=True,\n",
    "                yearly_seasonality=False,\n",
    "                daily_seasonality=True,\n",
    "            )\n",
    "\n",
    "            for r in regressors:\n",
    "                m.add_regressor(r)\n",
    "\n",
    "            m.fit(base_train)\n",
    "\n",
    "            val_future = val_X.copy()\n",
    "            val_forecast = m.predict(val_future)\n",
    "            y_val_pred = val_forecast[\"yhat\"].values\n",
    "            y_val_true = val[\"y\"].values\n",
    "\n",
    "            val_rmse = root_mean_squared_error(y_val_true, y_val_pred)\n",
    "            print(f\"   cp={cp}, sp={sp} → Val RMSE = {val_rmse:.2f}\")\n",
    "\n",
    "            if val_rmse < best_rmse:\n",
    "                best_rmse = val_rmse\n",
    "                best_cfg = (cp, sp)\n",
    "\n",
    "    cp_best, sp_best = best_cfg\n",
    "    print(f\" Best config for {coin_name}: cp={cp_best}, sp={sp_best} (Val RMSE={best_rmse:.2f})\")\n",
    "\n",
    "    # ---------- model on full train ----------\n",
    "    m_final = Prophet(\n",
    "        seasonality_mode=\"multiplicative\",\n",
    "        changepoint_prior_scale=cp_best,\n",
    "        seasonality_prior_scale=sp_best,\n",
    "        changepoint_range=0.95,\n",
    "        weekly_seasonality=True,\n",
    "        yearly_seasonality=False,\n",
    "        daily_seasonality=True,\n",
    "    )\n",
    "\n",
    "    for r in regressors:\n",
    "        m_final.add_regressor(r)\n",
    "\n",
    "    m_final.fit(train_p)\n",
    "\n",
    "    # Train metrics\n",
    "    train_future = train_p[[\"ds\"] + regressors]\n",
    "    train_forecast = m_final.predict(train_future)\n",
    "    y_train_pred = train_forecast[\"yhat\"].values\n",
    "    y_train_true = train_p[\"y\"].values\n",
    "\n",
    "    train_mae = mean_absolute_error(y_train_true, y_train_pred)\n",
    "    train_rmse = root_mean_squared_error(y_train_true, y_train_pred)\n",
    "    print(f\"  Train MAE  = {train_mae:.3f}\")\n",
    "    print(f\"  Train RMSE = {train_rmse:.3f}\")\n",
    "\n",
    "    # Test forecast\n",
    "    test_future = test_p[[\"ds\"] + regressors]\n",
    "    test_forecast = m_final.predict(test_future)\n",
    "    y_test_pred = test_forecast[\"yhat\"].values\n",
    "    y_test_true = test_p[\"y\"].values\n",
    "\n",
    "    test_mae = mean_absolute_error(y_test_true, y_test_pred)\n",
    "    test_rmse = root_mean_squared_error(y_test_true, y_test_pred)\n",
    "    print(f\" Test MAE   = {test_mae:.3f}\")\n",
    "    print(f\" Test RMSE  = {test_rmse:.3f}\")\n",
    "\n",
    "    # Save plots & CSV\n",
    "    forecast_plot = save_forecast_plot(\n",
    "        dates=test[\"Date\"].values,\n",
    "        actual=y_test_true,\n",
    "        predicted=y_test_pred,\n",
    "        coin=coin_name,\n",
    "        model_name=\"Prophet_LagReg\"\n",
    "    )\n",
    "\n",
    "    residuals = y_test_true - y_test_pred\n",
    "    residual_plot = save_residual_plot(\n",
    "        dates=test[\"Date\"].values,\n",
    "        residuals=residuals,\n",
    "        coin=coin_name,\n",
    "        model_name=\"Prophet_LagReg\"\n",
    "    )\n",
    "\n",
    "    pred_csv = save_predictions_csv(\n",
    "        dates=test[\"Date\"].values,\n",
    "        actual=y_test_true,\n",
    "        predicted=y_test_pred,\n",
    "        coin=coin_name,\n",
    "        model_name=\"Prophet_LagReg\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"Coin\": coin_name,\n",
    "        \"Model\": \"Prophet_LagReg\",\n",
    "        \"cp_best\": cp_best,\n",
    "        \"sp_best\": sp_best,\n",
    "        \"Val_RMSE\": best_rmse,\n",
    "        \"Train_MAE\": train_mae,\n",
    "        \"Train_RMSE\": train_rmse,\n",
    "        \"Test_MAE\": test_mae,\n",
    "        \"Test_RMSE\": test_rmse,\n",
    "        \"ForecastPlot\": str(forecast_plot),\n",
    "        \"ResidualPlot\": str(residual_plot),\n",
    "        \"PredCSV\": str(pred_csv),\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# RUN PROPHET WITH LAG REGRESSORS\n",
    "# ============================================================\n",
    "\n",
    "prophet_regressors = [\n",
    "    \"Close_lag1\", \"Close_lag7\", \"Close_lag14\", \"Close_lag30\",\n",
    "    \"Return_lag1\", \"Return_lag7\", \"Return_lag14\", \"Return_lag30\",\n",
    "    \"Volume_lag1\", \"Volume_lag7\", \"Volume_lag14\", \"Volume_lag30\",\n",
    "    \"DayOfWeek\", \"Month\"\n",
    "]\n",
    "\n",
    "results_prophet_lag = []\n",
    "\n",
    "print(\"\\n================= PROPHET (LAG REGRESSORS) START =================\\n\")\n",
    "\n",
    "for coin in df[\"Name\"].unique():\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    print(f\" Now Processing Coin: {coin.upper()}\")\n",
    "    print(\"----------------------------------------------------------\")\n",
    "\n",
    "    sub_coin = df[df[\"Name\"] == coin].copy()\n",
    "\n",
    "    try:\n",
    "        row = run_prophet_with_lags(sub_coin, coin, prophet_regressors)\n",
    "        if row is not None:\n",
    "            results_prophet_lag.append(row)\n",
    "    except Exception as e:\n",
    "        print(f\" !! Failed for {coin}: {e}\")\n",
    "\n",
    "print(\"\\n================= PROPHET (LAG REGRESSORS) FINISHED =================\\n\")\n",
    "\n",
    "if results_prophet_lag:\n",
    "    prophet_lag_df = pd.DataFrame(results_prophet_lag).sort_values(\"Test_RMSE\")\n",
    "    display(prophet_lag_df)\n",
    "else:\n",
    "    print(\"No Prophet results — something went wrong.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abb90663-f182-4f0a-918c-9d9d5957a8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (37082, 44)\n",
      "Columns: ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Name', 'Symbol', 'SourceFile', 'LogReturn', 'Return_%', 'Volatility_7d', 'Volatility_30d', 'Momentum_7d', 'Momentum_30d', 'RSI_14', 'EMA_12', 'EMA_26', 'MACD', 'MACD_Signal', 'EMA_10', 'EMA_20', 'EMA_50', 'BB_Upper', 'BB_Lower', 'BB_Width', 'High_Low_%', 'Close_Open_%', 'MarketPressure', 'Close_lag1', 'Volume_lag1', 'Return_lag1', 'Close_lag7', 'Volume_lag7', 'Return_lag7', 'Close_lag14', 'Volume_lag14', 'Return_lag14', 'Close_lag30', 'Volume_lag30', 'Return_lag30', 'DayOfWeek', 'Month', 'Quarter']\n",
      "\n",
      "Using feature columns:\n",
      "['Open', 'High', 'Low', 'Volume', 'LogReturn', 'Return_%', 'Volatility_7d', 'Volatility_30d', 'Momentum_7d', 'Momentum_30d', 'RSI_14', 'EMA_12', 'EMA_26', 'MACD', 'MACD_Signal', 'EMA_10', 'EMA_20', 'EMA_50', 'BB_Upper', 'BB_Lower', 'BB_Width', 'High_Low_%', 'Close_Open_%', 'MarketPressure', 'Close_lag1', 'Volume_lag1', 'Return_lag1', 'Close_lag7', 'Volume_lag7', 'Return_lag7', 'Close_lag14', 'Volume_lag14', 'Return_lag14', 'Close_lag30', 'Volume_lag30', 'Return_lag30', 'DayOfWeek', 'Month', 'Quarter']\n",
      "\n",
      "================= LSTM FORECASTING START =================\n",
      "\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: AAVE\n",
      "----------------------------------------------------------\n",
      " Skipping Aave: not enough rows.\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: BINANCE COIN\n",
      "----------------------------------------------------------\n",
      "• Train rows: 1009, Val: 216, Test: 217\n",
      "Training samples: 949, Validation samples: 156, Testing samples: 157\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ lstm (LSTM)                          │ (None, 60, 64)              │          26,624 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout (Dropout)                    │ (None, 60, 64)              │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ lstm_1 (LSTM)                        │ (None, 32)                  │          12,416 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_1 (Dropout)                  │ (None, 32)                  │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense (Dense)                        │ (None, 16)                  │             528 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_1 (Dense)                      │ (None, 1)                   │              17 │\n",
      "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
      " Total params: 39,585 (154.63 KB)\n",
      " Trainable params: 39,585 (154.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - loss: 0.1645 - mae: 0.3495 - val_loss: 0.3815 - val_mae: 0.6055\n",
      "Epoch 2/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.1515 - mae: 0.3279 - val_loss: 0.3475 - val_mae: 0.5767\n",
      "Epoch 3/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.1297 - mae: 0.3031 - val_loss: 0.3168 - val_mae: 0.5494\n",
      "Epoch 4/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.1148 - mae: 0.2802 - val_loss: 0.2887 - val_mae: 0.5232\n",
      "Epoch 5/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - loss: 0.1021 - mae: 0.2616 - val_loss: 0.2634 - val_mae: 0.4985\n",
      "Epoch 6/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - loss: 0.1036 - mae: 0.2582 - val_loss: 0.2405 - val_mae: 0.4749\n",
      "Epoch 7/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0882 - mae: 0.2323 - val_loss: 0.2209 - val_mae: 0.4539\n",
      "Epoch 8/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0681 - mae: 0.2013 - val_loss: 0.2030 - val_mae: 0.4337\n",
      "Epoch 9/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0700 - mae: 0.2067 - val_loss: 0.1866 - val_mae: 0.4144\n",
      "Epoch 10/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0642 - mae: 0.1923 - val_loss: 0.1723 - val_mae: 0.3968\n",
      "Epoch 11/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - loss: 0.0627 - mae: 0.1893 - val_loss: 0.1601 - val_mae: 0.3810\n",
      "Epoch 12/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0573 - mae: 0.1755 - val_loss: 0.1491 - val_mae: 0.3663\n",
      "Epoch 13/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0510 - mae: 0.1689 - val_loss: 0.1400 - val_mae: 0.3536\n",
      "Epoch 14/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - loss: 0.0518 - mae: 0.1719 - val_loss: 0.1316 - val_mae: 0.3417\n",
      "Epoch 15/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0482 - mae: 0.1654 - val_loss: 0.1242 - val_mae: 0.3306\n",
      "Epoch 16/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0519 - mae: 0.1710 - val_loss: 0.1184 - val_mae: 0.3216\n",
      "Epoch 17/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0462 - mae: 0.1600 - val_loss: 0.1128 - val_mae: 0.3129\n",
      "Epoch 18/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0459 - mae: 0.1637 - val_loss: 0.1081 - val_mae: 0.3053\n",
      "Epoch 19/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0402 - mae: 0.1517 - val_loss: 0.1046 - val_mae: 0.2995\n",
      "Epoch 20/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.0455 - mae: 0.1639 - val_loss: 0.1008 - val_mae: 0.2932\n",
      "Epoch 21/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0408 - mae: 0.1532 - val_loss: 0.0983 - val_mae: 0.2887\n",
      "Epoch 22/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - loss: 0.0434 - mae: 0.1584 - val_loss: 0.0962 - val_mae: 0.2851\n",
      "Epoch 23/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0456 - mae: 0.1655 - val_loss: 0.0941 - val_mae: 0.2814\n",
      "Epoch 24/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.0464 - mae: 0.1636 - val_loss: 0.0923 - val_mae: 0.2783\n",
      "Epoch 25/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0391 - mae: 0.1512 - val_loss: 0.0913 - val_mae: 0.2765\n",
      "Epoch 26/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - loss: 0.0443 - mae: 0.1597 - val_loss: 0.0899 - val_mae: 0.2739\n",
      "Epoch 27/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0433 - mae: 0.1588 - val_loss: 0.0892 - val_mae: 0.2726\n",
      "Epoch 28/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0408 - mae: 0.1546 - val_loss: 0.0884 - val_mae: 0.2711\n",
      "Epoch 29/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0436 - mae: 0.1611 - val_loss: 0.0878 - val_mae: 0.2699\n",
      "Epoch 30/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0435 - mae: 0.1604 - val_loss: 0.0874 - val_mae: 0.2692\n",
      "Epoch 31/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0439 - mae: 0.1610 - val_loss: 0.0869 - val_mae: 0.2683\n",
      "Epoch 32/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 66ms/step - loss: 0.0441 - mae: 0.1606 - val_loss: 0.0869 - val_mae: 0.2683\n",
      "Epoch 33/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0430 - mae: 0.1594 - val_loss: 0.0867 - val_mae: 0.2680\n",
      "Epoch 34/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.0448 - mae: 0.1646 - val_loss: 0.0861 - val_mae: 0.2668\n",
      "Epoch 35/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0473 - mae: 0.1669 - val_loss: 0.0856 - val_mae: 0.2658\n",
      "Epoch 36/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0420 - mae: 0.1575 - val_loss: 0.0863 - val_mae: 0.2672\n",
      "Epoch 37/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0431 - mae: 0.1596 - val_loss: 0.0858 - val_mae: 0.2662\n",
      "Epoch 38/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0447 - mae: 0.1628 - val_loss: 0.0861 - val_mae: 0.2668\n",
      "Epoch 39/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0424 - mae: 0.1593 - val_loss: 0.0856 - val_mae: 0.2659\n",
      "Epoch 40/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0450 - mae: 0.1637 - val_loss: 0.0857 - val_mae: 0.2660\n",
      "Epoch 41/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0448 - mae: 0.1632 - val_loss: 0.0853 - val_mae: 0.2653\n",
      "Epoch 42/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 0.0430 - mae: 0.1603 - val_loss: 0.0860 - val_mae: 0.2667\n",
      "Epoch 43/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0409 - mae: 0.1561 - val_loss: 0.0862 - val_mae: 0.2670\n",
      "Epoch 44/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0428 - mae: 0.1588 - val_loss: 0.0858 - val_mae: 0.2663\n",
      "Epoch 45/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0441 - mae: 0.1597 - val_loss: 0.0860 - val_mae: 0.2667\n",
      "Epoch 46/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0443 - mae: 0.1621 - val_loss: 0.0860 - val_mae: 0.2666\n",
      "Epoch 47/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0454 - mae: 0.1666 - val_loss: 0.0860 - val_mae: 0.2665\n",
      "Epoch 48/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.0438 - mae: 0.1598 - val_loss: 0.0859 - val_mae: 0.2664\n",
      "Epoch 49/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - loss: 0.0450 - mae: 0.1635 - val_loss: 0.0857 - val_mae: 0.2661\n",
      "Epoch 50/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - loss: 0.0419 - mae: 0.1591 - val_loss: 0.0856 - val_mae: 0.2658\n",
      "Epoch 51/100\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.0447 - mae: 0.1628 - val_loss: 0.0857 - val_mae: 0.2661\n",
      "Epoch 51: early stopping\n",
      "Restoring model weights from the end of the best epoch: 41.\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "   ✔ Train MAE  = 6.217\n",
      "   ✔ Train RMSE = 8.064\n",
      "   ✔ Test MAE   = 333.043\n",
      "   ✔ Test RMSE  = 366.816\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: BITCOIN\n",
      "----------------------------------------------------------\n",
      "• Train rows: 2093, Val: 448, Test: 450\n",
      "Training samples: 2033, Validation samples: 388, Testing samples: 390\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_1\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ lstm_2 (LSTM)                        │ (None, 60, 64)              │          26,624 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_2 (Dropout)                  │ (None, 60, 64)              │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ lstm_3 (LSTM)                        │ (None, 32)                  │          12,416 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_3 (Dropout)                  │ (None, 32)                  │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_2 (Dense)                      │ (None, 16)                  │             528 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_3 (Dense)                      │ (None, 1)                   │              17 │\n",
      "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
      " Total params: 39,585 (154.63 KB)\n",
      " Trainable params: 39,585 (154.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 61ms/step - loss: 0.0410 - mae: 0.1093 - val_loss: 0.1447 - val_mae: 0.3676\n",
      "Epoch 2/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 0.0326 - mae: 0.1141 - val_loss: 0.1193 - val_mae: 0.3313\n",
      "Epoch 3/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - loss: 0.0322 - mae: 0.1273 - val_loss: 0.1084 - val_mae: 0.3144\n",
      "Epoch 4/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 0.0298 - mae: 0.1319 - val_loss: 0.1050 - val_mae: 0.3089\n",
      "Epoch 5/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.0304 - mae: 0.1339 - val_loss: 0.1040 - val_mae: 0.3072\n",
      "Epoch 6/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - loss: 0.0306 - mae: 0.1344 - val_loss: 0.1031 - val_mae: 0.3058\n",
      "Epoch 7/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0322 - mae: 0.1390 - val_loss: 0.1034 - val_mae: 0.3063\n",
      "Epoch 8/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0325 - mae: 0.1384 - val_loss: 0.1047 - val_mae: 0.3085\n",
      "Epoch 9/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - loss: 0.0323 - mae: 0.1360 - val_loss: 0.1038 - val_mae: 0.3070\n",
      "Epoch 10/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - loss: 0.0292 - mae: 0.1339 - val_loss: 0.1036 - val_mae: 0.3066\n",
      "Epoch 11/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 0.0297 - mae: 0.1331 - val_loss: 0.1017 - val_mae: 0.3035\n",
      "Epoch 12/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - loss: 0.0310 - mae: 0.1348 - val_loss: 0.1030 - val_mae: 0.3057\n",
      "Epoch 13/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - loss: 0.0318 - mae: 0.1375 - val_loss: 0.1020 - val_mae: 0.3041\n",
      "Epoch 14/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - loss: 0.0298 - mae: 0.1341 - val_loss: 0.1028 - val_mae: 0.3054\n",
      "Epoch 15/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - loss: 0.0337 - mae: 0.1411 - val_loss: 0.1036 - val_mae: 0.3067\n",
      "Epoch 16/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - loss: 0.0277 - mae: 0.1296 - val_loss: 0.1015 - val_mae: 0.3032\n",
      "Epoch 17/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 0.0319 - mae: 0.1386 - val_loss: 0.1026 - val_mae: 0.3050\n",
      "Epoch 18/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 0.0331 - mae: 0.1401 - val_loss: 0.1037 - val_mae: 0.3068\n",
      "Epoch 19/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - loss: 0.0294 - mae: 0.1327 - val_loss: 0.1032 - val_mae: 0.3060\n",
      "Epoch 20/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - loss: 0.0297 - mae: 0.1339 - val_loss: 0.1022 - val_mae: 0.3044\n",
      "Epoch 21/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0317 - mae: 0.1374 - val_loss: 0.1030 - val_mae: 0.3057\n",
      "Epoch 22/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - loss: 0.0327 - mae: 0.1364 - val_loss: 0.1033 - val_mae: 0.3061\n",
      "Epoch 23/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - loss: 0.0302 - mae: 0.1344 - val_loss: 0.1019 - val_mae: 0.3038\n",
      "Epoch 24/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 0.0303 - mae: 0.1337 - val_loss: 0.1024 - val_mae: 0.3047\n",
      "Epoch 25/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.0326 - mae: 0.1386 - val_loss: 0.1027 - val_mae: 0.3052\n",
      "Epoch 26/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - loss: 0.0314 - mae: 0.1357 - val_loss: 0.1036 - val_mae: 0.3067\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "   ✔ Train MAE  = 2662.419\n",
      "   ✔ Train RMSE = 3431.607\n",
      "   ✔ Test MAE   = 26329.526\n",
      "   ✔ Test RMSE  = 31802.515\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: CARDANO\n",
      "----------------------------------------------------------\n",
      "• Train rows: 961, Val: 206, Test: 207\n",
      "Training samples: 901, Validation samples: 146, Testing samples: 147\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_2\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ lstm_4 (LSTM)                        │ (None, 60, 64)              │          26,624 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_4 (Dropout)                  │ (None, 60, 64)              │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ lstm_5 (LSTM)                        │ (None, 32)                  │          12,416 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_5 (Dropout)                  │ (None, 32)                  │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_4 (Dense)                      │ (None, 16)                  │             528 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_5 (Dense)                      │ (None, 1)                   │              17 │\n",
      "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
      " Total params: 39,585 (154.63 KB)\n",
      " Trainable params: 39,585 (154.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - loss: 0.0368 - mae: 0.1042 - val_loss: 0.0045 - val_mae: 0.0642\n",
      "Epoch 2/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.0278 - mae: 0.0798 - val_loss: 0.0022 - val_mae: 0.0420\n",
      "Epoch 3/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0263 - mae: 0.0767 - val_loss: 0.0010 - val_mae: 0.0252\n",
      "Epoch 4/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0235 - mae: 0.0799 - val_loss: 5.7227e-04 - val_mae: 0.0179\n",
      "Epoch 5/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - loss: 0.0223 - mae: 0.0852 - val_loss: 4.3101e-04 - val_mae: 0.0177\n",
      "Epoch 6/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.0180 - mae: 0.0842 - val_loss: 4.2456e-04 - val_mae: 0.0182\n",
      "Epoch 7/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0205 - mae: 0.0884 - val_loss: 4.4554e-04 - val_mae: 0.0189\n",
      "Epoch 8/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0174 - mae: 0.0848 - val_loss: 4.6103e-04 - val_mae: 0.0193\n",
      "Epoch 9/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0232 - mae: 0.0954 - val_loss: 4.8673e-04 - val_mae: 0.0198\n",
      "Epoch 10/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0242 - mae: 0.0973 - val_loss: 4.7048e-04 - val_mae: 0.0195\n",
      "Epoch 11/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0215 - mae: 0.0936 - val_loss: 4.7158e-04 - val_mae: 0.0195\n",
      "Epoch 12/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - loss: 0.0190 - mae: 0.0893 - val_loss: 4.5257e-04 - val_mae: 0.0191\n",
      "Epoch 13/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.0167 - mae: 0.0849 - val_loss: 4.8565e-04 - val_mae: 0.0198\n",
      "Epoch 14/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 0.0217 - mae: 0.0938 - val_loss: 4.9792e-04 - val_mae: 0.0201\n",
      "Epoch 15/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0231 - mae: 0.0952 - val_loss: 4.8685e-04 - val_mae: 0.0198\n",
      "Epoch 16/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0185 - mae: 0.0877 - val_loss: 4.5571e-04 - val_mae: 0.0191\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "   ✔ Train MAE  = 0.097\n",
      "   ✔ Train RMSE = 0.156\n",
      "   ✔ Test MAE   = 1.225\n",
      "   ✔ Test RMSE  = 1.254\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: CHAINLINK\n",
      "----------------------------------------------------------\n",
      "• Train rows: 969, Val: 207, Test: 209\n",
      "Training samples: 909, Validation samples: 147, Testing samples: 149\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_3\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ lstm_6 (LSTM)                        │ (None, 60, 64)              │          26,624 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_6 (Dropout)                  │ (None, 60, 64)              │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ lstm_7 (LSTM)                        │ (None, 32)                  │          12,416 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_7 (Dropout)                  │ (None, 32)                  │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_6 (Dense)                      │ (None, 16)                  │             528 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_7 (Dense)                      │ (None, 1)                   │              17 │\n",
      "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
      " Total params: 39,585 (154.63 KB)\n",
      " Trainable params: 39,585 (154.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 88ms/step - loss: 0.1322 - mae: 0.2559 - val_loss: 6.6694 - val_mae: 2.5179\n",
      "Epoch 2/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.1070 - mae: 0.2117 - val_loss: 6.5363 - val_mae: 2.4913\n",
      "Epoch 3/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.1039 - mae: 0.2119 - val_loss: 6.4114 - val_mae: 2.4661\n",
      "Epoch 4/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0923 - mae: 0.1967 - val_loss: 6.2986 - val_mae: 2.4431\n",
      "Epoch 5/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0859 - mae: 0.2023 - val_loss: 6.1968 - val_mae: 2.4222\n",
      "Epoch 6/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0775 - mae: 0.1990 - val_loss: 6.1079 - val_mae: 2.4038\n",
      "Epoch 7/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0770 - mae: 0.2069 - val_loss: 6.0240 - val_mae: 2.3863\n",
      "Epoch 8/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0767 - mae: 0.2110 - val_loss: 5.9563 - val_mae: 2.3720\n",
      "Epoch 9/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0754 - mae: 0.2155 - val_loss: 5.8966 - val_mae: 2.3594\n",
      "Epoch 10/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - loss: 0.0660 - mae: 0.2083 - val_loss: 5.8428 - val_mae: 2.3480\n",
      "Epoch 11/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0613 - mae: 0.2035 - val_loss: 5.7984 - val_mae: 2.3385\n",
      "Epoch 12/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0703 - mae: 0.2185 - val_loss: 5.7533 - val_mae: 2.3289\n",
      "Epoch 13/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0632 - mae: 0.2130 - val_loss: 5.7184 - val_mae: 2.3214\n",
      "Epoch 14/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0646 - mae: 0.2169 - val_loss: 5.6911 - val_mae: 2.3155\n",
      "Epoch 15/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0666 - mae: 0.2206 - val_loss: 5.6723 - val_mae: 2.3114\n",
      "Epoch 16/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0697 - mae: 0.2263 - val_loss: 5.6593 - val_mae: 2.3086\n",
      "Epoch 17/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0648 - mae: 0.2178 - val_loss: 5.6498 - val_mae: 2.3065\n",
      "Epoch 18/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.0633 - mae: 0.2176 - val_loss: 5.6382 - val_mae: 2.3040\n",
      "Epoch 19/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0651 - mae: 0.2223 - val_loss: 5.6353 - val_mae: 2.3034\n",
      "Epoch 20/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0656 - mae: 0.2223 - val_loss: 5.6197 - val_mae: 2.3000\n",
      "Epoch 21/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - loss: 0.0704 - mae: 0.2281 - val_loss: 5.6169 - val_mae: 2.2994\n",
      "Epoch 22/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.0657 - mae: 0.2250 - val_loss: 5.6192 - val_mae: 2.2999\n",
      "Epoch 23/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0689 - mae: 0.2283 - val_loss: 5.6135 - val_mae: 2.2987\n",
      "Epoch 24/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - loss: 0.0658 - mae: 0.2237 - val_loss: 5.6115 - val_mae: 2.2982\n",
      "Epoch 25/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - loss: 0.0654 - mae: 0.2245 - val_loss: 5.6107 - val_mae: 2.2980\n",
      "Epoch 26/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0658 - mae: 0.2256 - val_loss: 5.6068 - val_mae: 2.2972\n",
      "Epoch 27/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.0679 - mae: 0.2279 - val_loss: 5.6025 - val_mae: 2.2962\n",
      "Epoch 28/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.0659 - mae: 0.2233 - val_loss: 5.6144 - val_mae: 2.2988\n",
      "Epoch 29/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0695 - mae: 0.2299 - val_loss: 5.6055 - val_mae: 2.2969\n",
      "Epoch 30/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0609 - mae: 0.2187 - val_loss: 5.6133 - val_mae: 2.2986\n",
      "Epoch 31/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0655 - mae: 0.2244 - val_loss: 5.6040 - val_mae: 2.2966\n",
      "Epoch 32/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0636 - mae: 0.2214 - val_loss: 5.6075 - val_mae: 2.2973\n",
      "Epoch 33/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - loss: 0.0630 - mae: 0.2208 - val_loss: 5.6131 - val_mae: 2.2986\n",
      "Epoch 34/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0693 - mae: 0.2298 - val_loss: 5.6046 - val_mae: 2.2967\n",
      "Epoch 35/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - loss: 0.0672 - mae: 0.2269 - val_loss: 5.6006 - val_mae: 2.2958\n",
      "Epoch 36/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0660 - mae: 0.2246 - val_loss: 5.6129 - val_mae: 2.2985\n",
      "Epoch 37/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - loss: 0.0632 - mae: 0.2195 - val_loss: 5.6157 - val_mae: 2.2991\n",
      "Epoch 38/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - loss: 0.0602 - mae: 0.2161 - val_loss: 5.6148 - val_mae: 2.2989\n",
      "Epoch 39/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.0634 - mae: 0.2200 - val_loss: 5.6139 - val_mae: 2.2987\n",
      "Epoch 40/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - loss: 0.0652 - mae: 0.2225 - val_loss: 5.6098 - val_mae: 2.2978\n",
      "Epoch 41/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0588 - mae: 0.2144 - val_loss: 5.6179 - val_mae: 2.2996\n",
      "Epoch 42/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0651 - mae: 0.2235 - val_loss: 5.6040 - val_mae: 2.2966\n",
      "Epoch 43/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - loss: 0.0620 - mae: 0.2187 - val_loss: 5.6066 - val_mae: 2.2971\n",
      "Epoch 44/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0630 - mae: 0.2222 - val_loss: 5.5981 - val_mae: 2.2953\n",
      "Epoch 45/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0643 - mae: 0.2218 - val_loss: 5.6041 - val_mae: 2.2966\n",
      "Epoch 46/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - loss: 0.0666 - mae: 0.2258 - val_loss: 5.6034 - val_mae: 2.2965\n",
      "Epoch 47/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - loss: 0.0652 - mae: 0.2227 - val_loss: 5.6090 - val_mae: 2.2977\n",
      "Epoch 48/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0650 - mae: 0.2243 - val_loss: 5.6135 - val_mae: 2.2987\n",
      "Epoch 49/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.0670 - mae: 0.2253 - val_loss: 5.6128 - val_mae: 2.2985\n",
      "Epoch 50/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - loss: 0.0591 - mae: 0.2153 - val_loss: 5.6117 - val_mae: 2.2982\n",
      "Epoch 51/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0674 - mae: 0.2260 - val_loss: 5.6025 - val_mae: 2.2962\n",
      "Epoch 52/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - loss: 0.0649 - mae: 0.2223 - val_loss: 5.6024 - val_mae: 2.2962\n",
      "Epoch 53/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0608 - mae: 0.2188 - val_loss: 5.6103 - val_mae: 2.2979\n",
      "Epoch 54/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0637 - mae: 0.2225 - val_loss: 5.6044 - val_mae: 2.2967\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "   ✔ Train MAE  = 1.027\n",
      "   ✔ Train RMSE = 1.170\n",
      "   ✔ Test MAE   = 29.043\n",
      "   ✔ Test RMSE  = 30.046\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: COSMOS\n",
      "----------------------------------------------------------\n",
      "• Train rows: 591, Val: 126, Test: 128\n",
      "Training samples: 531, Validation samples: 66, Testing samples: 68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_4\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ lstm_8 (LSTM)                        │ (None, 60, 64)              │          26,624 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_8 (Dropout)                  │ (None, 60, 64)              │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ lstm_9 (LSTM)                        │ (None, 32)                  │          12,416 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_9 (Dropout)                  │ (None, 32)                  │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_8 (Dense)                      │ (None, 16)                  │             528 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_9 (Dense)                      │ (None, 1)                   │              17 │\n",
      "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
      " Total params: 39,585 (154.63 KB)\n",
      " Trainable params: 39,585 (154.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 127ms/step - loss: 0.1387 - mae: 0.3231 - val_loss: 2.7981 - val_mae: 1.4065\n",
      "Epoch 2/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.1298 - mae: 0.3070 - val_loss: 2.7516 - val_mae: 1.3899\n",
      "Epoch 3/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.1311 - mae: 0.3015 - val_loss: 2.7069 - val_mae: 1.3737\n",
      "Epoch 4/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.1049 - mae: 0.2691 - val_loss: 2.6640 - val_mae: 1.3580\n",
      "Epoch 5/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.1012 - mae: 0.2601 - val_loss: 2.6226 - val_mae: 1.3427\n",
      "Epoch 6/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0966 - mae: 0.2526 - val_loss: 2.5827 - val_mae: 1.3277\n",
      "Epoch 7/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0925 - mae: 0.2395 - val_loss: 2.5447 - val_mae: 1.3133\n",
      "Epoch 8/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0805 - mae: 0.2178 - val_loss: 2.5091 - val_mae: 1.2997\n",
      "Epoch 9/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0705 - mae: 0.2019 - val_loss: 2.4754 - val_mae: 1.2867\n",
      "Epoch 10/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0740 - mae: 0.2052 - val_loss: 2.4428 - val_mae: 1.2739\n",
      "Epoch 11/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0680 - mae: 0.1964 - val_loss: 2.4115 - val_mae: 1.2616\n",
      "Epoch 12/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0620 - mae: 0.1867 - val_loss: 2.3825 - val_mae: 1.2501\n",
      "Epoch 13/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0662 - mae: 0.1942 - val_loss: 2.3542 - val_mae: 1.2387\n",
      "Epoch 14/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0540 - mae: 0.1754 - val_loss: 2.3280 - val_mae: 1.2281\n",
      "Epoch 15/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0549 - mae: 0.1786 - val_loss: 2.3032 - val_mae: 1.2179\n",
      "Epoch 16/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0516 - mae: 0.1735 - val_loss: 2.2796 - val_mae: 1.2082\n",
      "Epoch 17/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0468 - mae: 0.1664 - val_loss: 2.2590 - val_mae: 1.1996\n",
      "Epoch 18/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0473 - mae: 0.1701 - val_loss: 2.2384 - val_mae: 1.1910\n",
      "Epoch 19/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0487 - mae: 0.1703 - val_loss: 2.2183 - val_mae: 1.1826\n",
      "Epoch 20/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0427 - mae: 0.1617 - val_loss: 2.2012 - val_mae: 1.1753\n",
      "Epoch 21/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0438 - mae: 0.1656 - val_loss: 2.1856 - val_mae: 1.1686\n",
      "Epoch 22/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0380 - mae: 0.1546 - val_loss: 2.1702 - val_mae: 1.1620\n",
      "Epoch 23/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0410 - mae: 0.1590 - val_loss: 2.1557 - val_mae: 1.1558\n",
      "Epoch 24/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0386 - mae: 0.1581 - val_loss: 2.1423 - val_mae: 1.1500\n",
      "Epoch 25/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0367 - mae: 0.1521 - val_loss: 2.1312 - val_mae: 1.1451\n",
      "Epoch 26/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.0398 - mae: 0.1594 - val_loss: 2.1196 - val_mae: 1.1401\n",
      "Epoch 27/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0393 - mae: 0.1570 - val_loss: 2.1085 - val_mae: 1.1352\n",
      "Epoch 28/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0414 - mae: 0.1609 - val_loss: 2.0990 - val_mae: 1.1310\n",
      "Epoch 29/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0413 - mae: 0.1611 - val_loss: 2.0907 - val_mae: 1.1273\n",
      "Epoch 30/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0398 - mae: 0.1579 - val_loss: 2.0828 - val_mae: 1.1238\n",
      "Epoch 31/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0326 - mae: 0.1456 - val_loss: 2.0765 - val_mae: 1.1210\n",
      "Epoch 32/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0372 - mae: 0.1544 - val_loss: 2.0701 - val_mae: 1.1182\n",
      "Epoch 33/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0388 - mae: 0.1600 - val_loss: 2.0639 - val_mae: 1.1154\n",
      "Epoch 34/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0391 - mae: 0.1563 - val_loss: 2.0600 - val_mae: 1.1136\n",
      "Epoch 35/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0359 - mae: 0.1544 - val_loss: 2.0549 - val_mae: 1.1113\n",
      "Epoch 36/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0355 - mae: 0.1515 - val_loss: 2.0506 - val_mae: 1.1094\n",
      "Epoch 37/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0342 - mae: 0.1507 - val_loss: 2.0473 - val_mae: 1.1079\n",
      "Epoch 38/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0358 - mae: 0.1526 - val_loss: 2.0431 - val_mae: 1.1060\n",
      "Epoch 39/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0360 - mae: 0.1517 - val_loss: 2.0404 - val_mae: 1.1048\n",
      "Epoch 40/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0371 - mae: 0.1536 - val_loss: 2.0372 - val_mae: 1.1033\n",
      "Epoch 41/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0395 - mae: 0.1610 - val_loss: 2.0358 - val_mae: 1.1027\n",
      "Epoch 42/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0367 - mae: 0.1545 - val_loss: 2.0334 - val_mae: 1.1016\n",
      "Epoch 43/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0349 - mae: 0.1539 - val_loss: 2.0322 - val_mae: 1.1011\n",
      "Epoch 44/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0352 - mae: 0.1513 - val_loss: 2.0309 - val_mae: 1.1005\n",
      "Epoch 45/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0352 - mae: 0.1539 - val_loss: 2.0300 - val_mae: 1.1001\n",
      "Epoch 46/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.0372 - mae: 0.1554 - val_loss: 2.0286 - val_mae: 1.0994\n",
      "Epoch 47/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0375 - mae: 0.1588 - val_loss: 2.0257 - val_mae: 1.0981\n",
      "Epoch 48/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0343 - mae: 0.1516 - val_loss: 2.0256 - val_mae: 1.0981\n",
      "Epoch 49/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0359 - mae: 0.1528 - val_loss: 2.0253 - val_mae: 1.0979\n",
      "Epoch 50/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0366 - mae: 0.1561 - val_loss: 2.0242 - val_mae: 1.0974\n",
      "Epoch 51/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0373 - mae: 0.1571 - val_loss: 2.0231 - val_mae: 1.0969\n",
      "Epoch 52/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0348 - mae: 0.1501 - val_loss: 2.0221 - val_mae: 1.0965\n",
      "Epoch 53/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0345 - mae: 0.1505 - val_loss: 2.0222 - val_mae: 1.0965\n",
      "Epoch 54/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0368 - mae: 0.1548 - val_loss: 2.0214 - val_mae: 1.0962\n",
      "Epoch 55/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0361 - mae: 0.1541 - val_loss: 2.0222 - val_mae: 1.0965\n",
      "Epoch 56/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0348 - mae: 0.1494 - val_loss: 2.0220 - val_mae: 1.0964\n",
      "Epoch 57/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0371 - mae: 0.1561 - val_loss: 2.0210 - val_mae: 1.0960\n",
      "Epoch 58/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - loss: 0.0374 - mae: 0.1583 - val_loss: 2.0206 - val_mae: 1.0958\n",
      "Epoch 59/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0375 - mae: 0.1578 - val_loss: 2.0206 - val_mae: 1.0958\n",
      "Epoch 60/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0377 - mae: 0.1556 - val_loss: 2.0211 - val_mae: 1.0960\n",
      "Epoch 61/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0359 - mae: 0.1548 - val_loss: 2.0209 - val_mae: 1.0959\n",
      "Epoch 62/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0334 - mae: 0.1474 - val_loss: 2.0205 - val_mae: 1.0957\n",
      "Epoch 63/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0367 - mae: 0.1529 - val_loss: 2.0202 - val_mae: 1.0956\n",
      "Epoch 64/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0358 - mae: 0.1527 - val_loss: 2.0203 - val_mae: 1.0956\n",
      "Epoch 65/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0364 - mae: 0.1541 - val_loss: 2.0215 - val_mae: 1.0962\n",
      "Epoch 66/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0346 - mae: 0.1532 - val_loss: 2.0214 - val_mae: 1.0962\n",
      "Epoch 67/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0374 - mae: 0.1545 - val_loss: 2.0207 - val_mae: 1.0958\n",
      "Epoch 68/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0349 - mae: 0.1515 - val_loss: 2.0195 - val_mae: 1.0953\n",
      "Epoch 69/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0335 - mae: 0.1484 - val_loss: 2.0196 - val_mae: 1.0953\n",
      "Epoch 70/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0372 - mae: 0.1568 - val_loss: 2.0205 - val_mae: 1.0957\n",
      "Epoch 71/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0365 - mae: 0.1554 - val_loss: 2.0213 - val_mae: 1.0961\n",
      "Epoch 72/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0381 - mae: 0.1556 - val_loss: 2.0203 - val_mae: 1.0957\n",
      "Epoch 73/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0403 - mae: 0.1641 - val_loss: 2.0197 - val_mae: 1.0954\n",
      "Epoch 74/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0377 - mae: 0.1592 - val_loss: 2.0209 - val_mae: 1.0959\n",
      "Epoch 75/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0361 - mae: 0.1543 - val_loss: 2.0215 - val_mae: 1.0962\n",
      "Epoch 76/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0338 - mae: 0.1494 - val_loss: 2.0208 - val_mae: 1.0959\n",
      "Epoch 77/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0368 - mae: 0.1578 - val_loss: 2.0210 - val_mae: 1.0960\n",
      "Epoch 78/100\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0369 - mae: 0.1537 - val_loss: 2.0208 - val_mae: 1.0959\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "   ✔ Train MAE  = 1.062\n",
      "   ✔ Train RMSE = 1.312\n",
      "   ✔ Test MAE   = 12.142\n",
      "   ✔ Test RMSE  = 13.414\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: CRYPTO.COM COIN\n",
      "----------------------------------------------------------\n",
      "• Train rows: 654, Val: 140, Test: 141\n",
      "Training samples: 594, Validation samples: 80, Testing samples: 81\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_5\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ lstm_10 (LSTM)                       │ (None, 60, 64)              │          26,624 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_10 (Dropout)                 │ (None, 60, 64)              │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ lstm_11 (LSTM)                       │ (None, 32)                  │          12,416 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_11 (Dropout)                 │ (None, 32)                  │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_10 (Dense)                     │ (None, 16)                  │             528 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_11 (Dense)                     │ (None, 1)                   │              17 │\n",
      "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
      " Total params: 39,585 (154.63 KB)\n",
      " Trainable params: 39,585 (154.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 114ms/step - loss: 0.1662 - mae: 0.3192 - val_loss: 0.1019 - val_mae: 0.3151\n",
      "Epoch 2/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.1618 - mae: 0.3125 - val_loss: 0.0906 - val_mae: 0.2967\n",
      "Epoch 3/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.1518 - mae: 0.3008 - val_loss: 0.0802 - val_mae: 0.2785\n",
      "Epoch 4/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.1463 - mae: 0.2866 - val_loss: 0.0706 - val_mae: 0.2608\n",
      "Epoch 5/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.1267 - mae: 0.2576 - val_loss: 0.0622 - val_mae: 0.2440\n",
      "Epoch 6/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.1193 - mae: 0.2460 - val_loss: 0.0545 - val_mae: 0.2278\n",
      "Epoch 7/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.1213 - mae: 0.2448 - val_loss: 0.0475 - val_mae: 0.2118\n",
      "Epoch 8/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.1154 - mae: 0.2320 - val_loss: 0.0414 - val_mae: 0.1968\n",
      "Epoch 9/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.1030 - mae: 0.2140 - val_loss: 0.0359 - val_mae: 0.1824\n",
      "Epoch 10/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.1032 - mae: 0.2126 - val_loss: 0.0311 - val_mae: 0.1686\n",
      "Epoch 11/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0939 - mae: 0.2011 - val_loss: 0.0268 - val_mae: 0.1555\n",
      "Epoch 12/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0933 - mae: 0.2012 - val_loss: 0.0230 - val_mae: 0.1428\n",
      "Epoch 13/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - loss: 0.0903 - mae: 0.1987 - val_loss: 0.0198 - val_mae: 0.1310\n",
      "Epoch 14/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0861 - mae: 0.1966 - val_loss: 0.0170 - val_mae: 0.1199\n",
      "Epoch 15/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.0750 - mae: 0.1802 - val_loss: 0.0146 - val_mae: 0.1092\n",
      "Epoch 16/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0731 - mae: 0.1800 - val_loss: 0.0125 - val_mae: 0.0993\n",
      "Epoch 17/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.0685 - mae: 0.1723 - val_loss: 0.0107 - val_mae: 0.0899\n",
      "Epoch 18/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0748 - mae: 0.1817 - val_loss: 0.0092 - val_mae: 0.0810\n",
      "Epoch 19/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0788 - mae: 0.1915 - val_loss: 0.0079 - val_mae: 0.0728\n",
      "Epoch 20/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0736 - mae: 0.1879 - val_loss: 0.0069 - val_mae: 0.0656\n",
      "Epoch 21/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.0740 - mae: 0.1850 - val_loss: 0.0060 - val_mae: 0.0589\n",
      "Epoch 22/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0693 - mae: 0.1848 - val_loss: 0.0053 - val_mae: 0.0539\n",
      "Epoch 23/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0667 - mae: 0.1813 - val_loss: 0.0047 - val_mae: 0.0500\n",
      "Epoch 24/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0672 - mae: 0.1826 - val_loss: 0.0043 - val_mae: 0.0474\n",
      "Epoch 25/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.0677 - mae: 0.1850 - val_loss: 0.0039 - val_mae: 0.0451\n",
      "Epoch 26/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0680 - mae: 0.1877 - val_loss: 0.0036 - val_mae: 0.0432\n",
      "Epoch 27/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.0661 - mae: 0.1845 - val_loss: 0.0033 - val_mae: 0.0418\n",
      "Epoch 28/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.0623 - mae: 0.1803 - val_loss: 0.0032 - val_mae: 0.0407\n",
      "Epoch 29/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0660 - mae: 0.1877 - val_loss: 0.0030 - val_mae: 0.0397\n",
      "Epoch 30/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0617 - mae: 0.1805 - val_loss: 0.0029 - val_mae: 0.0393\n",
      "Epoch 31/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0669 - mae: 0.1919 - val_loss: 0.0028 - val_mae: 0.0391\n",
      "Epoch 32/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0604 - mae: 0.1801 - val_loss: 0.0027 - val_mae: 0.0392\n",
      "Epoch 33/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0682 - mae: 0.1978 - val_loss: 0.0027 - val_mae: 0.0394\n",
      "Epoch 34/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0636 - mae: 0.1868 - val_loss: 0.0027 - val_mae: 0.0397\n",
      "Epoch 35/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0645 - mae: 0.1902 - val_loss: 0.0027 - val_mae: 0.0400\n",
      "Epoch 36/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0655 - mae: 0.1943 - val_loss: 0.0026 - val_mae: 0.0404\n",
      "Epoch 37/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0673 - mae: 0.1952 - val_loss: 0.0026 - val_mae: 0.0409\n",
      "Epoch 38/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.0683 - mae: 0.1995 - val_loss: 0.0026 - val_mae: 0.0410\n",
      "Epoch 39/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0628 - mae: 0.1865 - val_loss: 0.0026 - val_mae: 0.0413\n",
      "Epoch 40/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0692 - mae: 0.1995 - val_loss: 0.0026 - val_mae: 0.0418\n",
      "Epoch 41/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0589 - mae: 0.1812 - val_loss: 0.0026 - val_mae: 0.0417\n",
      "Epoch 42/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0643 - mae: 0.1923 - val_loss: 0.0026 - val_mae: 0.0420\n",
      "Epoch 43/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0696 - mae: 0.2029 - val_loss: 0.0026 - val_mae: 0.0423\n",
      "Epoch 44/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0614 - mae: 0.1881 - val_loss: 0.0027 - val_mae: 0.0424\n",
      "Epoch 45/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0636 - mae: 0.1948 - val_loss: 0.0027 - val_mae: 0.0425\n",
      "Epoch 46/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - loss: 0.0665 - mae: 0.1993 - val_loss: 0.0027 - val_mae: 0.0426\n",
      "Epoch 47/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0640 - mae: 0.1882 - val_loss: 0.0027 - val_mae: 0.0428\n",
      "Epoch 48/100\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0657 - mae: 0.1982 - val_loss: 0.0027 - val_mae: 0.0428\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "   ✔ Train MAE  = 0.032\n",
      "   ✔ Train RMSE = 0.043\n",
      "   ✔ Test MAE   = 0.072\n",
      "   ✔ Test RMSE  = 0.080\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: DOGECOIN\n",
      "----------------------------------------------------------\n",
      "• Train rows: 1931, Val: 414, Test: 415\n",
      "Training samples: 1871, Validation samples: 354, Testing samples: 355\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_6\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ lstm_12 (LSTM)                       │ (None, 60, 64)              │          26,624 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_12 (Dropout)                 │ (None, 60, 64)              │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ lstm_13 (LSTM)                       │ (None, 32)                  │          12,416 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_13 (Dropout)                 │ (None, 32)                  │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_12 (Dense)                     │ (None, 16)                  │             528 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_13 (Dense)                     │ (None, 1)                   │              17 │\n",
      "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
      " Total params: 39,585 (154.63 KB)\n",
      " Trainable params: 39,585 (154.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 73ms/step - loss: 0.0269 - mae: 0.0906 - val_loss: 0.0111 - val_mae: 0.1021\n",
      "Epoch 2/100\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - loss: 0.0122 - mae: 0.0727 - val_loss: 0.0066 - val_mae: 0.0774\n",
      "Epoch 3/100\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - loss: 0.0154 - mae: 0.0859 - val_loss: 0.0054 - val_mae: 0.0688\n",
      "Epoch 4/100\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - loss: 0.0149 - mae: 0.0861 - val_loss: 0.0052 - val_mae: 0.0678\n",
      "Epoch 5/100\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 0.0158 - mae: 0.0891 - val_loss: 0.0054 - val_mae: 0.0688\n",
      "Epoch 6/100\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - loss: 0.0131 - mae: 0.0838 - val_loss: 0.0051 - val_mae: 0.0668\n",
      "Epoch 7/100\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - loss: 0.0146 - mae: 0.0870 - val_loss: 0.0050 - val_mae: 0.0660\n",
      "Epoch 8/100\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - loss: 0.0157 - mae: 0.0890 - val_loss: 0.0053 - val_mae: 0.0682\n",
      "Epoch 9/100\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - loss: 0.0135 - mae: 0.0856 - val_loss: 0.0053 - val_mae: 0.0682\n",
      "Epoch 10/100\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0129 - mae: 0.0836 - val_loss: 0.0049 - val_mae: 0.0649\n",
      "Epoch 11/100\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0150 - mae: 0.0886 - val_loss: 0.0051 - val_mae: 0.0665\n",
      "Epoch 12/100\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0130 - mae: 0.0848 - val_loss: 0.0051 - val_mae: 0.0665\n",
      "Epoch 13/100\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.0135 - mae: 0.0872 - val_loss: 0.0051 - val_mae: 0.0667\n",
      "Epoch 14/100\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 0.0129 - mae: 0.0836 - val_loss: 0.0052 - val_mae: 0.0674\n",
      "Epoch 15/100\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.0136 - mae: 0.0864 - val_loss: 0.0051 - val_mae: 0.0667\n",
      "Epoch 16/100\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 0.0141 - mae: 0.0884 - val_loss: 0.0051 - val_mae: 0.0665\n",
      "Epoch 17/100\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 0.0130 - mae: 0.0841 - val_loss: 0.0051 - val_mae: 0.0668\n",
      "Epoch 18/100\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - loss: 0.0142 - mae: 0.0875 - val_loss: 0.0052 - val_mae: 0.0674\n",
      "Epoch 19/100\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 0.0145 - mae: 0.0863 - val_loss: 0.0051 - val_mae: 0.0669\n",
      "Epoch 20/100\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 0.0135 - mae: 0.0860 - val_loss: 0.0051 - val_mae: 0.0667\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "   ✔ Train MAE  = 0.001\n",
      "   ✔ Train RMSE = 0.002\n",
      "   ✔ Test MAE   = 0.095\n",
      "   ✔ Test RMSE  = 0.178\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: EOS\n",
      "----------------------------------------------------------\n",
      "• Train rows: 1026, Val: 219, Test: 221\n",
      "Training samples: 966, Validation samples: 159, Testing samples: 161\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_7\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ lstm_14 (LSTM)                       │ (None, 60, 64)              │          26,624 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_14 (Dropout)                 │ (None, 60, 64)              │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ lstm_15 (LSTM)                       │ (None, 32)                  │          12,416 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_15 (Dropout)                 │ (None, 32)                  │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_14 (Dense)                     │ (None, 16)                  │             528 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_15 (Dense)                     │ (None, 1)                   │              17 │\n",
      "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
      " Total params: 39,585 (154.63 KB)\n",
      " Trainable params: 39,585 (154.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 87ms/step - loss: 0.0977 - mae: 0.2512 - val_loss: 0.0066 - val_mae: 0.0795\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0673 - mae: 0.1998 - val_loss: 0.0030 - val_mae: 0.0524\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0528 - mae: 0.1688 - val_loss: 9.6201e-04 - val_mae: 0.0269\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.0474 - mae: 0.1528 - val_loss: 2.4760e-04 - val_mae: 0.0115\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0429 - mae: 0.1386 - val_loss: 5.3224e-04 - val_mae: 0.0208\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0339 - mae: 0.1229 - val_loss: 0.0015 - val_mae: 0.0362\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0307 - mae: 0.1168 - val_loss: 0.0028 - val_mae: 0.0511\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - loss: 0.0340 - mae: 0.1231 - val_loss: 0.0044 - val_mae: 0.0648\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - loss: 0.0324 - mae: 0.1235 - val_loss: 0.0061 - val_mae: 0.0766\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - loss: 0.0305 - mae: 0.1202 - val_loss: 0.0077 - val_mae: 0.0862\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0288 - mae: 0.1195 - val_loss: 0.0090 - val_mae: 0.0938\n",
      "Epoch 12/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0300 - mae: 0.1250 - val_loss: 0.0101 - val_mae: 0.0995\n",
      "Epoch 13/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0276 - mae: 0.1200 - val_loss: 0.0111 - val_mae: 0.1043\n",
      "Epoch 14/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.0284 - mae: 0.1233 - val_loss: 0.0117 - val_mae: 0.1072\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "   ✔ Train MAE  = 2.922\n",
      "   ✔ Train RMSE = 4.320\n",
      "   ✔ Test MAE   = 2.670\n",
      "   ✔ Test RMSE  = 3.344\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: ETHEREUM\n",
      "----------------------------------------------------------\n",
      "• Train rows: 1512, Val: 324, Test: 324\n",
      "Training samples: 1452, Validation samples: 264, Testing samples: 264\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_8\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ lstm_16 (LSTM)                       │ (None, 60, 64)              │          26,624 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_16 (Dropout)                 │ (None, 60, 64)              │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ lstm_17 (LSTM)                       │ (None, 32)                  │          12,416 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_17 (Dropout)                 │ (None, 32)                  │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_16 (Dense)                     │ (None, 16)                  │             528 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_17 (Dense)                     │ (None, 1)                   │              17 │\n",
      "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
      " Total params: 39,585 (154.63 KB)\n",
      " Trainable params: 39,585 (154.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - loss: 0.0607 - mae: 0.1648 - val_loss: 0.0149 - val_mae: 0.1118\n",
      "Epoch 2/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - loss: 0.0446 - mae: 0.1383 - val_loss: 0.0081 - val_mae: 0.0753\n",
      "Epoch 3/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 0.0378 - mae: 0.1311 - val_loss: 0.0046 - val_mae: 0.0496\n",
      "Epoch 4/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 0.0344 - mae: 0.1270 - val_loss: 0.0031 - val_mae: 0.0407\n",
      "Epoch 5/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - loss: 0.0350 - mae: 0.1310 - val_loss: 0.0026 - val_mae: 0.0378\n",
      "Epoch 6/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - loss: 0.0323 - mae: 0.1302 - val_loss: 0.0024 - val_mae: 0.0370\n",
      "Epoch 7/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - loss: 0.0337 - mae: 0.1330 - val_loss: 0.0024 - val_mae: 0.0371\n",
      "Epoch 8/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0354 - mae: 0.1371 - val_loss: 0.0024 - val_mae: 0.0373\n",
      "Epoch 9/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - loss: 0.0338 - mae: 0.1358 - val_loss: 0.0024 - val_mae: 0.0375\n",
      "Epoch 10/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - loss: 0.0322 - mae: 0.1306 - val_loss: 0.0024 - val_mae: 0.0376\n",
      "Epoch 11/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0314 - mae: 0.1318 - val_loss: 0.0024 - val_mae: 0.0377\n",
      "Epoch 12/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0331 - mae: 0.1343 - val_loss: 0.0024 - val_mae: 0.0374\n",
      "Epoch 13/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 0.0303 - mae: 0.1293 - val_loss: 0.0024 - val_mae: 0.0374\n",
      "Epoch 14/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.0337 - mae: 0.1352 - val_loss: 0.0024 - val_mae: 0.0377\n",
      "Epoch 15/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - loss: 0.0351 - mae: 0.1383 - val_loss: 0.0024 - val_mae: 0.0376\n",
      "Epoch 16/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0309 - mae: 0.1307 - val_loss: 0.0024 - val_mae: 0.0376\n",
      "Epoch 17/100\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 0.0312 - mae: 0.1319 - val_loss: 0.0024 - val_mae: 0.0374\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "   ✔ Train MAE  = 184.872\n",
      "   ✔ Train RMSE = 252.067\n",
      "   ✔ Test MAE   = 1415.774\n",
      "   ✔ Test RMSE  = 1684.842\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: IOTA\n",
      "----------------------------------------------------------\n",
      "• Train rows: 1038, Val: 222, Test: 224\n",
      "Training samples: 978, Validation samples: 162, Testing samples: 164\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_9\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ lstm_18 (LSTM)                       │ (None, 60, 64)              │          26,624 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_18 (Dropout)                 │ (None, 60, 64)              │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ lstm_19 (LSTM)                       │ (None, 32)                  │          12,416 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_19 (Dropout)                 │ (None, 32)                  │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_18 (Dense)                     │ (None, 16)                  │             528 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_19 (Dense)                     │ (None, 1)                   │              17 │\n",
      "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
      " Total params: 39,585 (154.63 KB)\n",
      " Trainable params: 39,585 (154.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - loss: 0.0448 - mae: 0.1269 - val_loss: 1.0187e-04 - val_mae: 0.0068\n",
      "Epoch 2/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0330 - mae: 0.0916 - val_loss: 5.8442e-04 - val_mae: 0.0224\n",
      "Epoch 3/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.0294 - mae: 0.0940 - val_loss: 0.0020 - val_mae: 0.0441\n",
      "Epoch 4/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - loss: 0.0273 - mae: 0.0969 - val_loss: 0.0037 - val_mae: 0.0603\n",
      "Epoch 5/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 0.0244 - mae: 0.0972 - val_loss: 0.0053 - val_mae: 0.0724\n",
      "Epoch 6/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0279 - mae: 0.1073 - val_loss: 0.0068 - val_mae: 0.0819\n",
      "Epoch 7/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - loss: 0.0321 - mae: 0.1181 - val_loss: 0.0078 - val_mae: 0.0879\n",
      "Epoch 8/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - loss: 0.0274 - mae: 0.1142 - val_loss: 0.0083 - val_mae: 0.0908\n",
      "Epoch 9/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.0288 - mae: 0.1178 - val_loss: 0.0086 - val_mae: 0.0921\n",
      "Epoch 10/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.0326 - mae: 0.1230 - val_loss: 0.0088 - val_mae: 0.0933\n",
      "Epoch 11/100\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - loss: 0.0270 - mae: 0.1178 - val_loss: 0.0090 - val_mae: 0.0945\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "   ✔ Train MAE  = 0.538\n",
      "   ✔ Train RMSE = 1.026\n",
      "   ✔ Test MAE   = 1.077\n",
      "   ✔ Test RMSE  = 1.193\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: LITECOIN\n",
      "----------------------------------------------------------\n",
      "• Train rows: 2093, Val: 448, Test: 450\n",
      "Training samples: 2033, Validation samples: 388, Testing samples: 390\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_10\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ lstm_20 (LSTM)                       │ (None, 60, 64)              │          26,624 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_20 (Dropout)                 │ (None, 60, 64)              │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ lstm_21 (LSTM)                       │ (None, 32)                  │          12,416 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_21 (Dropout)                 │ (None, 32)                  │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_20 (Dense)                     │ (None, 16)                  │             528 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_21 (Dense)                     │ (None, 1)                   │              17 │\n",
      "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
      " Total params: 39,585 (154.63 KB)\n",
      " Trainable params: 39,585 (154.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 80ms/step - loss: 0.0286 - mae: 0.0869 - val_loss: 0.0255 - val_mae: 0.1430\n",
      "Epoch 2/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - loss: 0.0233 - mae: 0.0918 - val_loss: 0.0192 - val_mae: 0.1187\n",
      "Epoch 3/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - loss: 0.0220 - mae: 0.0988 - val_loss: 0.0173 - val_mae: 0.1104\n",
      "Epoch 4/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 0.0231 - mae: 0.1048 - val_loss: 0.0176 - val_mae: 0.1119\n",
      "Epoch 5/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 0.0238 - mae: 0.1036 - val_loss: 0.0175 - val_mae: 0.1115\n",
      "Epoch 6/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - loss: 0.0234 - mae: 0.1014 - val_loss: 0.0171 - val_mae: 0.1096\n",
      "Epoch 7/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.0235 - mae: 0.1037 - val_loss: 0.0171 - val_mae: 0.1096\n",
      "Epoch 8/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - loss: 0.0209 - mae: 0.1005 - val_loss: 0.0170 - val_mae: 0.1092\n",
      "Epoch 9/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - loss: 0.0221 - mae: 0.1008 - val_loss: 0.0171 - val_mae: 0.1097\n",
      "Epoch 10/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 0.0240 - mae: 0.1049 - val_loss: 0.0171 - val_mae: 0.1095\n",
      "Epoch 11/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0213 - mae: 0.0987 - val_loss: 0.0168 - val_mae: 0.1082\n",
      "Epoch 12/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 0.0214 - mae: 0.1009 - val_loss: 0.0172 - val_mae: 0.1104\n",
      "Epoch 13/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - loss: 0.0255 - mae: 0.1057 - val_loss: 0.0174 - val_mae: 0.1110\n",
      "Epoch 14/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - loss: 0.0233 - mae: 0.1028 - val_loss: 0.0173 - val_mae: 0.1104\n",
      "Epoch 15/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 0.0234 - mae: 0.1037 - val_loss: 0.0172 - val_mae: 0.1102\n",
      "Epoch 16/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - loss: 0.0226 - mae: 0.1007 - val_loss: 0.0168 - val_mae: 0.1085\n",
      "Epoch 17/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - loss: 0.0230 - mae: 0.1015 - val_loss: 0.0171 - val_mae: 0.1098\n",
      "Epoch 18/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 0.0241 - mae: 0.1032 - val_loss: 0.0173 - val_mae: 0.1107\n",
      "Epoch 19/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 0.0235 - mae: 0.1036 - val_loss: 0.0172 - val_mae: 0.1101\n",
      "Epoch 20/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 0.0217 - mae: 0.1002 - val_loss: 0.0169 - val_mae: 0.1089\n",
      "Epoch 21/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - loss: 0.0244 - mae: 0.1052 - val_loss: 0.0172 - val_mae: 0.1102\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "   ✔ Train MAE  = 36.820\n",
      "   ✔ Train RMSE = 54.101\n",
      "   ✔ Test MAE   = 93.354\n",
      "   ✔ Test RMSE  = 123.238\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: MONERO\n",
      "----------------------------------------------------------\n",
      "• Train rows: 1821, Val: 390, Test: 391\n",
      "Training samples: 1761, Validation samples: 330, Testing samples: 331\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_11\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ lstm_22 (LSTM)                       │ (None, 60, 64)              │          26,624 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_22 (Dropout)                 │ (None, 60, 64)              │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ lstm_23 (LSTM)                       │ (None, 32)                  │          12,416 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_23 (Dropout)                 │ (None, 32)                  │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_22 (Dense)                     │ (None, 16)                  │             528 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_23 (Dense)                     │ (None, 1)                   │              17 │\n",
      "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
      " Total params: 39,585 (154.63 KB)\n",
      " Trainable params: 39,585 (154.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 75ms/step - loss: 0.0432 - mae: 0.1149 - val_loss: 0.0083 - val_mae: 0.0869\n",
      "Epoch 2/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 0.0341 - mae: 0.1147 - val_loss: 0.0035 - val_mae: 0.0525\n",
      "Epoch 3/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - loss: 0.0356 - mae: 0.1257 - val_loss: 0.0018 - val_mae: 0.0348\n",
      "Epoch 4/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 0.0368 - mae: 0.1334 - val_loss: 0.0013 - val_mae: 0.0283\n",
      "Epoch 5/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.0345 - mae: 0.1328 - val_loss: 0.0012 - val_mae: 0.0262\n",
      "Epoch 6/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 0.0324 - mae: 0.1306 - val_loss: 0.0011 - val_mae: 0.0258\n",
      "Epoch 7/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - loss: 0.0354 - mae: 0.1350 - val_loss: 0.0010 - val_mae: 0.0243\n",
      "Epoch 8/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0341 - mae: 0.1356 - val_loss: 0.0011 - val_mae: 0.0250\n",
      "Epoch 9/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - loss: 0.0351 - mae: 0.1350 - val_loss: 0.0011 - val_mae: 0.0250\n",
      "Epoch 10/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 0.0362 - mae: 0.1344 - val_loss: 0.0011 - val_mae: 0.0254\n",
      "Epoch 11/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 73ms/step - loss: 0.0306 - mae: 0.1285 - val_loss: 0.0011 - val_mae: 0.0248\n",
      "Epoch 12/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - loss: 0.0330 - mae: 0.1317 - val_loss: 0.0010 - val_mae: 0.0243\n",
      "Epoch 13/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - loss: 0.0311 - mae: 0.1309 - val_loss: 9.9520e-04 - val_mae: 0.0241\n",
      "Epoch 14/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - loss: 0.0366 - mae: 0.1384 - val_loss: 0.0011 - val_mae: 0.0253\n",
      "Epoch 15/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0344 - mae: 0.1339 - val_loss: 0.0011 - val_mae: 0.0248\n",
      "Epoch 16/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.0327 - mae: 0.1325 - val_loss: 0.0011 - val_mae: 0.0250\n",
      "Epoch 17/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.0325 - mae: 0.1316 - val_loss: 0.0011 - val_mae: 0.0250\n",
      "Epoch 18/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - loss: 0.0369 - mae: 0.1402 - val_loss: 0.0010 - val_mae: 0.0244\n",
      "Epoch 19/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 0.0362 - mae: 0.1377 - val_loss: 0.0011 - val_mae: 0.0252\n",
      "Epoch 20/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - loss: 0.0352 - mae: 0.1370 - val_loss: 9.9739e-04 - val_mae: 0.0241\n",
      "Epoch 21/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - loss: 0.0342 - mae: 0.1352 - val_loss: 0.0010 - val_mae: 0.0245\n",
      "Epoch 22/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - loss: 0.0334 - mae: 0.1313 - val_loss: 0.0010 - val_mae: 0.0245\n",
      "Epoch 23/100\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - loss: 0.0367 - mae: 0.1395 - val_loss: 0.0010 - val_mae: 0.0244\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "   ✔ Train MAE  = 63.405\n",
      "   ✔ Train RMSE = 86.700\n",
      "   ✔ Test MAE   = 134.169\n",
      "   ✔ Test RMSE  = 162.982\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: NEM\n",
      "----------------------------------------------------------\n",
      "• Train rows: 1601, Val: 343, Test: 344\n",
      "Training samples: 1541, Validation samples: 283, Testing samples: 284\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_12\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ lstm_24 (LSTM)                       │ (None, 60, 64)              │          26,624 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_24 (Dropout)                 │ (None, 60, 64)              │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ lstm_25 (LSTM)                       │ (None, 32)                  │          12,416 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_25 (Dropout)                 │ (None, 32)                  │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_24 (Dense)                     │ (None, 16)                  │             528 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_25 (Dense)                     │ (None, 1)                   │              17 │\n",
      "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
      " Total params: 39,585 (154.63 KB)\n",
      " Trainable params: 39,585 (154.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - loss: 0.0152 - mae: 0.0655 - val_loss: 2.9088e-04 - val_mae: 0.0165\n",
      "Epoch 2/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 0.0171 - mae: 0.0688 - val_loss: 0.0014 - val_mae: 0.0372\n",
      "Epoch 3/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - loss: 0.0145 - mae: 0.0718 - val_loss: 0.0017 - val_mae: 0.0416\n",
      "Epoch 4/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - loss: 0.0116 - mae: 0.0671 - val_loss: 0.0020 - val_mae: 0.0446\n",
      "Epoch 5/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - loss: 0.0160 - mae: 0.0761 - val_loss: 0.0022 - val_mae: 0.0466\n",
      "Epoch 6/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - loss: 0.0145 - mae: 0.0732 - val_loss: 0.0020 - val_mae: 0.0441\n",
      "Epoch 7/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - loss: 0.0179 - mae: 0.0781 - val_loss: 0.0020 - val_mae: 0.0449\n",
      "Epoch 8/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - loss: 0.0129 - mae: 0.0707 - val_loss: 0.0019 - val_mae: 0.0428\n",
      "Epoch 9/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - loss: 0.0139 - mae: 0.0717 - val_loss: 0.0020 - val_mae: 0.0442\n",
      "Epoch 10/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - loss: 0.0140 - mae: 0.0718 - val_loss: 0.0020 - val_mae: 0.0440\n",
      "Epoch 11/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 0.0141 - mae: 0.0718 - val_loss: 0.0019 - val_mae: 0.0439\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "   ✔ Train MAE  = 0.117\n",
      "   ✔ Train RMSE = 0.226\n",
      "   ✔ Test MAE   = 0.191\n",
      "   ✔ Test RMSE  = 0.241\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: POLKADOT\n",
      "----------------------------------------------------------\n",
      " Skipping Polkadot: not enough rows.\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: SOLANA\n",
      "----------------------------------------------------------\n",
      "• Train rows: 316, Val: 67, Test: 69\n",
      "Training samples: 256, Validation samples: 7, Testing samples: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_13\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ lstm_26 (LSTM)                       │ (None, 60, 64)              │          26,624 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_26 (Dropout)                 │ (None, 60, 64)              │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ lstm_27 (LSTM)                       │ (None, 32)                  │          12,416 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_27 (Dropout)                 │ (None, 32)                  │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_26 (Dense)                     │ (None, 16)                  │             528 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_27 (Dense)                     │ (None, 1)                   │              17 │\n",
      "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
      " Total params: 39,585 (154.63 KB)\n",
      " Trainable params: 39,585 (154.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 183ms/step - loss: 0.0690 - mae: 0.1882 - val_loss: 14.5836 - val_mae: 3.8066\n",
      "Epoch 2/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0547 - mae: 0.1719 - val_loss: 14.5234 - val_mae: 3.7987\n",
      "Epoch 3/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0516 - mae: 0.1612 - val_loss: 14.4647 - val_mae: 3.7910\n",
      "Epoch 4/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0641 - mae: 0.1753 - val_loss: 14.4057 - val_mae: 3.7832\n",
      "Epoch 5/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0564 - mae: 0.1668 - val_loss: 14.3486 - val_mae: 3.7756\n",
      "Epoch 6/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0488 - mae: 0.1586 - val_loss: 14.2941 - val_mae: 3.7684\n",
      "Epoch 7/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0479 - mae: 0.1468 - val_loss: 14.2410 - val_mae: 3.7614\n",
      "Epoch 8/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0435 - mae: 0.1474 - val_loss: 14.1889 - val_mae: 3.7544\n",
      "Epoch 9/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0515 - mae: 0.1506 - val_loss: 14.1376 - val_mae: 3.7476\n",
      "Epoch 10/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0461 - mae: 0.1402 - val_loss: 14.0886 - val_mae: 3.7410\n",
      "Epoch 11/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0424 - mae: 0.1369 - val_loss: 14.0415 - val_mae: 3.7347\n",
      "Epoch 12/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0353 - mae: 0.1236 - val_loss: 13.9958 - val_mae: 3.7286\n",
      "Epoch 13/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0391 - mae: 0.1265 - val_loss: 13.9512 - val_mae: 3.7226\n",
      "Epoch 14/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0315 - mae: 0.1197 - val_loss: 13.9093 - val_mae: 3.7170\n",
      "Epoch 15/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0399 - mae: 0.1223 - val_loss: 13.8679 - val_mae: 3.7114\n",
      "Epoch 16/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0399 - mae: 0.1221 - val_loss: 13.8288 - val_mae: 3.7062\n",
      "Epoch 17/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0294 - mae: 0.1122 - val_loss: 13.7916 - val_mae: 3.7011\n",
      "Epoch 18/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0328 - mae: 0.1122 - val_loss: 13.7549 - val_mae: 3.6962\n",
      "Epoch 19/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - loss: 0.0435 - mae: 0.1288 - val_loss: 13.7181 - val_mae: 3.6912\n",
      "Epoch 20/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0291 - mae: 0.1060 - val_loss: 13.6879 - val_mae: 3.6871\n",
      "Epoch 21/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0296 - mae: 0.1100 - val_loss: 13.6568 - val_mae: 3.6829\n",
      "Epoch 22/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0327 - mae: 0.1122 - val_loss: 13.6266 - val_mae: 3.6788\n",
      "Epoch 23/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0294 - mae: 0.1073 - val_loss: 13.5986 - val_mae: 3.6750\n",
      "Epoch 24/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0331 - mae: 0.1149 - val_loss: 13.5704 - val_mae: 3.6711\n",
      "Epoch 25/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - loss: 0.0307 - mae: 0.1080 - val_loss: 13.5451 - val_mae: 3.6677\n",
      "Epoch 26/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0318 - mae: 0.1163 - val_loss: 13.5202 - val_mae: 3.6643\n",
      "Epoch 27/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0255 - mae: 0.1036 - val_loss: 13.4985 - val_mae: 3.6613\n",
      "Epoch 28/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0297 - mae: 0.1100 - val_loss: 13.4779 - val_mae: 3.6585\n",
      "Epoch 29/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0300 - mae: 0.1073 - val_loss: 13.4565 - val_mae: 3.6556\n",
      "Epoch 30/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0270 - mae: 0.1077 - val_loss: 13.4372 - val_mae: 3.6529\n",
      "Epoch 31/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0270 - mae: 0.1064 - val_loss: 13.4208 - val_mae: 3.6507\n",
      "Epoch 32/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0300 - mae: 0.1142 - val_loss: 13.4029 - val_mae: 3.6483\n",
      "Epoch 33/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0309 - mae: 0.1101 - val_loss: 13.3866 - val_mae: 3.6460\n",
      "Epoch 34/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0330 - mae: 0.1188 - val_loss: 13.3721 - val_mae: 3.6440\n",
      "Epoch 35/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0315 - mae: 0.1165 - val_loss: 13.3597 - val_mae: 3.6423\n",
      "Epoch 36/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0329 - mae: 0.1178 - val_loss: 13.3459 - val_mae: 3.6404\n",
      "Epoch 37/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0326 - mae: 0.1198 - val_loss: 13.3353 - val_mae: 3.6390\n",
      "Epoch 38/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0299 - mae: 0.1111 - val_loss: 13.3239 - val_mae: 3.6374\n",
      "Epoch 39/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0293 - mae: 0.1154 - val_loss: 13.3143 - val_mae: 3.6361\n",
      "Epoch 40/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0300 - mae: 0.1155 - val_loss: 13.3048 - val_mae: 3.6348\n",
      "Epoch 41/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0305 - mae: 0.1174 - val_loss: 13.2958 - val_mae: 3.6335\n",
      "Epoch 42/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0315 - mae: 0.1208 - val_loss: 13.2867 - val_mae: 3.6323\n",
      "Epoch 43/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0299 - mae: 0.1173 - val_loss: 13.2789 - val_mae: 3.6312\n",
      "Epoch 44/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - loss: 0.0318 - mae: 0.1169 - val_loss: 13.2738 - val_mae: 3.6305\n",
      "Epoch 45/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0309 - mae: 0.1140 - val_loss: 13.2671 - val_mae: 3.6296\n",
      "Epoch 46/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0300 - mae: 0.1160 - val_loss: 13.2622 - val_mae: 3.6289\n",
      "Epoch 47/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0321 - mae: 0.1198 - val_loss: 13.2576 - val_mae: 3.6283\n",
      "Epoch 48/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0296 - mae: 0.1158 - val_loss: 13.2534 - val_mae: 3.6277\n",
      "Epoch 49/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0295 - mae: 0.1162 - val_loss: 13.2497 - val_mae: 3.6272\n",
      "Epoch 50/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0348 - mae: 0.1233 - val_loss: 13.2438 - val_mae: 3.6264\n",
      "Epoch 51/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0241 - mae: 0.1084 - val_loss: 13.2433 - val_mae: 3.6263\n",
      "Epoch 52/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0297 - mae: 0.1197 - val_loss: 13.2405 - val_mae: 3.6259\n",
      "Epoch 53/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0277 - mae: 0.1147 - val_loss: 13.2354 - val_mae: 3.6252\n",
      "Epoch 54/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0276 - mae: 0.1152 - val_loss: 13.2343 - val_mae: 3.6251\n",
      "Epoch 55/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0298 - mae: 0.1181 - val_loss: 13.2302 - val_mae: 3.6245\n",
      "Epoch 56/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0272 - mae: 0.1141 - val_loss: 13.2294 - val_mae: 3.6244\n",
      "Epoch 57/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0275 - mae: 0.1175 - val_loss: 13.2278 - val_mae: 3.6242\n",
      "Epoch 58/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0256 - mae: 0.1125 - val_loss: 13.2263 - val_mae: 3.6240\n",
      "Epoch 59/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0254 - mae: 0.1110 - val_loss: 13.2240 - val_mae: 3.6237\n",
      "Epoch 60/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0247 - mae: 0.1108 - val_loss: 13.2222 - val_mae: 3.6234\n",
      "Epoch 61/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0296 - mae: 0.1161 - val_loss: 13.2208 - val_mae: 3.6232\n",
      "Epoch 62/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0301 - mae: 0.1179 - val_loss: 13.2182 - val_mae: 3.6229\n",
      "Epoch 63/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0299 - mae: 0.1166 - val_loss: 13.2185 - val_mae: 3.6229\n",
      "Epoch 64/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0278 - mae: 0.1157 - val_loss: 13.2181 - val_mae: 3.6228\n",
      "Epoch 65/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0247 - mae: 0.1121 - val_loss: 13.2199 - val_mae: 3.6231\n",
      "Epoch 66/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0263 - mae: 0.1093 - val_loss: 13.2184 - val_mae: 3.6229\n",
      "Epoch 67/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0236 - mae: 0.1088 - val_loss: 13.2200 - val_mae: 3.6231\n",
      "Epoch 68/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 0.0310 - mae: 0.1196 - val_loss: 13.2161 - val_mae: 3.6226\n",
      "Epoch 69/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0286 - mae: 0.1159 - val_loss: 13.2152 - val_mae: 3.6224\n",
      "Epoch 70/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0311 - mae: 0.1153 - val_loss: 13.2133 - val_mae: 3.6222\n",
      "Epoch 71/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0246 - mae: 0.1094 - val_loss: 13.2142 - val_mae: 3.6223\n",
      "Epoch 72/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0280 - mae: 0.1154 - val_loss: 13.2128 - val_mae: 3.6221\n",
      "Epoch 73/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0269 - mae: 0.1139 - val_loss: 13.2128 - val_mae: 3.6221\n",
      "Epoch 74/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 0.0290 - mae: 0.1148 - val_loss: 13.2139 - val_mae: 3.6223\n",
      "Epoch 75/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0250 - mae: 0.1098 - val_loss: 13.2140 - val_mae: 3.6223\n",
      "Epoch 76/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0284 - mae: 0.1147 - val_loss: 13.2121 - val_mae: 3.6220\n",
      "Epoch 77/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0321 - mae: 0.1235 - val_loss: 13.2097 - val_mae: 3.6217\n",
      "Epoch 78/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0291 - mae: 0.1176 - val_loss: 13.2105 - val_mae: 3.6218\n",
      "Epoch 79/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0301 - mae: 0.1180 - val_loss: 13.2102 - val_mae: 3.6217\n",
      "Epoch 80/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - loss: 0.0274 - mae: 0.1155 - val_loss: 13.2125 - val_mae: 3.6221\n",
      "Epoch 81/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0252 - mae: 0.1114 - val_loss: 13.2118 - val_mae: 3.6220\n",
      "Epoch 82/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0301 - mae: 0.1188 - val_loss: 13.2115 - val_mae: 3.6219\n",
      "Epoch 83/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0252 - mae: 0.1098 - val_loss: 13.2123 - val_mae: 3.6220\n",
      "Epoch 84/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.0298 - mae: 0.1200 - val_loss: 13.2133 - val_mae: 3.6222\n",
      "Epoch 85/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0279 - mae: 0.1096 - val_loss: 13.2139 - val_mae: 3.6223\n",
      "Epoch 86/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0296 - mae: 0.1186 - val_loss: 13.2109 - val_mae: 3.6218\n",
      "Epoch 87/100\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - loss: 0.0267 - mae: 0.1135 - val_loss: 13.2129 - val_mae: 3.6221\n",
      "Epoch 87: early stopping\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 544ms/step\n",
      "   ✔ Train MAE  = 1.281\n",
      "   ✔ Train RMSE = 1.870\n",
      "   ✔ Test MAE   = 31.352\n",
      "   ✔ Test RMSE  = 31.362\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: STELLAR\n",
      "----------------------------------------------------------\n",
      "• Train rows: 1768, Val: 379, Test: 380\n",
      "Training samples: 1708, Validation samples: 319, Testing samples: 320\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_14\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ lstm_28 (LSTM)                       │ (None, 60, 64)              │          26,624 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_28 (Dropout)                 │ (None, 60, 64)              │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ lstm_29 (LSTM)                       │ (None, 32)                  │          12,416 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_29 (Dropout)                 │ (None, 32)                  │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_28 (Dense)                     │ (None, 16)                  │             528 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_29 (Dense)                     │ (None, 1)                   │              17 │\n",
      "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
      " Total params: 39,585 (154.63 KB)\n",
      " Trainable params: 39,585 (154.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - loss: 0.0255 - mae: 0.0882 - val_loss: 5.8017e-04 - val_mae: 0.0211\n",
      "Epoch 2/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - loss: 0.0226 - mae: 0.0987 - val_loss: 1.8791e-04 - val_mae: 0.0109\n",
      "Epoch 3/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0206 - mae: 0.1059 - val_loss: 4.3167e-04 - val_mae: 0.0172\n",
      "Epoch 4/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - loss: 0.0216 - mae: 0.1095 - val_loss: 5.1463e-04 - val_mae: 0.0192\n",
      "Epoch 5/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - loss: 0.0179 - mae: 0.1019 - val_loss: 5.5935e-04 - val_mae: 0.0203\n",
      "Epoch 6/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 0.0196 - mae: 0.1068 - val_loss: 5.9454e-04 - val_mae: 0.0211\n",
      "Epoch 7/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - loss: 0.0207 - mae: 0.1095 - val_loss: 5.0992e-04 - val_mae: 0.0191\n",
      "Epoch 8/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - loss: 0.0214 - mae: 0.1115 - val_loss: 5.5267e-04 - val_mae: 0.0201\n",
      "Epoch 9/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 0.0198 - mae: 0.1071 - val_loss: 4.8342e-04 - val_mae: 0.0185\n",
      "Epoch 10/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0186 - mae: 0.1052 - val_loss: 6.0343e-04 - val_mae: 0.0213\n",
      "Epoch 11/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - loss: 0.0193 - mae: 0.1060 - val_loss: 5.1206e-04 - val_mae: 0.0192\n",
      "Epoch 12/100\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0175 - mae: 0.1029 - val_loss: 6.7176e-04 - val_mae: 0.0228\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "   ✔ Train MAE  = 0.092\n",
      "   ✔ Train RMSE = 0.128\n",
      "   ✔ Test MAE   = 0.217\n",
      "   ✔ Test RMSE  = 0.279\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: TRON\n",
      "----------------------------------------------------------\n",
      "• Train rows: 974, Val: 208, Test: 210\n",
      "Training samples: 914, Validation samples: 148, Testing samples: 150\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_15\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ lstm_30 (LSTM)                       │ (None, 60, 64)              │          26,624 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_30 (Dropout)                 │ (None, 60, 64)              │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ lstm_31 (LSTM)                       │ (None, 32)                  │          12,416 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_31 (Dropout)                 │ (None, 32)                  │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_30 (Dense)                     │ (None, 16)                  │             528 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_31 (Dense)                     │ (None, 1)                   │              17 │\n",
      "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
      " Total params: 39,585 (154.63 KB)\n",
      " Trainable params: 39,585 (154.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 110ms/step - loss: 0.0220 - mae: 0.1129 - val_loss: 0.0079 - val_mae: 0.0866\n",
      "Epoch 2/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.0206 - mae: 0.0968 - val_loss: 0.0041 - val_mae: 0.0609\n",
      "Epoch 3/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.0212 - mae: 0.0826 - val_loss: 0.0020 - val_mae: 0.0397\n",
      "Epoch 4/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0125 - mae: 0.0622 - val_loss: 9.7597e-04 - val_mae: 0.0268\n",
      "Epoch 5/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - loss: 0.0131 - mae: 0.0607 - val_loss: 5.3939e-04 - val_mae: 0.0192\n",
      "Epoch 6/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - loss: 0.0106 - mae: 0.0608 - val_loss: 4.2937e-04 - val_mae: 0.0154\n",
      "Epoch 7/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0089 - mae: 0.0567 - val_loss: 4.4009e-04 - val_mae: 0.0154\n",
      "Epoch 8/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0091 - mae: 0.0608 - val_loss: 4.8326e-04 - val_mae: 0.0169\n",
      "Epoch 9/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.0098 - mae: 0.0612 - val_loss: 5.3125e-04 - val_mae: 0.0182\n",
      "Epoch 10/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0125 - mae: 0.0656 - val_loss: 5.5987e-04 - val_mae: 0.0188\n",
      "Epoch 11/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.0085 - mae: 0.0618 - val_loss: 5.6370e-04 - val_mae: 0.0189\n",
      "Epoch 12/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - loss: 0.0098 - mae: 0.0630 - val_loss: 5.8914e-04 - val_mae: 0.0195\n",
      "Epoch 13/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0082 - mae: 0.0578 - val_loss: 5.7414e-04 - val_mae: 0.0192\n",
      "Epoch 14/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0081 - mae: 0.0611 - val_loss: 5.8053e-04 - val_mae: 0.0193\n",
      "Epoch 15/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - loss: 0.0076 - mae: 0.0587 - val_loss: 5.9191e-04 - val_mae: 0.0195\n",
      "Epoch 16/100\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.0090 - mae: 0.0610 - val_loss: 5.8561e-04 - val_mae: 0.0194\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "   ✔ Train MAE  = 0.013\n",
      "   ✔ Train RMSE = 0.022\n",
      "   ✔ Test MAE   = 0.057\n",
      "   ✔ Test RMSE  = 0.066\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: TETHER\n",
      "----------------------------------------------------------\n",
      "• Train rows: 1622, Val: 347, Test: 349\n",
      "Training samples: 1562, Validation samples: 287, Testing samples: 289\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_16\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ lstm_32 (LSTM)                       │ (None, 60, 64)              │          26,624 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_32 (Dropout)                 │ (None, 60, 64)              │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ lstm_33 (LSTM)                       │ (None, 32)                  │          12,416 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_33 (Dropout)                 │ (None, 32)                  │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_32 (Dense)                     │ (None, 16)                  │             528 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_33 (Dense)                     │ (None, 1)                   │              17 │\n",
      "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
      " Total params: 39,585 (154.63 KB)\n",
      " Trainable params: 39,585 (154.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - loss: 0.4273 - mae: 0.6525 - val_loss: 0.3753 - val_mae: 0.6126\n",
      "Epoch 2/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 0.3578 - mae: 0.5978 - val_loss: 0.3202 - val_mae: 0.5658\n",
      "Epoch 3/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - loss: 0.3050 - mae: 0.5519 - val_loss: 0.2714 - val_mae: 0.5209\n",
      "Epoch 4/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 0.2580 - mae: 0.5076 - val_loss: 0.2285 - val_mae: 0.4779\n",
      "Epoch 5/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - loss: 0.2162 - mae: 0.4645 - val_loss: 0.1910 - val_mae: 0.4370\n",
      "Epoch 6/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - loss: 0.1802 - mae: 0.4241 - val_loss: 0.1585 - val_mae: 0.3981\n",
      "Epoch 7/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - loss: 0.1491 - mae: 0.3857 - val_loss: 0.1305 - val_mae: 0.3612\n",
      "Epoch 8/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - loss: 0.1223 - mae: 0.3492 - val_loss: 0.1066 - val_mae: 0.3264\n",
      "Epoch 9/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0996 - mae: 0.3150 - val_loss: 0.0864 - val_mae: 0.2938\n",
      "Epoch 10/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - loss: 0.0808 - mae: 0.2836 - val_loss: 0.0693 - val_mae: 0.2632\n",
      "Epoch 11/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 0.0644 - mae: 0.2531 - val_loss: 0.0552 - val_mae: 0.2347\n",
      "Epoch 12/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - loss: 0.0510 - mae: 0.2252 - val_loss: 0.0435 - val_mae: 0.2084\n",
      "Epoch 13/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0399 - mae: 0.1991 - val_loss: 0.0339 - val_mae: 0.1840\n",
      "Epoch 14/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 0.0310 - mae: 0.1752 - val_loss: 0.0262 - val_mae: 0.1618\n",
      "Epoch 15/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - loss: 0.0238 - mae: 0.1533 - val_loss: 0.0201 - val_mae: 0.1414\n",
      "Epoch 16/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - loss: 0.0181 - mae: 0.1336 - val_loss: 0.0152 - val_mae: 0.1230\n",
      "Epoch 17/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - loss: 0.0136 - mae: 0.1155 - val_loss: 0.0114 - val_mae: 0.1064\n",
      "Epoch 18/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.0102 - mae: 0.1000 - val_loss: 0.0085 - val_mae: 0.0916\n",
      "Epoch 19/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 0.0075 - mae: 0.0853 - val_loss: 0.0062 - val_mae: 0.0784\n",
      "Epoch 20/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - loss: 0.0056 - mae: 0.0735 - val_loss: 0.0045 - val_mae: 0.0668\n",
      "Epoch 21/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - loss: 0.0040 - mae: 0.0622 - val_loss: 0.0033 - val_mae: 0.0566\n",
      "Epoch 22/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - loss: 0.0029 - mae: 0.0526 - val_loss: 0.0024 - val_mae: 0.0477\n",
      "Epoch 23/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - loss: 0.0021 - mae: 0.0439 - val_loss: 0.0017 - val_mae: 0.0402\n",
      "Epoch 24/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - loss: 0.0015 - mae: 0.0373 - val_loss: 0.0012 - val_mae: 0.0337\n",
      "Epoch 25/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - loss: 0.0012 - mae: 0.0315 - val_loss: 8.5893e-04 - val_mae: 0.0282\n",
      "Epoch 26/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 8.7103e-04 - mae: 0.0266 - val_loss: 6.1737e-04 - val_mae: 0.0236\n",
      "Epoch 27/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - loss: 6.1844e-04 - mae: 0.0217 - val_loss: 4.4766e-04 - val_mae: 0.0196\n",
      "Epoch 28/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 4.6724e-04 - mae: 0.0183 - val_loss: 3.3330e-04 - val_mae: 0.0164\n",
      "Epoch 29/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - loss: 4.2296e-04 - mae: 0.0157 - val_loss: 2.5458e-04 - val_mae: 0.0138\n",
      "Epoch 30/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - loss: 3.4150e-04 - mae: 0.0133 - val_loss: 2.0128e-04 - val_mae: 0.0118\n",
      "Epoch 31/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - loss: 3.5582e-04 - mae: 0.0120 - val_loss: 1.6432e-04 - val_mae: 0.0100\n",
      "Epoch 32/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - loss: 3.1935e-04 - mae: 0.0105 - val_loss: 1.3950e-04 - val_mae: 0.0087\n",
      "Epoch 33/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - loss: 3.0789e-04 - mae: 0.0093 - val_loss: 1.2302e-04 - val_mae: 0.0078\n",
      "Epoch 34/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - loss: 2.3931e-04 - mae: 0.0081 - val_loss: 1.1100e-04 - val_mae: 0.0070\n",
      "Epoch 35/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - loss: 2.6935e-04 - mae: 0.0077 - val_loss: 1.0316e-04 - val_mae: 0.0066\n",
      "Epoch 36/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 2.2698e-04 - mae: 0.0070 - val_loss: 9.7867e-05 - val_mae: 0.0062\n",
      "Epoch 37/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - loss: 2.2491e-04 - mae: 0.0065 - val_loss: 9.4268e-05 - val_mae: 0.0060\n",
      "Epoch 38/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - loss: 2.4472e-04 - mae: 0.0066 - val_loss: 9.2029e-05 - val_mae: 0.0059\n",
      "Epoch 39/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - loss: 2.7930e-04 - mae: 0.0070 - val_loss: 8.9960e-05 - val_mae: 0.0057\n",
      "Epoch 40/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - loss: 2.6488e-04 - mae: 0.0072 - val_loss: 8.8922e-05 - val_mae: 0.0057\n",
      "Epoch 41/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 2.5888e-04 - mae: 0.0068 - val_loss: 8.7856e-05 - val_mae: 0.0056\n",
      "Epoch 42/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - loss: 3.2467e-04 - mae: 0.0076 - val_loss: 8.7335e-05 - val_mae: 0.0056\n",
      "Epoch 43/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - loss: 2.7985e-04 - mae: 0.0073 - val_loss: 8.6798e-05 - val_mae: 0.0055\n",
      "Epoch 44/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - loss: 2.6018e-04 - mae: 0.0071 - val_loss: 8.6318e-05 - val_mae: 0.0055\n",
      "Epoch 45/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 3.1787e-04 - mae: 0.0073 - val_loss: 8.6201e-05 - val_mae: 0.0055\n",
      "Epoch 46/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - loss: 2.1464e-04 - mae: 0.0067 - val_loss: 8.6008e-05 - val_mae: 0.0055\n",
      "Epoch 47/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - loss: 2.9418e-04 - mae: 0.0072 - val_loss: 8.6426e-05 - val_mae: 0.0055\n",
      "Epoch 48/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 2.4182e-04 - mae: 0.0065 - val_loss: 8.6051e-05 - val_mae: 0.0055\n",
      "Epoch 49/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 2.7793e-04 - mae: 0.0071 - val_loss: 8.5450e-05 - val_mae: 0.0055\n",
      "Epoch 50/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 67ms/step - loss: 2.7830e-04 - mae: 0.0073 - val_loss: 8.5744e-05 - val_mae: 0.0055\n",
      "Epoch 51/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - loss: 2.7585e-04 - mae: 0.0071 - val_loss: 8.5687e-05 - val_mae: 0.0055\n",
      "Epoch 52/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - loss: 3.1567e-04 - mae: 0.0079 - val_loss: 8.6032e-05 - val_mae: 0.0055\n",
      "Epoch 53/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - loss: 2.5573e-04 - mae: 0.0068 - val_loss: 8.5702e-05 - val_mae: 0.0055\n",
      "Epoch 54/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 2.4005e-04 - mae: 0.0069 - val_loss: 8.5382e-05 - val_mae: 0.0055\n",
      "Epoch 55/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 2.6665e-04 - mae: 0.0071 - val_loss: 8.5597e-05 - val_mae: 0.0055\n",
      "Epoch 56/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - loss: 2.8737e-04 - mae: 0.0075 - val_loss: 8.5682e-05 - val_mae: 0.0055\n",
      "Epoch 57/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - loss: 3.1267e-04 - mae: 0.0075 - val_loss: 8.5909e-05 - val_mae: 0.0055\n",
      "Epoch 58/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 2.2083e-04 - mae: 0.0067 - val_loss: 8.5674e-05 - val_mae: 0.0055\n",
      "Epoch 59/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 2.4371e-04 - mae: 0.0071 - val_loss: 8.5555e-05 - val_mae: 0.0055\n",
      "Epoch 60/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - loss: 3.2202e-04 - mae: 0.0074 - val_loss: 8.5784e-05 - val_mae: 0.0055\n",
      "Epoch 61/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - loss: 2.8272e-04 - mae: 0.0075 - val_loss: 8.5856e-05 - val_mae: 0.0055\n",
      "Epoch 62/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - loss: 2.7721e-04 - mae: 0.0075 - val_loss: 8.5795e-05 - val_mae: 0.0055\n",
      "Epoch 63/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - loss: 3.0001e-04 - mae: 0.0075 - val_loss: 8.5991e-05 - val_mae: 0.0055\n",
      "Epoch 64/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - loss: 2.9792e-04 - mae: 0.0071 - val_loss: 8.5233e-05 - val_mae: 0.0054\n",
      "Epoch 65/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - loss: 2.3468e-04 - mae: 0.0069 - val_loss: 8.5488e-05 - val_mae: 0.0055\n",
      "Epoch 66/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 2.6749e-04 - mae: 0.0072 - val_loss: 8.6262e-05 - val_mae: 0.0055\n",
      "Epoch 67/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - loss: 2.8329e-04 - mae: 0.0075 - val_loss: 8.5732e-05 - val_mae: 0.0055\n",
      "Epoch 68/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - loss: 2.8635e-04 - mae: 0.0071 - val_loss: 8.5961e-05 - val_mae: 0.0055\n",
      "Epoch 69/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 2.3506e-04 - mae: 0.0069 - val_loss: 8.6232e-05 - val_mae: 0.0055\n",
      "Epoch 70/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 65ms/step - loss: 2.1298e-04 - mae: 0.0066 - val_loss: 8.5956e-05 - val_mae: 0.0055\n",
      "Epoch 71/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - loss: 2.7276e-04 - mae: 0.0071 - val_loss: 8.5393e-05 - val_mae: 0.0055\n",
      "Epoch 72/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - loss: 2.5699e-04 - mae: 0.0068 - val_loss: 8.6115e-05 - val_mae: 0.0055\n",
      "Epoch 73/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - loss: 2.8685e-04 - mae: 0.0073 - val_loss: 8.5431e-05 - val_mae: 0.0055\n",
      "Epoch 74/100\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - loss: 2.8314e-04 - mae: 0.0072 - val_loss: 8.5661e-05 - val_mae: 0.0055\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 64.\n",
      "\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "   ✔ Train MAE  = 0.004\n",
      "   ✔ Train RMSE = 0.010\n",
      "   ✔ Test MAE   = 0.001\n",
      "   ✔ Test RMSE  = 0.001\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: USD COIN\n",
      "----------------------------------------------------------\n",
      "• Train rows: 701, Val: 150, Test: 151\n",
      "Training samples: 641, Validation samples: 90, Testing samples: 91\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_17\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ lstm_34 (LSTM)                       │ (None, 60, 64)              │          26,624 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_34 (Dropout)                 │ (None, 60, 64)              │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ lstm_35 (LSTM)                       │ (None, 32)                  │          12,416 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_35 (Dropout)                 │ (None, 32)                  │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_34 (Dense)                     │ (None, 16)                  │             528 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_35 (Dense)                     │ (None, 1)                   │              17 │\n",
      "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
      " Total params: 39,585 (154.63 KB)\n",
      " Trainable params: 39,585 (154.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - loss: 0.1759 - mae: 0.3834 - val_loss: 0.1472 - val_mae: 0.3836\n",
      "Epoch 2/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.2030 - mae: 0.4408 - val_loss: 0.1314 - val_mae: 0.3625\n",
      "Epoch 3/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.1867 - mae: 0.4220 - val_loss: 0.1170 - val_mae: 0.3421\n",
      "Epoch 4/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.1661 - mae: 0.3967 - val_loss: 0.1038 - val_mae: 0.3221\n",
      "Epoch 5/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.1529 - mae: 0.3793 - val_loss: 0.0915 - val_mae: 0.3025\n",
      "Epoch 6/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.1370 - mae: 0.3577 - val_loss: 0.0804 - val_mae: 0.2836\n",
      "Epoch 7/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.1249 - mae: 0.3413 - val_loss: 0.0705 - val_mae: 0.2655\n",
      "Epoch 8/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.1158 - mae: 0.3271 - val_loss: 0.0615 - val_mae: 0.2479\n",
      "Epoch 9/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.1016 - mae: 0.3055 - val_loss: 0.0533 - val_mae: 0.2309\n",
      "Epoch 10/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - loss: 0.0932 - mae: 0.2901 - val_loss: 0.0459 - val_mae: 0.2142\n",
      "Epoch 11/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - loss: 0.0860 - mae: 0.2772 - val_loss: 0.0393 - val_mae: 0.1981\n",
      "Epoch 12/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.0746 - mae: 0.2568 - val_loss: 0.0334 - val_mae: 0.1828\n",
      "Epoch 13/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0650 - mae: 0.2384 - val_loss: 0.0280 - val_mae: 0.1672\n",
      "Epoch 14/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0629 - mae: 0.2309 - val_loss: 0.0233 - val_mae: 0.1525\n",
      "Epoch 15/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.0518 - mae: 0.2098 - val_loss: 0.0194 - val_mae: 0.1391\n",
      "Epoch 16/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0510 - mae: 0.2032 - val_loss: 0.0159 - val_mae: 0.1259\n",
      "Epoch 17/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0428 - mae: 0.1873 - val_loss: 0.0129 - val_mae: 0.1134\n",
      "Epoch 18/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0379 - mae: 0.1729 - val_loss: 0.0103 - val_mae: 0.1015\n",
      "Epoch 19/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0376 - mae: 0.1689 - val_loss: 0.0081 - val_mae: 0.0900\n",
      "Epoch 20/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0306 - mae: 0.1492 - val_loss: 0.0063 - val_mae: 0.0794\n",
      "Epoch 21/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.0299 - mae: 0.1438 - val_loss: 0.0048 - val_mae: 0.0694\n",
      "Epoch 22/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.0278 - mae: 0.1358 - val_loss: 0.0036 - val_mae: 0.0598\n",
      "Epoch 23/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0228 - mae: 0.1188 - val_loss: 0.0025 - val_mae: 0.0503\n",
      "Epoch 24/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.0214 - mae: 0.1137 - val_loss: 0.0017 - val_mae: 0.0415\n",
      "Epoch 25/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0198 - mae: 0.1061 - val_loss: 0.0011 - val_mae: 0.0332\n",
      "Epoch 26/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0188 - mae: 0.0995 - val_loss: 6.5546e-04 - val_mae: 0.0253\n",
      "Epoch 27/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0184 - mae: 0.0953 - val_loss: 3.4686e-04 - val_mae: 0.0183\n",
      "Epoch 28/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.0165 - mae: 0.0910 - val_loss: 1.5000e-04 - val_mae: 0.0118\n",
      "Epoch 29/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0150 - mae: 0.0830 - val_loss: 4.7766e-05 - val_mae: 0.0060\n",
      "Epoch 30/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0153 - mae: 0.0839 - val_loss: 2.0197e-05 - val_mae: 0.0026\n",
      "Epoch 31/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - loss: 0.0125 - mae: 0.0717 - val_loss: 5.3178e-05 - val_mae: 0.0061\n",
      "Epoch 32/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0120 - mae: 0.0719 - val_loss: 1.3926e-04 - val_mae: 0.0109\n",
      "Epoch 33/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0128 - mae: 0.0724 - val_loss: 2.7163e-04 - val_mae: 0.0159\n",
      "Epoch 34/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - loss: 0.0131 - mae: 0.0745 - val_loss: 4.3040e-04 - val_mae: 0.0203\n",
      "Epoch 35/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - loss: 0.0108 - mae: 0.0674 - val_loss: 6.1427e-04 - val_mae: 0.0244\n",
      "Epoch 36/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0123 - mae: 0.0712 - val_loss: 8.0615e-04 - val_mae: 0.0280\n",
      "Epoch 37/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - loss: 0.0109 - mae: 0.0664 - val_loss: 0.0010 - val_mae: 0.0313\n",
      "Epoch 38/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0118 - mae: 0.0697 - val_loss: 0.0012 - val_mae: 0.0347\n",
      "Epoch 39/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0103 - mae: 0.0653 - val_loss: 0.0015 - val_mae: 0.0378\n",
      "Epoch 40/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - loss: 0.0094 - mae: 0.0658 - val_loss: 0.0017 - val_mae: 0.0410\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "   ✔ Train MAE  = 0.006\n",
      "   ✔ Train RMSE = 0.009\n",
      "   ✔ Test MAE   = 0.000\n",
      "   ✔ Test RMSE  = 0.001\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: UNISWAP\n",
      "----------------------------------------------------------\n",
      " Skipping Uniswap: not enough rows.\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: WRAPPED BITCOIN\n",
      "----------------------------------------------------------\n",
      "• Train rows: 621, Val: 133, Test: 134\n",
      "Training samples: 561, Validation samples: 73, Testing samples: 74\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_18\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ lstm_36 (LSTM)                       │ (None, 60, 64)              │          26,624 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_36 (Dropout)                 │ (None, 60, 64)              │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ lstm_37 (LSTM)                       │ (None, 32)                  │          12,416 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_37 (Dropout)                 │ (None, 32)                  │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_36 (Dense)                     │ (None, 16)                  │             528 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_37 (Dense)                     │ (None, 1)                   │              17 │\n",
      "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
      " Total params: 39,585 (154.63 KB)\n",
      " Trainable params: 39,585 (154.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 117ms/step - loss: 0.4313 - mae: 0.6227 - val_loss: 13.1134 - val_mae: 3.4642\n",
      "Epoch 2/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - loss: 0.3736 - mae: 0.5819 - val_loss: 12.9913 - val_mae: 3.4465\n",
      "Epoch 3/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.3467 - mae: 0.5552 - val_loss: 12.8708 - val_mae: 3.4290\n",
      "Epoch 4/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.3286 - mae: 0.5380 - val_loss: 12.7530 - val_mae: 3.4118\n",
      "Epoch 5/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - loss: 0.3245 - mae: 0.5354 - val_loss: 12.6364 - val_mae: 3.3947\n",
      "Epoch 6/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.3024 - mae: 0.5157 - val_loss: 12.5235 - val_mae: 3.3780\n",
      "Epoch 7/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.2886 - mae: 0.5018 - val_loss: 12.4128 - val_mae: 3.3616\n",
      "Epoch 8/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.2714 - mae: 0.4848 - val_loss: 12.3052 - val_mae: 3.3455\n",
      "Epoch 9/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.2586 - mae: 0.4704 - val_loss: 12.1992 - val_mae: 3.3296\n",
      "Epoch 10/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.2318 - mae: 0.4411 - val_loss: 12.0963 - val_mae: 3.3142\n",
      "Epoch 11/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - loss: 0.2232 - mae: 0.4355 - val_loss: 11.9952 - val_mae: 3.2989\n",
      "Epoch 12/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.2095 - mae: 0.4194 - val_loss: 11.8971 - val_mae: 3.2840\n",
      "Epoch 13/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.1950 - mae: 0.3989 - val_loss: 11.8013 - val_mae: 3.2693\n",
      "Epoch 14/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 0.1885 - mae: 0.3894 - val_loss: 11.7072 - val_mae: 3.2549\n",
      "Epoch 15/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.1733 - mae: 0.3753 - val_loss: 11.6152 - val_mae: 3.2408\n",
      "Epoch 16/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.1816 - mae: 0.3803 - val_loss: 11.5251 - val_mae: 3.2268\n",
      "Epoch 17/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.1527 - mae: 0.3486 - val_loss: 11.4401 - val_mae: 3.2136\n",
      "Epoch 18/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - loss: 0.1595 - mae: 0.3600 - val_loss: 11.3549 - val_mae: 3.2003\n",
      "Epoch 19/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.1468 - mae: 0.3402 - val_loss: 11.2734 - val_mae: 3.1876\n",
      "Epoch 20/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - loss: 0.1319 - mae: 0.3229 - val_loss: 11.1938 - val_mae: 3.1751\n",
      "Epoch 21/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.1325 - mae: 0.3276 - val_loss: 11.1150 - val_mae: 3.1626\n",
      "Epoch 22/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.1122 - mae: 0.2945 - val_loss: 11.0411 - val_mae: 3.1509\n",
      "Epoch 23/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.1118 - mae: 0.2939 - val_loss: 10.9675 - val_mae: 3.1392\n",
      "Epoch 24/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.1093 - mae: 0.2889 - val_loss: 10.8964 - val_mae: 3.1279\n",
      "Epoch 25/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - loss: 0.0987 - mae: 0.2720 - val_loss: 10.8284 - val_mae: 3.1170\n",
      "Epoch 26/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0921 - mae: 0.2656 - val_loss: 10.7614 - val_mae: 3.1062\n",
      "Epoch 27/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0952 - mae: 0.2682 - val_loss: 10.6962 - val_mae: 3.0957\n",
      "Epoch 28/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0826 - mae: 0.2450 - val_loss: 10.6351 - val_mae: 3.0858\n",
      "Epoch 29/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - loss: 0.0797 - mae: 0.2432 - val_loss: 10.5743 - val_mae: 3.0760\n",
      "Epoch 30/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - loss: 0.0774 - mae: 0.2369 - val_loss: 10.5154 - val_mae: 3.0664\n",
      "Epoch 31/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0710 - mae: 0.2279 - val_loss: 10.4603 - val_mae: 3.0574\n",
      "Epoch 32/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0690 - mae: 0.2235 - val_loss: 10.4062 - val_mae: 3.0485\n",
      "Epoch 33/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0715 - mae: 0.2284 - val_loss: 10.3531 - val_mae: 3.0398\n",
      "Epoch 34/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0659 - mae: 0.2164 - val_loss: 10.3032 - val_mae: 3.0316\n",
      "Epoch 35/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0597 - mae: 0.2074 - val_loss: 10.2559 - val_mae: 3.0238\n",
      "Epoch 36/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0594 - mae: 0.2058 - val_loss: 10.2082 - val_mae: 3.0159\n",
      "Epoch 37/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0580 - mae: 0.2012 - val_loss: 10.1634 - val_mae: 3.0084\n",
      "Epoch 38/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0554 - mae: 0.1966 - val_loss: 10.1195 - val_mae: 3.0011\n",
      "Epoch 39/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0566 - mae: 0.2018 - val_loss: 10.0789 - val_mae: 2.9944\n",
      "Epoch 40/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0533 - mae: 0.1934 - val_loss: 10.0390 - val_mae: 2.9877\n",
      "Epoch 41/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0515 - mae: 0.1905 - val_loss: 10.0008 - val_mae: 2.9813\n",
      "Epoch 42/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0498 - mae: 0.1893 - val_loss: 9.9665 - val_mae: 2.9755\n",
      "Epoch 43/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0488 - mae: 0.1847 - val_loss: 9.9315 - val_mae: 2.9696\n",
      "Epoch 44/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0484 - mae: 0.1835 - val_loss: 9.8983 - val_mae: 2.9641\n",
      "Epoch 45/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0476 - mae: 0.1805 - val_loss: 9.8664 - val_mae: 2.9587\n",
      "Epoch 46/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0424 - mae: 0.1724 - val_loss: 9.8364 - val_mae: 2.9536\n",
      "Epoch 47/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0411 - mae: 0.1683 - val_loss: 9.8084 - val_mae: 2.9489\n",
      "Epoch 48/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0459 - mae: 0.1787 - val_loss: 9.7815 - val_mae: 2.9443\n",
      "Epoch 49/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0444 - mae: 0.1772 - val_loss: 9.7566 - val_mae: 2.9401\n",
      "Epoch 50/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - loss: 0.0429 - mae: 0.1718 - val_loss: 9.7312 - val_mae: 2.9357\n",
      "Epoch 51/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0416 - mae: 0.1704 - val_loss: 9.7086 - val_mae: 2.9319\n",
      "Epoch 52/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0398 - mae: 0.1652 - val_loss: 9.6852 - val_mae: 2.9279\n",
      "Epoch 53/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0413 - mae: 0.1691 - val_loss: 9.6642 - val_mae: 2.9243\n",
      "Epoch 54/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0413 - mae: 0.1705 - val_loss: 9.6454 - val_mae: 2.9211\n",
      "Epoch 55/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.0395 - mae: 0.1653 - val_loss: 9.6264 - val_mae: 2.9178\n",
      "Epoch 56/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0385 - mae: 0.1596 - val_loss: 9.6066 - val_mae: 2.9144\n",
      "Epoch 57/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0402 - mae: 0.1659 - val_loss: 9.5925 - val_mae: 2.9120\n",
      "Epoch 58/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0390 - mae: 0.1623 - val_loss: 9.5766 - val_mae: 2.9093\n",
      "Epoch 59/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0383 - mae: 0.1593 - val_loss: 9.5624 - val_mae: 2.9068\n",
      "Epoch 60/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0379 - mae: 0.1597 - val_loss: 9.5500 - val_mae: 2.9047\n",
      "Epoch 61/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0388 - mae: 0.1607 - val_loss: 9.5368 - val_mae: 2.9024\n",
      "Epoch 62/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0397 - mae: 0.1619 - val_loss: 9.5252 - val_mae: 2.9004\n",
      "Epoch 63/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0357 - mae: 0.1524 - val_loss: 9.5121 - val_mae: 2.8982\n",
      "Epoch 64/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0380 - mae: 0.1575 - val_loss: 9.5030 - val_mae: 2.8966\n",
      "Epoch 65/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0367 - mae: 0.1567 - val_loss: 9.4909 - val_mae: 2.8945\n",
      "Epoch 66/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 0.0371 - mae: 0.1546 - val_loss: 9.4824 - val_mae: 2.8930\n",
      "Epoch 67/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0410 - mae: 0.1641 - val_loss: 9.4750 - val_mae: 2.8918\n",
      "Epoch 68/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - loss: 0.0390 - mae: 0.1604 - val_loss: 9.4668 - val_mae: 2.8903\n",
      "Epoch 69/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.0372 - mae: 0.1571 - val_loss: 9.4597 - val_mae: 2.8891\n",
      "Epoch 70/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.0379 - mae: 0.1574 - val_loss: 9.4549 - val_mae: 2.8883\n",
      "Epoch 71/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0397 - mae: 0.1646 - val_loss: 9.4485 - val_mae: 2.8872\n",
      "Epoch 72/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0370 - mae: 0.1559 - val_loss: 9.4421 - val_mae: 2.8861\n",
      "Epoch 73/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0361 - mae: 0.1527 - val_loss: 9.4350 - val_mae: 2.8848\n",
      "Epoch 74/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0399 - mae: 0.1634 - val_loss: 9.4290 - val_mae: 2.8838\n",
      "Epoch 75/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0371 - mae: 0.1565 - val_loss: 9.4242 - val_mae: 2.8830\n",
      "Epoch 76/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0389 - mae: 0.1625 - val_loss: 9.4198 - val_mae: 2.8822\n",
      "Epoch 77/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 0.0354 - mae: 0.1497 - val_loss: 9.4165 - val_mae: 2.8816\n",
      "Epoch 78/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0385 - mae: 0.1572 - val_loss: 9.4139 - val_mae: 2.8812\n",
      "Epoch 79/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0378 - mae: 0.1559 - val_loss: 9.4091 - val_mae: 2.8804\n",
      "Epoch 80/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0359 - mae: 0.1519 - val_loss: 9.4053 - val_mae: 2.8797\n",
      "Epoch 81/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 0.0383 - mae: 0.1581 - val_loss: 9.4019 - val_mae: 2.8791\n",
      "Epoch 82/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0383 - mae: 0.1573 - val_loss: 9.3989 - val_mae: 2.8786\n",
      "Epoch 83/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0384 - mae: 0.1597 - val_loss: 9.3973 - val_mae: 2.8783\n",
      "Epoch 84/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0383 - mae: 0.1581 - val_loss: 9.3930 - val_mae: 2.8776\n",
      "Epoch 85/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0373 - mae: 0.1563 - val_loss: 9.3922 - val_mae: 2.8774\n",
      "Epoch 86/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.0386 - mae: 0.1584 - val_loss: 9.3899 - val_mae: 2.8770\n",
      "Epoch 87/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0361 - mae: 0.1522 - val_loss: 9.3900 - val_mae: 2.8770\n",
      "Epoch 88/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - loss: 0.0384 - mae: 0.1579 - val_loss: 9.3884 - val_mae: 2.8768\n",
      "Epoch 89/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0363 - mae: 0.1569 - val_loss: 9.3864 - val_mae: 2.8764\n",
      "Epoch 90/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.0384 - mae: 0.1596 - val_loss: 9.3848 - val_mae: 2.8761\n",
      "Epoch 91/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - loss: 0.0368 - mae: 0.1551 - val_loss: 9.3860 - val_mae: 2.8763\n",
      "Epoch 92/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - loss: 0.0389 - mae: 0.1588 - val_loss: 9.3843 - val_mae: 2.8760\n",
      "Epoch 93/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - loss: 0.0371 - mae: 0.1543 - val_loss: 9.3815 - val_mae: 2.8756\n",
      "Epoch 94/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - loss: 0.0391 - mae: 0.1599 - val_loss: 9.3801 - val_mae: 2.8753\n",
      "Epoch 95/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0366 - mae: 0.1551 - val_loss: 9.3807 - val_mae: 2.8754\n",
      "Epoch 96/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.0371 - mae: 0.1561 - val_loss: 9.3797 - val_mae: 2.8752\n",
      "Epoch 97/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - loss: 0.0379 - mae: 0.1553 - val_loss: 9.3808 - val_mae: 2.8754\n",
      "Epoch 98/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0356 - mae: 0.1528 - val_loss: 9.3784 - val_mae: 2.8750\n",
      "Epoch 99/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - loss: 0.0375 - mae: 0.1567 - val_loss: 9.3810 - val_mae: 2.8755\n",
      "Epoch 100/100\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - loss: 0.0380 - mae: 0.1581 - val_loss: 9.3820 - val_mae: 2.8756\n",
      "Restoring model weights from the end of the best epoch: 98.\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "   ✔ Train MAE  = 1431.786\n",
      "   ✔ Train RMSE = 1774.216\n",
      "   ✔ Test MAE   = 32930.198\n",
      "   ✔ Test RMSE  = 34078.898\n",
      "----------------------------------------------------------\n",
      " Now Processing Coin: XRP\n",
      "----------------------------------------------------------\n",
      "• Train rows: 2025, Val: 433, Test: 435\n",
      "Training samples: 1965, Validation samples: 373, Testing samples: 375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Model: \"sequential_19\"\n",
      "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
      "┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n",
      "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
      "│ lstm_38 (LSTM)                       │ (None, 60, 64)              │          26,624 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_38 (Dropout)                 │ (None, 60, 64)              │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ lstm_39 (LSTM)                       │ (None, 32)                  │          12,416 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dropout_39 (Dropout)                 │ (None, 32)                  │               0 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_38 (Dense)                     │ (None, 16)                  │             528 │\n",
      "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
      "│ dense_39 (Dense)                     │ (None, 1)                   │              17 │\n",
      "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
      " Total params: 39,585 (154.63 KB)\n",
      " Trainable params: 39,585 (154.63 KB)\n",
      " Non-trainable params: 0 (0.00 B)\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - loss: 0.0127 - mae: 0.0569 - val_loss: 0.0017 - val_mae: 0.0355\n",
      "Epoch 2/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 0.0107 - mae: 0.0643 - val_loss: 0.0014 - val_mae: 0.0310\n",
      "Epoch 3/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - loss: 0.0115 - mae: 0.0689 - val_loss: 0.0015 - val_mae: 0.0314\n",
      "Epoch 4/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - loss: 0.0078 - mae: 0.0606 - val_loss: 0.0012 - val_mae: 0.0278\n",
      "Epoch 5/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - loss: 0.0102 - mae: 0.0670 - val_loss: 0.0014 - val_mae: 0.0302\n",
      "Epoch 6/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - loss: 0.0112 - mae: 0.0670 - val_loss: 0.0014 - val_mae: 0.0299\n",
      "Epoch 7/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.0131 - mae: 0.0696 - val_loss: 0.0015 - val_mae: 0.0322\n",
      "Epoch 8/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - loss: 0.0105 - mae: 0.0653 - val_loss: 0.0013 - val_mae: 0.0297\n",
      "Epoch 9/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - loss: 0.0104 - mae: 0.0667 - val_loss: 0.0014 - val_mae: 0.0308\n",
      "Epoch 10/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 0.0111 - mae: 0.0683 - val_loss: 0.0015 - val_mae: 0.0327\n",
      "Epoch 11/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - loss: 0.0107 - mae: 0.0653 - val_loss: 0.0014 - val_mae: 0.0301\n",
      "Epoch 12/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - loss: 0.0090 - mae: 0.0623 - val_loss: 0.0013 - val_mae: 0.0285\n",
      "Epoch 13/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - loss: 0.0120 - mae: 0.0688 - val_loss: 0.0014 - val_mae: 0.0313\n",
      "Epoch 14/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - loss: 0.0111 - mae: 0.0664 - val_loss: 0.0014 - val_mae: 0.0307\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "   ✔ Train MAE  = 0.225\n",
      "   ✔ Train RMSE = 0.342\n",
      "   ✔ Test MAE   = 0.347\n",
      "   ✔ Test RMSE  = 0.519\n",
      "\n",
      "================= LSTM FORECASTING FINISHED =================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coin</th>\n",
       "      <th>Model</th>\n",
       "      <th>Train_MAE</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Test_MAE</th>\n",
       "      <th>Test_RMSE</th>\n",
       "      <th>ForecastPlot</th>\n",
       "      <th>ResidualPlot</th>\n",
       "      <th>LossPlot</th>\n",
       "      <th>PredCSV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Tether</td>\n",
       "      <td>LSTM_Multi</td>\n",
       "      <td>0.004334</td>\n",
       "      <td>0.009931</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>USD Coin</td>\n",
       "      <td>LSTM_Multi</td>\n",
       "      <td>0.005690</td>\n",
       "      <td>0.008674</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TRON</td>\n",
       "      <td>LSTM_Multi</td>\n",
       "      <td>0.012693</td>\n",
       "      <td>0.021703</td>\n",
       "      <td>0.057335</td>\n",
       "      <td>0.066134</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Crypto.com Coin</td>\n",
       "      <td>LSTM_Multi</td>\n",
       "      <td>0.032148</td>\n",
       "      <td>0.042713</td>\n",
       "      <td>0.072207</td>\n",
       "      <td>0.080060</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dogecoin</td>\n",
       "      <td>LSTM_Multi</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.094590</td>\n",
       "      <td>0.177694</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NEM</td>\n",
       "      <td>LSTM_Multi</td>\n",
       "      <td>0.117143</td>\n",
       "      <td>0.226002</td>\n",
       "      <td>0.191073</td>\n",
       "      <td>0.240598</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Stellar</td>\n",
       "      <td>LSTM_Multi</td>\n",
       "      <td>0.092437</td>\n",
       "      <td>0.128224</td>\n",
       "      <td>0.216501</td>\n",
       "      <td>0.279340</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XRP</td>\n",
       "      <td>LSTM_Multi</td>\n",
       "      <td>0.225008</td>\n",
       "      <td>0.341546</td>\n",
       "      <td>0.346757</td>\n",
       "      <td>0.519098</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IOTA</td>\n",
       "      <td>LSTM_Multi</td>\n",
       "      <td>0.538097</td>\n",
       "      <td>1.026150</td>\n",
       "      <td>1.076793</td>\n",
       "      <td>1.192605</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cardano</td>\n",
       "      <td>LSTM_Multi</td>\n",
       "      <td>0.096505</td>\n",
       "      <td>0.155733</td>\n",
       "      <td>1.224508</td>\n",
       "      <td>1.253645</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EOS</td>\n",
       "      <td>LSTM_Multi</td>\n",
       "      <td>2.922239</td>\n",
       "      <td>4.319803</td>\n",
       "      <td>2.670042</td>\n",
       "      <td>3.344483</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cosmos</td>\n",
       "      <td>LSTM_Multi</td>\n",
       "      <td>1.061956</td>\n",
       "      <td>1.312327</td>\n",
       "      <td>12.141705</td>\n",
       "      <td>13.413705</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chainlink</td>\n",
       "      <td>LSTM_Multi</td>\n",
       "      <td>1.026727</td>\n",
       "      <td>1.170324</td>\n",
       "      <td>29.043348</td>\n",
       "      <td>30.046472</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Solana</td>\n",
       "      <td>LSTM_Multi</td>\n",
       "      <td>1.280888</td>\n",
       "      <td>1.870375</td>\n",
       "      <td>31.352218</td>\n",
       "      <td>31.361734</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Litecoin</td>\n",
       "      <td>LSTM_Multi</td>\n",
       "      <td>36.820151</td>\n",
       "      <td>54.100687</td>\n",
       "      <td>93.354167</td>\n",
       "      <td>123.237865</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Monero</td>\n",
       "      <td>LSTM_Multi</td>\n",
       "      <td>63.404922</td>\n",
       "      <td>86.699892</td>\n",
       "      <td>134.168895</td>\n",
       "      <td>162.982417</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Binance Coin</td>\n",
       "      <td>LSTM_Multi</td>\n",
       "      <td>6.216789</td>\n",
       "      <td>8.064049</td>\n",
       "      <td>333.043422</td>\n",
       "      <td>366.816093</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ethereum</td>\n",
       "      <td>LSTM_Multi</td>\n",
       "      <td>184.872267</td>\n",
       "      <td>252.067474</td>\n",
       "      <td>1415.773967</td>\n",
       "      <td>1684.842101</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>LSTM_Multi</td>\n",
       "      <td>2662.418592</td>\n",
       "      <td>3431.606510</td>\n",
       "      <td>26329.526028</td>\n",
       "      <td>31802.515125</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wrapped Bitcoin</td>\n",
       "      <td>LSTM_Multi</td>\n",
       "      <td>1431.785764</td>\n",
       "      <td>1774.215772</td>\n",
       "      <td>32930.197909</td>\n",
       "      <td>34078.898372</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "      <td>C:\\Users\\BALA\\OneDrive - University of Hertfor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Coin       Model    Train_MAE   Train_RMSE      Test_MAE  \\\n",
       "16           Tether  LSTM_Multi     0.004334     0.009931      0.000603   \n",
       "17         USD Coin  LSTM_Multi     0.005690     0.008674      0.000458   \n",
       "15             TRON  LSTM_Multi     0.012693     0.021703      0.057335   \n",
       "5   Crypto.com Coin  LSTM_Multi     0.032148     0.042713      0.072207   \n",
       "6          Dogecoin  LSTM_Multi     0.001475     0.001997      0.094590   \n",
       "12              NEM  LSTM_Multi     0.117143     0.226002      0.191073   \n",
       "14          Stellar  LSTM_Multi     0.092437     0.128224      0.216501   \n",
       "19              XRP  LSTM_Multi     0.225008     0.341546      0.346757   \n",
       "9              IOTA  LSTM_Multi     0.538097     1.026150      1.076793   \n",
       "2           Cardano  LSTM_Multi     0.096505     0.155733      1.224508   \n",
       "7               EOS  LSTM_Multi     2.922239     4.319803      2.670042   \n",
       "4            Cosmos  LSTM_Multi     1.061956     1.312327     12.141705   \n",
       "3         Chainlink  LSTM_Multi     1.026727     1.170324     29.043348   \n",
       "13           Solana  LSTM_Multi     1.280888     1.870375     31.352218   \n",
       "10         Litecoin  LSTM_Multi    36.820151    54.100687     93.354167   \n",
       "11           Monero  LSTM_Multi    63.404922    86.699892    134.168895   \n",
       "0      Binance Coin  LSTM_Multi     6.216789     8.064049    333.043422   \n",
       "8          Ethereum  LSTM_Multi   184.872267   252.067474   1415.773967   \n",
       "1           Bitcoin  LSTM_Multi  2662.418592  3431.606510  26329.526028   \n",
       "18  Wrapped Bitcoin  LSTM_Multi  1431.785764  1774.215772  32930.197909   \n",
       "\n",
       "       Test_RMSE                                       ForecastPlot  \\\n",
       "16      0.000973  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "17      0.001243  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "15      0.066134  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "5       0.080060  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "6       0.177694  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "12      0.240598  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "14      0.279340  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "19      0.519098  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "9       1.192605  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "2       1.253645  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "7       3.344483  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "4      13.413705  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "3      30.046472  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "13     31.361734  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "10    123.237865  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "11    162.982417  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "0     366.816093  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "8    1684.842101  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "1   31802.515125  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "18  34078.898372  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "\n",
       "                                         ResidualPlot  \\\n",
       "16  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "17  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "15  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "5   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "6   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "12  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "14  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "19  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "9   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "2   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "7   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "4   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "3   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "13  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "10  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "11  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "0   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "8   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "1   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "18  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "\n",
       "                                             LossPlot  \\\n",
       "16  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "17  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "15  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "5   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "6   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "12  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "14  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "19  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "9   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "2   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "7   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "4   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "3   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "13  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "10  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "11  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "0   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "8   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "1   C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "18  C:\\Users\\BALA\\OneDrive - University of Hertfor...   \n",
       "\n",
       "                                              PredCSV  \n",
       "16  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "17  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "15  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "5   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "6   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "12  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "14  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "19  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "9   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "2   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "7   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "4   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "3   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "13  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "10  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "11  C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "0   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "8   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "1   C:\\Users\\BALA\\OneDrive - University of Hertfor...  \n",
       "18  C:\\Users\\BALA\\OneDrive - University of Hertfor...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# IMPROVED LSTM FORECASTING — MULTIVARIATE, REGULARISED\n",
    "# ============================================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# ----------------- Paths -----------------\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "PROCESSED_DIR = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "FIG_DIR = PROJECT_ROOT / \"reports\" / \"figures\"\n",
    "\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----------------- Load data -----------------\n",
    "df = pd.read_csv(PROCESSED_DIR / \"crypto_features.csv\", parse_dates=[\"Date\"])\n",
    "df = df.sort_values([\"Name\", \"Date\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# ----------------- Config -----------------\n",
    "TARGET_COL = \"Close\"\n",
    "LOOKBACK = 60       # days in the input sequence\n",
    "HORIZON = 1         # forecast 1 day ahead\n",
    "\n",
    "# Features: all numeric columns except metadata and target\n",
    "meta_cols = [\"Date\", \"Name\", \"Symbol\", \"SourceFile\"]\n",
    "feature_cols = [c for c in df.columns if c not in meta_cols + [TARGET_COL]]\n",
    "\n",
    "print(\"\\nUsing feature columns:\")\n",
    "print(feature_cols)\n",
    "\n",
    "# ----------------- Helpers -----------------\n",
    "def make_sequences(values_X, values_y, lookback, horizon=1):\n",
    "    \"\"\"\n",
    "    Turn time-ordered arrays into (X, y) sequences.\n",
    "    X[i] is a sequence of 'lookback' time steps.\n",
    "    y[i] is the target at time t + horizon - 1.\n",
    "    \"\"\"\n",
    "    X_seq, y_seq = [], []\n",
    "    n = len(values_y)\n",
    "    for t in range(lookback, n - horizon + 1):\n",
    "        X_seq.append(values_X[t - lookback:t, :])\n",
    "        y_seq.append(values_y[t + horizon - 1])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "\n",
    "def build_lstm_model(input_shape):\n",
    "    \"\"\"\n",
    "    Simple but solid LSTM model with dropout.\n",
    "    input_shape = (timesteps, n_features)\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(32, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation=\"relu\"))\n",
    "    model.add(Dense(1))  # predict next Close\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_and_save_forecast(dates, y_true, y_pred, coin, model_name):\n",
    "    plt.figure(figsize=(11, 5))\n",
    "    plt.plot(dates, y_true, label=\"Actual\", linewidth=2)\n",
    "    plt.plot(dates, y_pred, label=\"Predicted\", linewidth=2)\n",
    "    plt.title(f\"{model_name} Forecast vs Actual — {coin}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Close Price\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    out_path = FIG_DIR / f\"{model_name}_{coin}_forecast.png\"\n",
    "    plt.savefig(out_path, dpi=240)\n",
    "    plt.close()\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def plot_and_save_residuals(dates, residuals, coin, model_name):\n",
    "    plt.figure(figsize=(11, 5))\n",
    "    plt.plot(dates, residuals, color=\"purple\")\n",
    "    plt.axhline(0, color=\"black\", linestyle=\"--\")\n",
    "    plt.title(f\"{model_name} Residuals — {coin}\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Residual (y_true - y_pred)\")\n",
    "    plt.tight_layout()\n",
    "    out_path = FIG_DIR / f\"{model_name}_{coin}_residuals.png\"\n",
    "    plt.savefig(out_path, dpi=240)\n",
    "    plt.close()\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def plot_and_save_loss(history, coin, model_name):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "    if \"val_loss\" in history.history:\n",
    "        plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "    plt.title(f\"{model_name} Loss Curves — {coin}\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    out_path = FIG_DIR / f\"{model_name}_{coin}_loss.png\"\n",
    "    plt.savefig(out_path, dpi=240)\n",
    "    plt.close()\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def save_predictions_csv(dates, y_true, y_pred, coin, model_name):\n",
    "    out = pd.DataFrame({\n",
    "        \"Date\": dates,\n",
    "        \"y_true\": y_true,\n",
    "        \"y_pred\": y_pred\n",
    "    })\n",
    "    out_path = PROCESSED_DIR / f\"predictions_{model_name.lower()}_{coin}.csv\"\n",
    "    out.to_csv(out_path, index=False)\n",
    "    return out_path\n",
    "\n",
    "\n",
    "# ----------------- Main LSTM loop (per coin) -----------------\n",
    "results_lstm = []\n",
    "\n",
    "print(\"\\n================= LSTM FORECASTING START =================\\n\")\n",
    "\n",
    "for coin in df[\"Name\"].unique():\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    print(f\" Now Processing Coin: {coin.upper()}\")\n",
    "    print(\"----------------------------------------------------------\")\n",
    "\n",
    "    sub = df[df[\"Name\"] == coin].copy().dropna(subset=[TARGET_COL])\n",
    "\n",
    "    if len(sub) < 365:  # at least 1 year of data\n",
    "        print(f\" Skipping {coin}: not enough rows.\")\n",
    "        continue\n",
    "\n",
    "    sub = sub.sort_values(\"Date\").reset_index(drop=True)\n",
    "\n",
    "    # Extract features & target\n",
    "    X_all = sub[feature_cols].values.astype(float)\n",
    "    y_all = sub[TARGET_COL].values.astype(float)\n",
    "    dates_all = sub[\"Date\"].values\n",
    "\n",
    "    n = len(sub)\n",
    "    n_train = int(n * 0.7)\n",
    "    n_val = int(n * 0.15)\n",
    "    n_test = n - n_train - n_val\n",
    "\n",
    "    train_X_raw = X_all[:n_train]\n",
    "    val_X_raw   = X_all[n_train:n_train + n_val]\n",
    "    test_X_raw  = X_all[n_train + n_val:]\n",
    "\n",
    "    train_y_raw = y_all[:n_train]\n",
    "    val_y_raw   = y_all[n_train:n_train + n_val]\n",
    "    test_y_raw  = y_all[n_train + n_val:]\n",
    "\n",
    "    train_dates = dates_all[:n_train]\n",
    "    val_dates   = dates_all[n_train:n_train + n_val]\n",
    "    test_dates  = dates_all[n_train + n_val:]\n",
    "\n",
    "    print(f\"• Train rows: {len(train_X_raw)}, Val: {len(val_X_raw)}, Test: {len(test_X_raw)}\")\n",
    "\n",
    "    # ------------ Scaling (fit only on TRAIN) ------------\n",
    "    scaler_X = MinMaxScaler()\n",
    "    scaler_y = MinMaxScaler()\n",
    "\n",
    "    train_X_scaled = scaler_X.fit_transform(train_X_raw)\n",
    "    val_X_scaled   = scaler_X.transform(val_X_raw)\n",
    "    test_X_scaled  = scaler_X.transform(test_X_raw)\n",
    "\n",
    "    train_y_scaled = scaler_y.fit_transform(train_y_raw.reshape(-1, 1)).flatten()\n",
    "    val_y_scaled   = scaler_y.transform(val_y_raw.reshape(-1, 1)).flatten()\n",
    "    test_y_scaled  = scaler_y.transform(test_y_raw.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # ------------ Sequence building ------------\n",
    "    X_train_seq, y_train_seq = make_sequences(train_X_scaled, train_y_scaled, LOOKBACK, HORIZON)\n",
    "    X_val_seq,   y_val_seq   = make_sequences(val_X_scaled,   val_y_scaled,   LOOKBACK, HORIZON)\n",
    "    X_test_seq,  y_test_seq  = make_sequences(test_X_scaled,  test_y_scaled,  LOOKBACK, HORIZON)\n",
    "\n",
    "    # Align dates with sequences (use last date in each window + horizon)\n",
    "    train_seq_dates = train_dates[LOOKBACK - 1:LOOKBACK - 1 + len(y_train_seq)]\n",
    "    val_seq_dates   = val_dates[LOOKBACK - 1:LOOKBACK - 1 + len(y_val_seq)]\n",
    "    test_seq_dates  = test_dates[LOOKBACK - 1:LOOKBACK - 1 + len(y_test_seq)]\n",
    "\n",
    "    print(f\"Training samples: {X_train_seq.shape[0]}, \"\n",
    "          f\"Validation samples: {X_val_seq.shape[0]}, \"\n",
    "          f\"Testing samples: {X_test_seq.shape[0]}\")\n",
    "\n",
    "    if X_train_seq.shape[0] == 0 or X_test_seq.shape[0] == 0:\n",
    "        print(f\" Skipping {coin}: not enough sequence data after LOOKBACK.\")\n",
    "        continue\n",
    "\n",
    "    # ------------ Build model ------------\n",
    "    input_shape = (X_train_seq.shape[1], X_train_seq.shape[2])\n",
    "    model = build_lstm_model(input_shape)\n",
    "    model.summary(print_fn=lambda x: print(\"   \" + x))\n",
    "\n",
    "    # ------------ Train model ------------\n",
    "    es = EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_seq, y_train_seq,\n",
    "        validation_data=(X_val_seq, y_val_seq),\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        callbacks=[es],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # ------------ Evaluate ------------\n",
    "    # Train preds\n",
    "    y_train_pred_scaled = model.predict(X_train_seq)\n",
    "    y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled).flatten()\n",
    "    y_train_true = scaler_y.inverse_transform(y_train_seq.reshape(-1, 1)).flatten()\n",
    "\n",
    "    train_mae = mean_absolute_error(y_train_true, y_train_pred)\n",
    "    train_rmse = root_mean_squared_error(y_train_true, y_train_pred)\n",
    "\n",
    "    # Test preds\n",
    "    y_test_pred_scaled = model.predict(X_test_seq)\n",
    "    y_test_pred = scaler_y.inverse_transform(y_test_pred_scaled).flatten()\n",
    "    y_test_true = scaler_y.inverse_transform(y_test_seq.reshape(-1, 1)).flatten()\n",
    "\n",
    "    test_mae = mean_absolute_error(y_test_true, y_test_pred)\n",
    "    test_rmse = root_mean_squared_error(y_test_true, y_test_pred)\n",
    "\n",
    "    print(f\"   Train MAE  = {train_mae:.3f}\")\n",
    "    print(f\"   Train RMSE = {train_rmse:.3f}\")\n",
    "    print(f\"   Test MAE   = {test_mae:.3f}\")\n",
    "    print(f\"   Test RMSE  = {test_rmse:.3f}\")\n",
    "\n",
    "    # ------------ Plots & CSVs ------------\n",
    "    forecast_plot = plot_and_save_forecast(\n",
    "        dates=test_seq_dates,\n",
    "        y_true=y_test_true,\n",
    "        y_pred=y_test_pred,\n",
    "        coin=coin,\n",
    "        model_name=\"LSTM_Multi\"\n",
    "    )\n",
    "\n",
    "    residuals = y_test_true - y_test_pred\n",
    "    residual_plot = plot_and_save_residuals(\n",
    "        dates=test_seq_dates,\n",
    "        residuals=residuals,\n",
    "        coin=coin,\n",
    "        model_name=\"LSTM_Multi\"\n",
    "    )\n",
    "\n",
    "    loss_plot = plot_and_save_loss(\n",
    "        history=history,\n",
    "        coin=coin,\n",
    "        model_name=\"LSTM_Multi\"\n",
    "    )\n",
    "\n",
    "    pred_csv = save_predictions_csv(\n",
    "        dates=test_seq_dates,\n",
    "        y_true=y_test_true,\n",
    "        y_pred=y_test_pred,\n",
    "        coin=coin,\n",
    "        model_name=\"LSTM_Multi\"\n",
    "    )\n",
    "\n",
    "    # ------------ Collect results ------------\n",
    "    results_lstm.append({\n",
    "        \"Coin\": coin,\n",
    "        \"Model\": \"LSTM_Multi\",\n",
    "        \"Train_MAE\": train_mae,\n",
    "        \"Train_RMSE\": train_rmse,\n",
    "        \"Test_MAE\": test_mae,\n",
    "        \"Test_RMSE\": test_rmse,\n",
    "        \"ForecastPlot\": str(forecast_plot),\n",
    "        \"ResidualPlot\": str(residual_plot),\n",
    "        \"LossPlot\": str(loss_plot),\n",
    "        \"PredCSV\": str(pred_csv),\n",
    "    })\n",
    "\n",
    "print(\"\\n================= LSTM FORECASTING FINISHED =================\\n\")\n",
    "\n",
    "if results_lstm:\n",
    "    lstm_df = pd.DataFrame(results_lstm).sort_values(\"Test_RMSE\")\n",
    "    display(lstm_df)\n",
    "else:\n",
    "    print(\"No LSTM results — something went wrong.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76056f4-5775-4e84-ad4a-abede822d6ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
